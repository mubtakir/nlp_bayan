#!/usr/bin/env python3
"""
Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¯Ù„Ø§Ù„Ø§Øª Ø§Ù„Ø¨ØµØ±ÙŠØ© - Visual Semantic Engine
==============================================

ğŸ§¬ ÙŠØ·Ø¨Ù‚ Ù†Ø¸Ø±ÙŠØ§Øª Ø¨ØµÙŠØ±Ø© Ø¹Ù„Ù‰ Ø³ÙŠÙ…ÙŠØ§Ø¦ÙŠØ© Ø§Ù„Ø­Ø±ÙˆÙ ÙÙŠ Ø¨ÙŠØ§Ù†:
   - Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙØ±: ÙƒÙ„ Ø­Ø±Ù Ù„Ù‡ Ø¶Ø¯
   - ØªØ¹Ø§Ù…Ø¯ Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯: Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯ ØªØªØ¹Ø§Ù…Ø¯ ÙÙŠ Ø§Ù„ÙØ¶Ø§Ø¡ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ
   - Ù†Ø¸Ø±ÙŠØ© Ø§Ù„Ø®ÙŠÙˆØ·: Ø§Ù„Ø­Ø±ÙˆÙ Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ø®ÙŠÙˆØ· Ù…Ø¹Ù†ÙˆÙŠØ©

Ø§Ù„Ù…Ø·ÙˆØ±: Ø¨Ø§Ø³Ù„ ÙŠØ­ÙŠÙ‰ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡
"""

import sys
import os
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
import math

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from extensions.bayan_baserah_bridge import (
    BayanBaserahBridge, LetterShapeType, 
    LETTER_SHAPE_EQUATIONS, SHAPE_MEANING_BRIDGE
)

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…Ù† Ø¨ÙŠØ§Ù†
try:
    from bayan.bayan.letter_semiotics.inference_engine import ARABIC_SHAPE_MEANINGS
    BAYAN_AVAILABLE = True
except ImportError:
    BAYAN_AVAILABLE = False
    ARABIC_SHAPE_MEANINGS = {}


@dataclass
class SemanticVector:
    """Ù…ØªØ¬Ù‡ Ø¯Ù„Ø§Ù„ÙŠ Ù„Ù„Ø­Ø±Ù ÙÙŠ Ø§Ù„ÙØ¶Ø§Ø¡ Ø§Ù„Ù…Ø¹Ù†ÙˆÙŠ"""
    letter: str
    x: float = 0.0  # Ø§Ù„Ø¨Ø¹Ø¯ Ø§Ù„Ø£ÙÙ‚ÙŠ (Ù…Ø§Ø¯ÙŠ â† Ù†ÙØ³ÙŠ)
    y: float = 0.0  # Ø§Ù„Ø¨Ø¹Ø¯ Ø§Ù„Ø¹Ù…ÙˆØ¯ÙŠ (Ø³Ù„Ø¨ÙŠ â† Ø¥ÙŠØ¬Ø§Ø¨ÙŠ)
    z: float = 0.0  # Ø§Ù„Ø¨Ø¹Ø¯ Ø§Ù„Ø¹Ù…Ù‚ÙŠ (Ø³Ø·Ø­ÙŠ â† Ø¹Ù…ÙŠÙ‚)
    magnitude: float = 0.0
    meanings: List[str] = field(default_factory=list)


class VisualSemanticEngine:
    """
    Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¯Ù„Ø§Ù„Ø§Øª Ø§Ù„Ø¨ØµØ±ÙŠØ©
    
    ğŸ§¬ ÙŠØ·Ø¨Ù‚ Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«Ù„Ø§Ø« Ù…Ù† Ø¨ØµÙŠØ±Ø©:
       1. Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙØ± - Ø§Ù†Ø¨Ø«Ø§Ù‚ Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯
       2. ØªØ¹Ø§Ù…Ø¯ Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯ - 90Â° ÙÙŠ Ø§Ù„ÙØ¶Ø§Ø¡
       3. Ø§Ù„Ø®ÙŠÙˆØ· - Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø¹Ù†ÙˆÙŠØ©
    """
    
    def __init__(self):
        self.bridge = BayanBaserahBridge()
        self.semantic_space: Dict[str, SemanticVector] = {}
        self._build_semantic_space()
        print("ğŸ§¬ Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¯Ù„Ø§Ù„Ø§Øª Ø§Ù„Ø¨ØµØ±ÙŠØ©: ØªÙ… Ø§Ù„ØªÙ‡ÙŠØ¦Ø©")
    
    def _build_semantic_space(self):
        """Ø¨Ù†Ø§Ø¡ Ø§Ù„ÙØ¶Ø§Ø¡ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ Ù„Ù„Ø­Ø±ÙˆÙ"""
        # ØªØ­Ø¯ÙŠØ¯ Ù…ÙˆÙ‚Ø¹ ÙƒÙ„ Ø­Ø±Ù ÙÙŠ Ø§Ù„ÙØ¶Ø§Ø¡ Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯
        letter_positions = {
            # Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø­Ù„Ù‚ÙŠØ© (Ø¹Ù…ÙŠÙ‚Ø©ØŒ Ù†ÙØ³ÙŠØ©)
            "Ø§": (0.0, 0.9, 0.9), "Ù‡": (0.1, 0.5, 0.8), "Ø¹": (0.2, 0.7, 0.9),
            "Ø­": (-0.1, 0.6, 0.7), "Øº": (0.3, 0.4, 0.8), "Ø®": (-0.2, 0.3, 0.7),
            
            # Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø´ÙÙ‡ÙŠØ© (Ø³Ø·Ø­ÙŠØ©ØŒ Ù…Ø§Ø¯ÙŠØ©)
            "Ø¨": (-0.8, 0.5, 0.1), "Ù…": (-0.7, 0.8, 0.2), "Ùˆ": (-0.6, 0.4, 0.1),
            "Ù": (-0.9, 0.3, 0.2),
            
            # Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù„Ø³Ø§Ù†ÙŠØ© (Ù…ØªÙˆØ³Ø·Ø©)
            "Øª": (-0.4, 0.4, 0.4), "Ø«": (-0.3, 0.3, 0.4), "Ø¯": (-0.5, 0.5, 0.5),
            "Ø°": (-0.4, 0.4, 0.5), "Ø±": (-0.3, 0.6, 0.4), "Ø²": (-0.2, 0.5, 0.4),
            "Ø³": (-0.5, 0.4, 0.5), "Ø´": (-0.4, 0.5, 0.5), "Øµ": (-0.6, 0.6, 0.6),
            "Ø¶": (-0.5, 0.5, 0.6), "Ø·": (-0.6, 0.7, 0.6), "Ø¸": (-0.5, 0.6, 0.6),
            "Ù„": (-0.2, 0.7, 0.3), "Ù†": (-0.3, 0.6, 0.3),
            
            # Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø­Ù†Ø¬Ø±ÙŠØ©
            "Ù‚": (0.5, 0.5, 0.7), "Ùƒ": (0.4, 0.6, 0.6),
            
            # Ø­Ø±ÙˆÙ Ø£Ø®Ø±Ù‰
            "Ø¬": (0.3, 0.5, 0.6), "ÙŠ": (-0.1, 0.5, 0.3),
        }
        
        for letter, (x, y, z) in letter_positions.items():
            meanings = ARABIC_SHAPE_MEANINGS.get(letter, {}).get("meanings", [])
            magnitude = math.sqrt(x**2 + y**2 + z**2)
            
            self.semantic_space[letter] = SemanticVector(
                letter=letter, x=x, y=y, z=z,
                magnitude=magnitude, meanings=meanings
            )
    
    def apply_zero_duality(self, letter: str) -> Dict[str, Any]:
        """
        ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ© Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙØ±
        
        ğŸ¯ Ø§Ù„Ø­Ø±Ù ÙŠÙ†Ø¨Ø«Ù‚ Ù…Ù† Ø§Ù„ØµÙØ± Ù…Ø¹ Ø¶Ø¯Ù‡
        Î£(+) + Î£(-) = 0
        """
        if letter not in self.semantic_space:
            return {"error": f"Ø§Ù„Ø­Ø±Ù '{letter}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„ÙØ¶Ø§Ø¡ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ"}
        
        vec = self.semantic_space[letter]
        
        # Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø© (Ø§Ù„Ø¶Ø¯)
        opposite_vec = SemanticVector(
            letter=f"Ø¶Ø¯_{letter}",
            x=-vec.x, y=-vec.y, z=-vec.z,
            magnitude=vec.magnitude
        )
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙˆØ§Ø²Ù† Ø§Ù„ÙƒÙˆÙ†ÙŠ
        balance = (vec.x + opposite_vec.x, vec.y + opposite_vec.y, vec.z + opposite_vec.z)
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù‚Ø±Ø¨ Ø­Ø±Ù Ù„Ù„Ø¶Ø¯
        closest_opposite = self._find_closest_letter(opposite_vec)
        
        return {
            "letter": letter,
            "position": (vec.x, vec.y, vec.z),
            "opposite_position": (opposite_vec.x, opposite_vec.y, opposite_vec.z),
            "balance": balance,
            "balance_sum": sum(balance),
            "closest_opposite_letter": closest_opposite,
            "theory": "Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙØ±: ÙƒÙ„ Ø´ÙŠØ¡ ÙŠÙ†Ø¨Ø«Ù‚ Ù…Ù† Ø§Ù„ØµÙØ± Ø¥Ù„Ù‰ Ø¶Ø¯ÙŠÙ† Ù…ØªÙˆØ§Ø²Ù†ÙŠÙ†"
        }
    
    def _find_closest_letter(self, target: SemanticVector) -> str:
        """Ø¥ÙŠØ¬Ø§Ø¯ Ø£Ù‚Ø±Ø¨ Ø­Ø±Ù Ù„Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù…Ø­Ø¯Ø¯"""
        min_distance = float('inf')
        closest = ""
        
        for letter, vec in self.semantic_space.items():
            distance = math.sqrt(
                (vec.x - target.x)**2 + 
                (vec.y - target.y)**2 + 
                (vec.z - target.z)**2
            )
            if distance < min_distance:
                min_distance = distance
                closest = letter
        
        return closest
    
    def apply_perpendicularity(self, letter1: str, letter2: str) -> Dict[str, Any]:
        """
        ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ© ØªØ¹Ø§Ù…Ø¯ Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯
        
        ğŸ¯ Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯ ØªØªØ¹Ø§Ù…Ø¯ (90Â°) Ù„Ù…Ù†Ø¹ Ø§Ù„ÙÙ†Ø§Ø¡ Ø§Ù„Ù…ØªØ¨Ø§Ø¯Ù„
        A âŠ¥ B âŸº AÂ·B = 0
        """
        if letter1 not in self.semantic_space or letter2 not in self.semantic_space:
            return {"error": "Ø£Ø­Ø¯ Ø§Ù„Ø­Ø±ÙÙŠÙ† ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"}
        
        vec1 = self.semantic_space[letter1]
        vec2 = self.semantic_space[letter2]
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¶Ø±Ø¨ Ø§Ù„Ù†Ù‚Ø·ÙŠ (dot product)
        dot_product = vec1.x * vec2.x + vec1.y * vec2.y + vec1.z * vec2.z
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø²Ø§ÙˆÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ù…ØªØ¬Ù‡ÙŠÙ†
        mag1 = vec1.magnitude if vec1.magnitude > 0 else 1
        mag2 = vec2.magnitude if vec2.magnitude > 0 else 1
        cos_angle = dot_product / (mag1 * mag2)
        cos_angle = max(-1, min(1, cos_angle))  # clamp
        angle_rad = math.acos(cos_angle)
        angle_deg = math.degrees(angle_rad)
        
        # Ù‡Ù„ Ù‡Ù…Ø§ Ù…ØªØ¹Ø§Ù…Ø¯Ø§Ù†ØŸ
        is_perpendicular = 80 <= angle_deg <= 100
        
        return {
            "letter1": letter1,
            "letter2": letter2,
            "dot_product": round(dot_product, 4),
            "angle_degrees": round(angle_deg, 2),
            "is_perpendicular": is_perpendicular,
            "relationship": "Ù…ØªØ¹Ø§Ù…Ø¯Ø§Ù† (Ø£Ø¶Ø¯Ø§Ø¯)" if is_perpendicular else "ØºÙŠØ± Ù…ØªØ¹Ø§Ù…Ø¯ÙŠÙ†",
            "theory": "ØªØ¹Ø§Ù…Ø¯ Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯: Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯ ØªØªØ¹Ø§Ù…Ø¯ Ø¨Ø²Ø§ÙˆÙŠØ© 90Â°"
        }

    def apply_filament_theory(self, word: str) -> Dict[str, Any]:
        """
        ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ© Ø§Ù„Ø®ÙŠÙˆØ·

        ğŸ¯ Ø§Ù„Ø­Ø±ÙˆÙ Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ø®ÙŠÙˆØ· Ù…Ø¹Ù†ÙˆÙŠØ© ØºÙŠØ± Ù…Ø±Ø¦ÙŠØ©
        System = Î£(Filaments) + Connections + Evolution
        """
        if not word:
            return {"error": "Ø§Ù„ÙƒÙ„Ù…Ø© ÙØ§Ø±ØºØ©"}

        letters = [l for l in word if l in self.semantic_space]
        if not letters:
            return {"error": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø­Ø±ÙˆÙ Ù…Ø¹Ø±ÙˆÙØ© ÙÙŠ Ø§Ù„ÙƒÙ„Ù…Ø©"}

        # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø®ÙŠÙˆØ· Ø¨ÙŠÙ† Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù…ØªØªØ§Ù„ÙŠØ©
        filaments = []
        total_tension = 0.0

        for i in range(len(letters) - 1):
            vec1 = self.semantic_space[letters[i]]
            vec2 = self.semantic_space[letters[i + 1]]

            # Ø­Ø³Ø§Ø¨ Ø·ÙˆÙ„ Ø§Ù„Ø®ÙŠØ· (Ø§Ù„Ù…Ø³Ø§ÙØ©)
            distance = math.sqrt(
                (vec2.x - vec1.x)**2 +
                (vec2.y - vec1.y)**2 +
                (vec2.z - vec1.z)**2
            )

            # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙˆØªØ± (ÙƒÙ„Ù…Ø§ Ø²Ø§Ø¯Øª Ø§Ù„Ù…Ø³Ø§ÙØ© Ø²Ø§Ø¯ Ø§Ù„ØªÙˆØªØ±)
            tension = distance
            total_tension += tension

            filaments.append({
                "from": letters[i],
                "to": letters[i + 1],
                "length": round(distance, 3),
                "tension": round(tension, 3)
            })

        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙ…Ø§Ø³Ùƒ Ø§Ù„ÙƒÙ„ÙŠ (Ø¹ÙƒØ³ÙŠ Ù…Ø¹ Ø§Ù„ØªÙˆØªØ±)
        cohesion = 1.0 / (1.0 + total_tension) if total_tension > 0 else 1.0

        return {
            "word": word,
            "letters": letters,
            "filaments": filaments,
            "total_tension": round(total_tension, 3),
            "cohesion": round(cohesion, 3),
            "interpretation": self._interpret_cohesion(cohesion),
            "theory": "Ù†Ø¸Ø±ÙŠØ© Ø§Ù„Ø®ÙŠÙˆØ·: Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ø®ÙŠÙˆØ· ØºÙŠØ± Ù…Ø±Ø¦ÙŠØ©"
        }

    def _interpret_cohesion(self, cohesion: float) -> str:
        """ØªÙØ³ÙŠØ± Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙ…Ø§Ø³Ùƒ"""
        if cohesion > 0.7:
            return "ØªÙ…Ø§Ø³Ùƒ Ø¹Ø§Ù„ÙŠ - Ø§Ù„Ø­Ø±ÙˆÙ Ù…ØªÙ‚Ø§Ø±Ø¨Ø© Ù…Ø¹Ù†ÙˆÙŠØ§Ù‹"
        elif cohesion > 0.4:
            return "ØªÙ…Ø§Ø³Ùƒ Ù…ØªÙˆØ³Ø· - ØªÙˆØ§Ø²Ù† Ù…Ø¹Ù†ÙˆÙŠ"
        else:
            return "ØªÙ…Ø§Ø³Ùƒ Ù…Ù†Ø®ÙØ¶ - ØªØ¨Ø§ÙŠÙ† Ù…Ø¹Ù†ÙˆÙŠ (Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù…Ù‚ØµÙˆØ¯Ø§Ù‹)"

    def visualize_word_in_space(self, word: str) -> Dict[str, Any]:
        """
        ØªØµÙˆØ± Ø§Ù„ÙƒÙ„Ù…Ø© ÙÙŠ Ø§Ù„ÙØ¶Ø§Ø¡ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯
        """
        letters = [l for l in word if l in self.semantic_space]

        points = []
        for letter in letters:
            vec = self.semantic_space[letter]
            points.append({
                "letter": letter,
                "x": vec.x,
                "y": vec.y,
                "z": vec.z,
                "meanings": vec.meanings[:2]
            })

        # Ø­Ø³Ø§Ø¨ Ù…Ø±ÙƒØ² Ø§Ù„Ø«Ù‚Ù„
        if points:
            center_x = sum(p["x"] for p in points) / len(points)
            center_y = sum(p["y"] for p in points) / len(points)
            center_z = sum(p["z"] for p in points) / len(points)
        else:
            center_x = center_y = center_z = 0

        return {
            "word": word,
            "points": points,
            "center_of_gravity": {
                "x": round(center_x, 3),
                "y": round(center_y, 3),
                "z": round(center_z, 3)
            },
            "interpretation": self._interpret_center(center_x, center_y, center_z)
        }

    def _interpret_center(self, x: float, y: float, z: float) -> str:
        """ØªÙØ³ÙŠØ± Ù…Ø±ÙƒØ² Ø§Ù„Ø«Ù‚Ù„"""
        parts = []

        if x < -0.3:
            parts.append("Ù…Ø§Ø¯ÙŠ/Ø´ÙÙ‡ÙŠ")
        elif x > 0.3:
            parts.append("Ù†ÙØ³ÙŠ/Ø­Ù„Ù‚ÙŠ")
        else:
            parts.append("Ù…ØªÙˆØ§Ø²Ù†")

        if y > 0.5:
            parts.append("Ø¥ÙŠØ¬Ø§Ø¨ÙŠ")
        elif y < 0.3:
            parts.append("Ù…Ø­Ø§ÙŠØ¯/Ø³Ù„Ø¨ÙŠ")

        if z > 0.5:
            parts.append("Ø¹Ù…ÙŠÙ‚")
        else:
            parts.append("Ø³Ø·Ø­ÙŠ")

        return " - ".join(parts)

    def full_analysis(self, word: str) -> Dict[str, Any]:
        """
        ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„ÙƒÙ„Ù…Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«Ù„Ø§Ø«
        """
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ø³Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        bridge_analysis = self.bridge.word_visual_analysis(word)

        # ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ© Ø§Ù„Ø®ÙŠÙˆØ·
        filament_analysis = self.apply_filament_theory(word)

        # ØªØµÙˆØ± ÙÙŠ Ø§Ù„ÙØ¶Ø§Ø¡
        space_analysis = self.visualize_word_in_space(word)

        # ØªØ­Ù„ÙŠÙ„ Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙØ± Ù„ÙƒÙ„ Ø­Ø±Ù
        duality_results = []
        for letter in word:
            if letter in self.semantic_space:
                result = self.apply_zero_duality(letter)
                if "error" not in result:
                    duality_results.append({
                        "letter": letter,
                        "opposite": result["closest_opposite_letter"]
                    })

        return {
            "word": word,
            "visual_analysis": {
                "meanings": bridge_analysis.get("combined_meanings", [])[:5],
                "harmony": bridge_analysis.get("visual_harmony", 0)
            },
            "filament_theory": {
                "cohesion": filament_analysis.get("cohesion", 0),
                "interpretation": filament_analysis.get("interpretation", "")
            },
            "space_position": space_analysis.get("center_of_gravity", {}),
            "space_interpretation": space_analysis.get("interpretation", ""),
            "dualities": duality_results,
            "summary": self._generate_summary(bridge_analysis, filament_analysis, space_analysis)
        }

    def _generate_summary(self, bridge: Dict, filament: Dict, space: Dict) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ø®Øµ Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
        parts = []

        harmony = bridge.get("visual_harmony", 0)
        if harmony > 0.7:
            parts.append("ØªÙ†Ø§ØºÙ… Ø¨ØµØ±ÙŠ Ø¹Ø§Ù„ÙŠ")

        cohesion = filament.get("cohesion", 0)
        if cohesion > 0.5:
            parts.append("ØªÙ…Ø§Ø³Ùƒ Ù…Ø¹Ù†ÙˆÙŠ Ù‚ÙˆÙŠ")

        interpretation = space.get("interpretation", "")
        if interpretation:
            parts.append(interpretation)

        return " | ".join(parts) if parts else "ØªØ­Ù„ÙŠÙ„ Ù…ØªÙˆØ§Ø²Ù†"


# Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
if __name__ == "__main__":
    engine = VisualSemanticEngine()

    print("\n" + "=" * 60)
    print("ğŸ§¬ Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¯Ù„Ø§Ù„Ø§Øª Ø§Ù„Ø¨ØµØ±ÙŠØ©")
    print("=" * 60)

    # Ø§Ø®ØªØ¨Ø§Ø± Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙØ±
    print("\nâš¡ Ù†Ø¸Ø±ÙŠØ© Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙØ± - Ø­Ø±Ù 'Ø¹':")
    result = engine.apply_zero_duality("Ø¹")
    print(f"   Ø§Ù„Ù…ÙˆÙ‚Ø¹: {result['position']}")
    print(f"   Ø§Ù„Ø¶Ø¯: {result['closest_opposite_letter']}")
    print(f"   Ø§Ù„ØªÙˆØ§Ø²Ù†: {result['balance_sum']}")

    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ¹Ø§Ù…Ø¯
    print("\nğŸ“ Ù†Ø¸Ø±ÙŠØ© ØªØ¹Ø§Ù…Ø¯ Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯ - 'Ø§' Ùˆ 'Ø¨':")
    result = engine.apply_perpendicularity("Ø§", "Ø¨")
    print(f"   Ø§Ù„Ø²Ø§ÙˆÙŠØ©: {result['angle_degrees']}Â°")
    print(f"   Ø§Ù„Ø¹Ù„Ø§Ù‚Ø©: {result['relationship']}")

    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®ÙŠÙˆØ·
    print("\nğŸ§µ Ù†Ø¸Ø±ÙŠØ© Ø§Ù„Ø®ÙŠÙˆØ· - ÙƒÙ„Ù…Ø© 'Ø¨ÙŠØ§Ù†':")
    result = engine.apply_filament_theory("Ø¨ÙŠØ§Ù†")
    print(f"   Ø§Ù„ØªÙ…Ø§Ø³Ùƒ: {result['cohesion']}")
    print(f"   Ø§Ù„ØªÙØ³ÙŠØ±: {result['interpretation']}")

    # ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„
    print("\nğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ - ÙƒÙ„Ù…Ø© 'Ø¹Ù‚Ù„':")
    result = engine.full_analysis("Ø¹Ù‚Ù„")
    print(f"   Ø§Ù„Ù…Ø¹Ø§Ù†ÙŠ: {result['visual_analysis']['meanings']}")
    print(f"   Ø§Ù„ØªÙ…Ø§Ø³Ùƒ: {result['filament_theory']['cohesion']}")
    print(f"   Ø§Ù„Ù…ÙˆÙ‚Ø¹: {result['space_interpretation']}")
    print(f"   Ø§Ù„Ù…Ù„Ø®Øµ: {result['summary']}")

    print("\n" + "=" * 60)
    print("âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±!")
    print("=" * 60)

