"""
ğŸŒ Ù…Ø­ÙˆÙ„ Ø§Ù„Ù„Ù‡Ø¬Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© - Arabic Dialect Adapter
ÙŠØ­ÙˆÙ„ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ù„Ù‡Ø¬Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ø¥Ù„Ù‰ Ø§Ù„ÙØµØ­Ù‰

Converts text from various Arabic dialects to Modern Standard Arabic (MSA)

Ø§Ù„Ù„Ù‡Ø¬Ø§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©:
- Ø§Ù„Ù…ØµØ±ÙŠØ© (Egyptian)
- Ø§Ù„Ø®Ù„ÙŠØ¬ÙŠØ© (Gulf)
- Ø§Ù„Ø´Ø§Ù…ÙŠØ© (Levantine)
- Ø§Ù„Ù…ØºØ±Ø¨ÙŠØ© (Moroccan)
- + Ø£ÙŠ Ù„Ù‡Ø¬Ø© Ù…Ø®ØµØµØ© Ù…Ù† Ù…Ù„ÙØ§Øª JSON
"""

import os
import json
from dataclasses import dataclass
from enum import Enum
from typing import Dict, List, Tuple, Optional
from pathlib import Path


class Dialect(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù„Ù‡Ø¬Ø§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©"""
    STANDARD = "standard"   # Ø§Ù„ÙØµØ­Ù‰
    EGYPTIAN = "egyptian"   # Ù…ØµØ±ÙŠ
    GULF = "gulf"          # Ø®Ù„ÙŠØ¬ÙŠ
    LEVANTINE = "levantine" # Ø´Ø§Ù…ÙŠ
    MOROCCAN = "moroccan"   # Ù…ØºØ±Ø¨ÙŠ


@dataclass
class ConversionResult:
    """Ù†ØªÙŠØ¬Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù„Ù‡Ø¬Ø©"""
    original: str           # Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ
    converted: str          # Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø­ÙˆÙ„
    dialect: Dialect        # Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ÙƒØªØ´ÙØ©
    confidence: float       # Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø© (0-1)
    changes: List[Tuple[str, str]]  # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª (Ù‚Ø¨Ù„ØŒ Ø¨Ø¹Ø¯)


class DialectAdapter:
    """
    Ù…Ø­ÙˆÙ„ Ø§Ù„Ù„Ù‡Ø¬Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
    ÙŠÙƒØªØ´Ù Ø§Ù„Ù„Ù‡Ø¬Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ ÙˆÙŠØ­ÙˆÙ„Ù‡Ø§ Ù„Ù„ÙØµØ­Ù‰
    """
    
    # Ù‚ÙˆØ§Ù…ÙŠØ³ Ø§Ù„Ù„Ù‡Ø¬Ø§Øª: ÙƒÙ„Ù…Ø©_Ø¹Ø§Ù…ÙŠØ© -> ÙƒÙ„Ù…Ø©_ÙØµØ­Ù‰
    DIALECTS: Dict[str, Dict[str, str]] = {
        "egyptian": {
            # Ø§Ù„Ø£ÙØ¹Ø§Ù„
            "Ø¹Ø§ÙŠØ²": "ÙŠØ±ÙŠØ¯", "Ø¹Ø§ÙˆØ²": "ÙŠØ±ÙŠØ¯", "Ø¹Ø§ÙˆØ²Ø©": "ØªØ±ÙŠØ¯",
            "Ø±Ø§Ø­": "Ø°Ù‡Ø¨", "Ù…Ø´ÙŠ": "Ø°Ù‡Ø¨", "Ø¬Ù‡": "Ø¬Ø§Ø¡", "Ø¬Øª": "Ø¬Ø§Ø¡Øª",
            "Ø´Ø§Ù": "Ø±Ø£Ù‰", "Ù‚Ø§Ù„": "Ù‚Ø§Ù„", "Ø¹Ù…Ù„": "ÙØ¹Ù„",
            "Ø§ÙƒÙ„": "Ø£ÙƒÙ„", "Ø´Ø±Ø¨": "Ø´Ø±Ø¨", "Ù†Ø§Ù…": "Ù†Ø§Ù…",
            # Ø§Ù„Ø¶Ù…Ø§Ø¦Ø± ÙˆØ§Ù„Ø¥Ø´Ø§Ø±Ø©
            "Ø¯Ù‡": "Ù‡Ø°Ø§", "Ø¯ÙŠ": "Ù‡Ø°Ù‡", "Ø¯ÙˆÙ„": "Ù‡Ø¤Ù„Ø§Ø¡",
            "Ø§Ù†Ø§": "Ø£Ù†Ø§", "Ø§Ù†Øª": "Ø£Ù†Øª", "Ù‡Ùˆ": "Ù‡Ùˆ", "Ù‡ÙŠ": "Ù‡ÙŠ",
            # Ø§Ù„Ø¸Ø±ÙˆÙ
            "Ø§Ù…Ø¨Ø§Ø±Ø­": "Ø£Ù…Ø³", "Ø¯Ù„ÙˆÙ‚ØªÙŠ": "Ø§Ù„Ø¢Ù†", "Ø¨ÙƒØ±Ù‡": "ØºØ¯Ø§Ù‹",
            "ÙƒØ¯Ù‡": "Ù‡ÙƒØ°Ø§", "Ù„ÙŠÙ‡": "Ù„Ù…Ø§Ø°Ø§",
            # Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù…
            "Ø§Ø²Ø§ÙŠ": "ÙƒÙŠÙ", "Ø¥ÙŠÙ‡": "Ù…Ø§Ø°Ø§", "ÙÙŠÙ†": "Ø£ÙŠÙ†", "Ù…ÙŠÙ†": "Ù…Ù†",
            # ØµÙØ§Øª ÙˆÙ…ØªÙØ±Ù‚Ø§Øª
            "ÙƒÙˆÙŠØ³": "Ø¬ÙŠØ¯", "Ø­Ù„Ùˆ": "Ø¬Ù…ÙŠÙ„", "ÙˆØ­Ø´": "Ø³ÙŠØ¡",
            "Ø§ÙˆÙŠ": "Ø¬Ø¯Ø§Ù‹", "Ø®Ø§Ù„Øµ": "ØªÙ…Ø§Ù…Ø§Ù‹", "Ø¨ØªØ§Ø¹": "Ø®Ø§Øµ_Ø¨Ù€",
        },
        "gulf": {
            # Ø§Ù„Ø£ÙØ¹Ø§Ù„
            "ÙŠØ¨ÙŠ": "ÙŠØ±ÙŠØ¯", "Ø§Ø¨ÙŠ": "Ø£Ø±ÙŠØ¯", "ØªØ¨ÙŠ": "ØªØ±ÙŠØ¯", "ÙŠØ¨ÙˆÙ†": "ÙŠØ±ÙŠØ¯ÙˆÙ†",
            "Ø±Ø§Ø­": "Ø°Ù‡Ø¨", "ÙŠØ±ÙˆØ­": "ÙŠØ°Ù‡Ø¨", "Ø¬Ø§": "Ø¬Ø§Ø¡",
            "Ø´Ø§Ù": "Ø±Ø£Ù‰", "ÙŠØ´ÙˆÙ": "ÙŠØ±Ù‰", "Ø³ÙˆÙ‰": "ÙØ¹Ù„", "ÙŠØ³ÙˆÙŠ": "ÙŠÙØ¹Ù„",
            # Ø§Ù„Ø¶Ù…Ø§Ø¦Ø±
            "Ù‡Ø°ÙŠ": "Ù‡Ø°Ù‡", "Ø°Ø§": "Ù‡Ø°Ø§", "Ù‡Ø°ÙˆÙ„": "Ù‡Ø¤Ù„Ø§Ø¡",
            # Ø§Ù„Ø¸Ø±ÙˆÙ
            "Ø§Ù„Ø­ÙŠÙ†": "Ø§Ù„Ø¢Ù†", "ØªÙˆÙ‡": "Ù„Ù„ØªÙˆ", "Ø¨Ø§Ú†Ø±": "ØºØ¯Ø§Ù‹", "Ø§Ù…Ø³": "Ø£Ù…Ø³",
            # Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù…  
            "Ø´Ù„ÙˆÙ†": "ÙƒÙŠÙ", "ÙˆÙŠÙ†": "Ø£ÙŠÙ†", "Ø´Ù†Ùˆ": "Ù…Ø§Ø°Ø§", "Ù…Ù†Ùˆ": "Ù…Ù†",
            "Ù„ÙŠØ´": "Ù„Ù…Ø§Ø°Ø§",
            # ØµÙØ§Øª
            "Ø²ÙŠÙ†": "Ø¬ÙŠØ¯", "ÙˆØ§Ø¬Ø¯": "ÙƒØ«ÙŠØ±", "ÙˆØ§ÙŠØ¯": "ÙƒØ«ÙŠØ± Ø¬Ø¯Ø§Ù‹",
            "Ù…Ø¨": "Ù„ÙŠØ³", "Ø¬Ø°ÙŠ": "Ù‡ÙƒØ°Ø§", "Ú†Ø°ÙŠ": "Ù‡ÙƒØ°Ø§",
        },
        "levantine": {
            # Ø§Ù„Ø£ÙØ¹Ø§Ù„
            "Ø¨Ø¯ÙŠ": "Ø£Ø±ÙŠØ¯", "Ø¨Ø¯Ùˆ": "ÙŠØ±ÙŠØ¯", "Ø¨Ø¯Ù‡Ø§": "ØªØ±ÙŠØ¯", "Ø¨Ø¯Ù‡Ù…": "ÙŠØ±ÙŠØ¯ÙˆÙ†",
            "Ø±Ø§Ø­": "Ø°Ù‡Ø¨", "Ø§Ø¬Ø§": "Ø¬Ø§Ø¡", "Ø§Ø¬Øª": "Ø¬Ø§Ø¡Øª",
            "Ø´Ø§Ù": "Ø±Ø£Ù‰", "Ø­ÙƒÙ‰": "ØªØ­Ø¯Ø«", "Ø¹Ù…Ù„": "ÙØ¹Ù„",
            # Ø§Ù„Ø¶Ù…Ø§Ø¦Ø±
            "Ù‡Ø§Ø¯": "Ù‡Ø°Ø§", "Ù‡Ø§ÙŠ": "Ù‡Ø°Ù‡", "Ù‡Ø¯ÙˆÙ„": "Ù‡Ø¤Ù„Ø§Ø¡",
            # Ø§Ù„Ø¸Ø±ÙˆÙ
            "Ù‡Ù„Ù‚": "Ø§Ù„Ø¢Ù†", "Ù‡Ù„Ø£": "Ø§Ù„Ø¢Ù†", "Ø¨ÙƒØ±Ø§": "ØºØ¯Ø§Ù‹", "Ù…Ø¨Ø§Ø±Ø­": "Ø£Ù…Ø³",
            "Ù‡ÙŠÙƒ": "Ù‡ÙƒØ°Ø§",
            # Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù…
            "Ø´Ùˆ": "Ù…Ø§Ø°Ø§", "ÙƒÙŠÙ": "ÙƒÙŠÙ", "ÙˆÙŠÙ†": "Ø£ÙŠÙ†", "Ù…ÙŠÙ†": "Ù…Ù†",
            "Ù„ÙŠØ´": "Ù„Ù…Ø§Ø°Ø§",
            # ØµÙØ§Øª
            "Ù…Ù†ÙŠØ­": "Ø¬ÙŠØ¯", "ÙƒØªÙŠØ±": "ÙƒØ«ÙŠØ±", "Ø´ÙˆÙŠ": "Ù‚Ù„ÙŠÙ„",
            "Ù…Ø´": "Ù„ÙŠØ³", "Ù…Ø§": "Ù„Ø§",
        },
        "moroccan": {
            # Ø§Ù„Ø£ÙØ¹Ø§Ù„
            "Ø¨ØºÙŠØª": "Ø£Ø±ÙŠØ¯", "Ø¨ØºÙ‰": "ÙŠØ±ÙŠØ¯", "Ø¨ØºØ§Øª": "ØªØ±ÙŠØ¯",
            "Ù…Ø´Ù‰": "Ø°Ù‡Ø¨", "Ø¬Ø§": "Ø¬Ø§Ø¡", "Ø¬Ø§Øª": "Ø¬Ø§Ø¡Øª",
            "Ø´Ø§Ù": "Ø±Ø£Ù‰", "Ø¯Ø§Ø±": "ÙØ¹Ù„", "ÙƒÙ„Ø§": "Ø£ÙƒÙ„",
            # Ø§Ù„Ø¶Ù…Ø§Ø¦Ø±
            "Ù‡Ø§Ø¯": "Ù‡Ø°Ø§", "Ù‡Ø§Ø¯ÙŠ": "Ù‡Ø°Ù‡", "Ù‡Ø§Ø¯Ùˆ": "Ù‡Ø¤Ù„Ø§Ø¡",
            # Ø§Ù„Ø¸Ø±ÙˆÙ
            "Ø¯Ø§Ø¨Ø§": "Ø§Ù„Ø¢Ù†", "ØºØ¯Ø§": "ØºØ¯Ø§Ù‹", "Ø§Ù„Ø¨Ø§Ø±Ø­": "Ø£Ù…Ø³",
            "Ù‡ÙƒØ§": "Ù‡ÙƒØ°Ø§", "Ù‡ÙƒØ§Ùƒ": "Ù‡ÙƒØ°Ø§",
            # Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù…
            "ÙƒÙŠÙØ§Ø´": "ÙƒÙŠÙ", "ÙÙŠÙ†": "Ø£ÙŠÙ†", "Ø´ÙƒÙˆÙ†": "Ù…Ù†", "Ø¹Ù„Ø§Ø´": "Ù„Ù…Ø§Ø°Ø§",
            "Ø´Ù†Ùˆ": "Ù…Ø§Ø°Ø§", "Ø§Ø´Ù†Ùˆ": "Ù…Ø§Ø°Ø§",
            # ØµÙØ§Øª
            "Ù…Ø²ÙŠØ§Ù†": "Ø¬ÙŠØ¯", "Ø¨Ø²Ø§Ù": "ÙƒØ«ÙŠØ±", "Ø´ÙˆÙŠØ©": "Ù‚Ù„ÙŠÙ„",
            "Ù…Ø§Ø´ÙŠ": "Ù„ÙŠØ³", "Ø§Ù„Ø¯Ø§Ø±": "Ø§Ù„Ù…Ù†Ø²Ù„", "Ø®Ø§ÙŠØ¨": "Ø³ÙŠØ¡",
        },
    }
    
    # ÙƒÙ„Ù…Ø§Øª Ù…Ù…ÙŠØ²Ø© Ù„ÙƒÙ„ Ù„Ù‡Ø¬Ø© (Ù„Ù„ÙƒØ´Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ)
    DIALECT_MARKERS: Dict[str, List[str]] = {
        "egyptian": ["Ø¹Ø§ÙŠØ²", "Ø¹Ø§ÙˆØ²", "Ø¹Ø§ÙˆØ²Ø©", "Ø§Ø²Ø§ÙŠ", "Ø¯Ù‡", "Ø¯ÙŠ", "Ø¯ÙˆÙ„", "Ø§Ù…Ø¨Ø§Ø±Ø­", "Ø¯Ù„ÙˆÙ‚ØªÙŠ", "ÙƒØ¯Ù‡", "Ø¥ÙŠÙ‡", "ÙÙŠÙ†", "Ù„ÙŠÙ‡", "Ø¨ØªØ§Ø¹"],
        "gulf": ["ÙŠØ¨ÙŠ", "Ø§Ø¨ÙŠ", "ØªØ¨ÙŠ", "ÙˆØ¯ÙŠ", "Ø´Ù„ÙˆÙ†", "ÙˆÙŠÙ†", "Ø§Ù„Ø­ÙŠÙ†", "ÙˆØ§ÙŠØ¯", "Ø²ÙŠÙ†", "Ø´Ù†Ùˆ", "Ù…Ù†Ùˆ", "Ø¬Ø°ÙŠ", "Ù‡Ø°ÙŠ"],
        "levantine": ["Ø¨Ø¯ÙŠ", "Ø¨Ø¯Ùˆ", "Ø¨Ø¯Ù‡Ø§", "Ø¨Ø¯Ù‡Ù…", "Ø´Ùˆ", "Ù‡ÙŠÙƒ", "Ù‡ÙˆÙ†", "Ù‡Ù„Ù‚", "Ù…Ù†ÙŠØ­", "ÙƒØªÙŠØ±", "Ù‡Ø§Ø¯", "Ù‡Ø§ÙŠ", "Ù„ÙŠØ´", "Ù‡Ø¯ÙˆÙ„"],
        "moroccan": ["Ø¨ØºÙŠØª", "Ø¨ØºÙ‰", "Ø¨ØºØ§Øª", "ÙƒÙŠÙØ§Ø´", "Ø¯Ø§Ø¨Ø§", "Ø¨Ø²Ø§Ù", "Ù…Ø²ÙŠØ§Ù†", "Ø´ÙƒÙˆÙ†", "Ø¹Ù„Ø§Ø´", "Ù‡ÙƒØ§", "Ø§Ù„Ø¯Ø§Ø±", "Ø®Ø§ÙŠØ¨"],
    }
    
    def __init__(self, load_json_dialects: bool = True):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø­ÙˆÙ„"""
        # Ø¨Ù†Ø§Ø¡ ÙÙ‡Ø±Ø³ Ø¹ÙƒØ³ÙŠ Ù„Ù„ÙƒÙ„Ù…Ø§Øª
        self.word_to_dialect: Dict[str, str] = {}
        for dialect, words in self.DIALECTS.items():
            for word in words:
                self.word_to_dialect[word] = dialect

        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù„Ù‡Ø¬Ø§Øª Ù…Ù† Ù…Ù„ÙØ§Øª JSON
        if load_json_dialects:
            self._load_json_dialects()

    def _load_json_dialects(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù„Ù‡Ø¬Ø§Øª Ù…Ù† Ù…Ù„ÙØ§Øª JSON"""
        dialects_dir = Path(__file__).parent / "dialects"
        if not dialects_dir.exists():
            return

        # ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª JSON
        for json_file in dialects_dir.glob("*.json"):
            try:
                self.load_dialect_file(str(json_file))
            except Exception as e:
                print(f"âš ï¸ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ {json_file.name}: {e}")

        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù„Ù‡Ø¬Ø§Øª Ø§Ù„Ù…Ø®ØµØµØ©
        custom_dir = dialects_dir / "custom"
        if custom_dir.exists():
            for json_file in custom_dir.glob("*.json"):
                try:
                    self.load_dialect_file(str(json_file))
                except Exception as e:
                    print(f"âš ï¸ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ {json_file.name}: {e}")

    def load_dialect_file(self, file_path: str) -> bool:
        """
        ØªØ­Ù…ÙŠÙ„ Ù„Ù‡Ø¬Ø© Ù…Ù† Ù…Ù„Ù JSON

        Args:
            file_path: Ù…Ø³Ø§Ø± Ù…Ù„Ù JSON Ù„Ù„Ù‡Ø¬Ø©

        Returns:
            True Ø¥Ø°Ø§ ØªÙ… Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            code = data.get("code", "")
            if not code:
                return False

            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª
            if "vocabulary" in data:
                if code not in self.DIALECTS:
                    self.DIALECTS[code] = {}
                self.DIALECTS[code].update(data["vocabulary"])

                # ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙÙ‡Ø±Ø³ Ø§Ù„Ø¹ÙƒØ³ÙŠ
                for word in data["vocabulary"]:
                    self.word_to_dialect[word] = code

            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ù…Ù…ÙŠØ²Ø©
            if "markers" in data:
                if code not in self.DIALECT_MARKERS:
                    self.DIALECT_MARKERS[code] = []
                self.DIALECT_MARKERS[code].extend(data["markers"])
                # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
                self.DIALECT_MARKERS[code] = list(set(self.DIALECT_MARKERS[code]))

            return True

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù {file_path}: {e}")
            return False

    def add_dialect(self, code: str, name: str, vocabulary: Dict[str, str],
                    markers: List[str] = None) -> bool:
        """
        Ø¥Ø¶Ø§ÙØ© Ù„Ù‡Ø¬Ø© Ø¬Ø¯ÙŠØ¯Ø© Ø¨Ø±Ù…Ø¬ÙŠØ§Ù‹

        Args:
            code: Ø±Ù…Ø² Ø§Ù„Ù„Ù‡Ø¬Ø© (Ù…Ø«Ù„: sudanese)
            name: Ø§Ø³Ù… Ø§Ù„Ù„Ù‡Ø¬Ø© (Ù…Ø«Ù„: Ø§Ù„Ø³ÙˆØ¯Ø§Ù†ÙŠØ©)
            vocabulary: Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„ÙƒÙ„Ù…Ø§Øª {Ø¹Ø§Ù…ÙŠØ©: ÙØµØ­Ù‰}
            markers: ÙƒÙ„Ù…Ø§Øª Ù…Ù…ÙŠØ²Ø© Ù„Ù„ÙƒØ´Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ

        Returns:
            True Ø¥Ø°Ø§ ØªÙ…Øª Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¨Ù†Ø¬Ø§Ø­
        """
        try:
            self.DIALECTS[code] = vocabulary
            self.DIALECT_MARKERS[code] = markers or list(vocabulary.keys())[:10]

            # ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙÙ‡Ø±Ø³ Ø§Ù„Ø¹ÙƒØ³ÙŠ
            for word in vocabulary:
                self.word_to_dialect[word] = code

            return True
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù„Ù‡Ø¬Ø©: {e}")
            return False

    def save_dialect_to_file(self, code: str, file_path: str = None) -> bool:
        """
        Ø­ÙØ¸ Ù„Ù‡Ø¬Ø© Ø¥Ù„Ù‰ Ù…Ù„Ù JSON

        Args:
            code: Ø±Ù…Ø² Ø§Ù„Ù„Ù‡Ø¬Ø©
            file_path: Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)

        Returns:
            True Ø¥Ø°Ø§ ØªÙ… Ø§Ù„Ø­ÙØ¸ Ø¨Ù†Ø¬Ø§Ø­
        """
        if code not in self.DIALECTS:
            print(f"âŒ Ø§Ù„Ù„Ù‡Ø¬Ø© '{code}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
            return False

        if file_path is None:
            dialects_dir = Path(__file__).parent / "dialects" / "custom"
            dialects_dir.mkdir(parents=True, exist_ok=True)
            file_path = str(dialects_dir / f"{code}.json")

        data = {
            "code": code,
            "vocabulary": self.DIALECTS[code],
            "markers": self.DIALECT_MARKERS.get(code, [])
        }

        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù„Ù‡Ø¬Ø© '{code}' ÙÙŠ {file_path}")
            return True
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ÙØ¸: {e}")
            return False

    def list_dialects(self) -> Dict[str, int]:
        """Ø¹Ø±Ø¶ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù„Ù‡Ø¬Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ù…Ø¹ Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª"""
        return {code: len(words) for code, words in self.DIALECTS.items()}

    def add_word(self, dialect_code: str, dialect_word: str, standard_word: str) -> bool:
        """
        Ø¥Ø¶Ø§ÙØ© ÙƒÙ„Ù…Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ù‡Ø¬Ø©

        Args:
            dialect_code: Ø±Ù…Ø² Ø§Ù„Ù„Ù‡Ø¬Ø©
            dialect_word: Ø§Ù„ÙƒÙ„Ù…Ø© Ø¨Ø§Ù„Ø¹Ø§Ù…ÙŠØ©
            standard_word: Ø§Ù„ÙƒÙ„Ù…Ø© Ø¨Ø§Ù„ÙØµØ­Ù‰
        """
        if dialect_code not in self.DIALECTS:
            self.DIALECTS[dialect_code] = {}

        self.DIALECTS[dialect_code][dialect_word] = standard_word
        self.word_to_dialect[dialect_word] = dialect_code
        return True

    def detect_dialect(self, text: str) -> Tuple[Dialect, float]:
        """
        Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù„Ù‡Ø¬Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ù…Ù† Ø§Ù„Ù†Øµ
        """
        words = text.split()
        dialect_scores: Dict[str, int] = {d: 0 for d in self.DIALECTS.keys()}
        marker_found = False

        for word in words:
            clean_word = word.strip(".,!?ØŒØŸ")
            for dialect, markers in self.DIALECT_MARKERS.items():
                if clean_word in markers:
                    dialect_scores[dialect] += 5
                    marker_found = True

        if not marker_found:
            return Dialect.STANDARD, 1.0

        max_score = max(dialect_scores.values())
        if max_score == 0:
            return Dialect.STANDARD, 1.0

        detected = max(dialect_scores, key=dialect_scores.get)
        confidence = min(max_score / (len(words) * 0.5), 1.0)
        return Dialect(detected), confidence

    def convert_to_standard(self, text: str, dialect: Optional[str] = None) -> ConversionResult:
        """
        ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ù„Ù‡Ø¬Ø© Ø¥Ù„Ù‰ Ø§Ù„ÙØµØ­Ù‰
        """
        # Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù„Ù‡Ø¬Ø© Ø¥Ø°Ø§ Ù„Ù… ØªØ­Ø¯Ø¯
        if dialect:
            # Ø¯Ø¹Ù… Ø§Ù„Ù„Ù‡Ø¬Ø§Øª Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© (ØºÙŠØ± Ø§Ù„Ù…Ø¹Ø±ÙØ© ÙÙŠ Enum)
            try:
                detected_dialect = Dialect(dialect)
            except ValueError:
                # Ù„Ù‡Ø¬Ø© Ù…Ø®ØµØµØ© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Enum
                if dialect in self.DIALECTS:
                    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚ÙŠÙ…Ø© Ù†ØµÙŠØ© Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Enum
                    dialect_code = dialect
                    confidence = 1.0

                    # Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
                    words = text.split()
                    converted_words = []
                    changes = []
                    dialect_dict = self.DIALECTS.get(dialect_code, {})

                    for word in words:
                        clean_word = word.strip(".,!?ØŒØŸ")
                        if clean_word in dialect_dict:
                            new_word = dialect_dict[clean_word]
                            converted_words.append(new_word)
                            changes.append((clean_word, new_word))
                        else:
                            converted_words.append(word)

                    converted_text = " ".join(converted_words)
                    # Ø¥Ù†Ø´Ø§Ø¡ Ù†ØªÙŠØ¬Ø© Ù…Ø¹ Ù„Ù‡Ø¬Ø© custom
                    return ConversionResult(text, converted_text, Dialect.STANDARD, confidence, changes)
                else:
                    return ConversionResult(text, text, Dialect.STANDARD, 0.0, [])
            confidence = 1.0
        else:
            detected_dialect, confidence = self.detect_dialect(text)

        if detected_dialect == Dialect.STANDARD:
            return ConversionResult(text, text, Dialect.STANDARD, 1.0, [])

        # Ø§Ù„ØªØ­ÙˆÙŠÙ„
        words = text.split()
        converted_words = []
        changes = []
        dialect_dict = self.DIALECTS.get(detected_dialect.value, {})

        for word in words:
            clean_word = word.strip(".,!?ØŒØŸ")
            if clean_word in dialect_dict:
                new_word = dialect_dict[clean_word]
                converted_words.append(new_word)
                changes.append((clean_word, new_word))
            else:
                converted_words.append(word)

        converted_text = " ".join(converted_words)
        return ConversionResult(text, converted_text, detected_dialect, confidence, changes)

    def convert_sentence(self, text: str) -> str:
        """ØªØ­ÙˆÙŠÙ„ Ù…Ø¨Ø§Ø´Ø± - Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø­ÙˆÙ„ ÙÙ‚Ø·"""
        return self.convert_to_standard(text).converted


# Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø©
def to_standard(text: str, dialect: Optional[str] = None) -> str:
    """ØªØ­ÙˆÙŠÙ„ Ø³Ø±ÙŠØ¹ Ù…Ù† Ù„Ù‡Ø¬Ø© Ø¥Ù„Ù‰ ÙØµØ­Ù‰"""
    adapter = DialectAdapter()
    return adapter.convert_to_standard(text, dialect).converted


def detect_dialect(text: str) -> Tuple[str, float]:
    """Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù„Ù‡Ø¬Ø©"""
    adapter = DialectAdapter()
    dialect, conf = adapter.detect_dialect(text)
    return dialect.value, conf

