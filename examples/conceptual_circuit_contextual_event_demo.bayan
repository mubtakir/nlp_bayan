# Demo: Conceptual circuit (Contextualized event)

hybrid {
    import ai.conceptual_circuits as circuits
    import ai.conceptual_language_bridge as lang_bridge
    import ai.conceptual_surface_planner as surface_planner
    import ai.conceptual_sentence_tree as sentence_tree
    import ai.conceptual_surface_realizer as surface_realizer
    import ai.conceptual_lm_bridge as lm_bridge

    # 1) Instantiate the contextualized-event circuit with Arabic conceptual data
    #    مثال: قراءة الطالب في مكتبة المدرسة
    circuit_output = circuits.build_contextualized_event_circuit(
        "حدث_القراءة",          # focus_event_id
        "الطالب",               # actor_id
        "قراءة",                # action_kind
        "مكتبة_المدرسة",        # context_frame
        "background"            # scope_label
    )

    trace = circuit_output["trace"]
    roles = circuit_output["roles"]
    bridges = circuit_output["bridge_structures"]

    print("==== Conceptual circuit demo: Contextualized event ====")
    print("Conceptual trace:")
    print(trace)
    print("")

    print("Roles (per pattern):")
    print(roles)
    print("")

    # 2) Realize a symbolic description sentence about context and scope
    ctx_bridge = bridges["Contextual_DescriptionPattern"]
    ctx_sent = lang_bridge.realize(ctx_bridge)

    print("Symbolic sentence (pre-linguistic):")
    print("Contextual DescriptionSentence:", ctx_sent)
    print("")

    # 3) Build EN/AR surface + LM examples
    examples = []

    ctx_result = lm_bridge.build_lm_examples_for_structure(
        trace,
        roles["ContextualizationPattern"],
        ctx_bridge,
        ["english", "arabic"],
        "neutral"
    )

    res_list = [ctx_result]

    for i in range(len(res_list)):
    {
        res = res_list[i]
        exs = res["examples"]
        for j in range(len(exs)):
        {
            examples.append(exs[j])
        }
    }

    print("Number of LM examples (EN + AR):", len(examples))
    print("")

    print("Example texts:")
    for i in range(len(examples)):
    {
        ex = examples[i]
        print("-", i, ":", ex["text"])
    }
    print("")

    # 4) Train symbolic bigram + trigram LMs over the circuit corpus
    vocab = lm_bridge.build_vocab_from_examples(examples, 1000, 1)
    print("Vocab size:", len(vocab["token_to_id"]))

    bigram_model = lm_bridge.train_bigram_lm_from_examples(examples, 1.0)
    trigram_model = lm_bridge.train_trigram_lm_from_examples(examples, 1.0)

    bigram_scores = lm_bridge.score_examples_with_bigram(examples, bigram_model)
    trigram_scores = lm_bridge.score_examples_with_trigram(examples, trigram_model)

    print("==== Bigram vs Trigram LM scores for contextualized-event circuit examples ====")
    for i in range(len(examples)):
    {
        ex = examples[i]
        sc_bg = bigram_scores[i]
        sc_tri = trigram_scores[i]
        print("Example", i, "text:", ex["text"])
        print("  Bigram:", sc_bg)
        print("  Trigram:", sc_tri)
    }
}

