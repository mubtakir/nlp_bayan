# Demo: Conceptual circuit (Causal link)

hybrid {
    import ai.conceptual_circuits as circuits
    import ai.conceptual_language_bridge as lang_bridge
    import ai.conceptual_surface_planner as surface_planner
    import ai.conceptual_sentence_tree as sentence_tree
    import ai.conceptual_surface_realizer as surface_realizer
    import ai.conceptual_lm_bridge as lm_bridge

    # 1) Instantiate the causal-link circuit with Arabic conceptual data
    #    مثال: مذاكرة تؤدي إلى نجاح
    circuit_output = circuits.build_causal_link_circuit(
        "حدث_مذاكرة",        # cause_event_id
        "حدث_نجاح",          # effect_event_id
        "الطالب",            # cause_actor_id
        "الطالب",            # effect_actor_id
        "مذاكرة",            # cause_action_kind
        "نجاح",              # effect_action_kind
        "سياق_دراسي",        # context_label
        0.9,                   # causal_strength
        0.85                   # conditional_probability
    )

    trace = circuit_output["trace"]
    roles = circuit_output["roles"]
    bridges = circuit_output["bridge_structures"]

    print("==== Conceptual circuit demo: Causal link ====")
    print("Conceptual trace:")
    print(trace)
    print("")

    print("Roles (per pattern):")
    print(roles)
    print("")

    # 2) Realize a symbolic causal sentence
    causal_bridge = bridges["CausalSentencePattern"]
    causal_sent = lang_bridge.realize(causal_bridge)

    print("Symbolic sentence (pre-linguistic):")
    print("CausalSentence:", causal_sent)
    print("")

    # 3) Build EN/AR surface + LM examples from the causal sentence
    examples = []

    causal_result = lm_bridge.build_lm_examples_for_structure(
        trace,
        roles["Probabilistic_Causation"],
        causal_bridge,
        ["english", "arabic"],
        "neutral"
    )

    res_list = [causal_result]

    for i in range(len(res_list)):
    {
        res = res_list[i]
        exs = res["examples"]
        for j in range(len(exs)):
        {
            examples.append(exs[j])
        }
    }

    print("Number of LM examples (EN + AR):", len(examples))
    print("")

    print("Example texts:")
    for i in range(len(examples)):
    {
        ex = examples[i]
        print("-", i, ":", ex["text"])
    }
    print("")

    # 4) Train symbolic bigram + trigram LMs over the circuit corpus
    vocab = lm_bridge.build_vocab_from_examples(examples, 1000, 1)
    print("Vocab size:", len(vocab["token_to_id"]))

    bigram_model = lm_bridge.train_bigram_lm_from_examples(examples, 1.0)
    trigram_model = lm_bridge.train_trigram_lm_from_examples(examples, 1.0)

    bigram_scores = lm_bridge.score_examples_with_bigram(examples, bigram_model)
    trigram_scores = lm_bridge.score_examples_with_trigram(examples, trigram_model)

    print("==== Bigram vs Trigram LM scores for causal-link circuit examples ====")
    for i in range(len(examples)):
    {
        ex = examples[i]
        sc_bg = bigram_scores[i]
        sc_tri = trigram_scores[i]
        print("Example", i, "text:", ex["text"])
        print("  Bigram:", sc_bg)
        print("  Trigram:", sc_tri)
    }
}

