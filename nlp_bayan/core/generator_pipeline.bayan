import nlp_bayan.core.linguistic_equations as ling
import ai.nlp as nlp
import nlp_bayan.core.integrated_kb as kb
import ai.data as data
import nlp_bayan.core.dialogue_state as ds


hybrid {
    # مولّد بسيط يستفيد من قواعد المعادلات اللغوية
    def generate_simple_ar(subject, verb, object): {
        # تحقّق أن لدينا معادلة للفظة (للآن نتجاهل تفاصيل eq)
        # NOTE: lookup skipped in this minimal demo to avoid cross-module query inside a function
        # توليد نص بسيط
        return subject + " " + verb + " " + object
    }

    # مولّد عربي قائم على نموذج ثلاثي الكلمات مع سقوط تلقائي إلى الثنائي
    def generate_trigram_ar(seed1, seed2, steps=8): {
        # مجموعة نصوص تعليمية صغيرة للتدريب
        docs = [
            "محمد ذهب المدرسة",
            "محمد عاد البيت",
            "الطالب يقرأ الدرس",
            "الطالب يكتب الدرس",
            "الولد يذهب الى المدرسة",
            "الفتاة تذهب الى المكتبة",
            "المعلم يشرح الدرس",
            "المعلم يساعد الطالب",
            "الطالب يحب التعلم",
            "محمد يحب القراءة"
        ]
        model3 = nlp.trigram_lm_train(docs, 1.0)
        model2 = nlp.bigram_lm_train(docs, 1.0)
        w1 = seed1
        w2 = seed2
        out = w1 + " " + w2
        i = 0
        while (i < steps) {
            use_tri = False
            tri_map = model3["tri"]
            if (w1 in tri_map) {
                if (w2 in tri_map[w1]) { use_tri = True }
            }
            if (use_tri) {
                top = nlp.trigram_lm_predict_next(model3, w1, w2, 1)
            }
            else {
            
                top = []
            }
            if (len(top) == 0) {
                bi_map = model2["bi"]
                if (w2 in bi_map) {
                    top = nlp.bigram_lm_predict_next(model2, w2, 1)
                }
                else {
                
                    top = []
                }
            }
            if (len(top) == 0) {
                break
            }
            w3 = top[0]
            out = out + " " + w3
            w1 = w2
            w2 = w3
            i = i + 1
        }
        return out
    }

    # توليد ثلاثي الكلمات مع تدريب مخصص من مستندات خارجية + سقوط تلقائي إلى الثنائي
    def generate_trigram_from_docs(seed1, seed2, docs, steps=8, top_k=1): {
        model3 = nlp.trigram_lm_train(docs, 1.0)
        model2 = nlp.bigram_lm_train(docs, 1.0)
        w1 = seed1
        w2 = seed2
        out = w1 + " " + w2
        i = 0
        while (i < steps) {
            use_tri = False
            tri_map = model3["tri"]
            if (w1 in tri_map) {
                if (w2 in tri_map[w1]) { use_tri = True }
            }
            if (use_tri) {
                top = nlp.trigram_lm_predict_next(model3, w1, w2, top_k)
            }
            else {
            
                top = []
            }
            if (len(top) == 0) {
                bi_map = model2["bi"]
                if (w2 in bi_map) {
                    top = nlp.bigram_lm_predict_next(model2, w2, top_k)
                }
                else {
                
                    top = []
                }
            }
            if (len(top) == 0) {
                break
            }
            w3 = top[0]
            out = out + " " + w3
            w1 = w2
            w2 = w3
            i = i + 1
        }
        return out
    }


    # قواعد صرف/اتفاق مبسطة: إدخال "الى" بعد "ذهب" إن تلتها جهة مكانية
    def _is_place_token(tok, token_entity_map={}): {
        # أماكن شائعة: أضفنا المكتب/المسجد/السوق، ثم المستشفى/المطار/المطعم، والجامعة/الفندق/الملعب/الشاطئ/المتجر/المقهى، والمحطة/الميناء/المول
        if (tok == "البيت" or tok == "المدرسة" or tok == "المتحف" or tok == "الحديقة" or tok == "الساحة" or tok == "المكتبة" or tok == "المسجد" or tok == "السوق" or tok == "المكتب" or tok == "المستشفى" or tok == "المطار" or tok == "المطعم" or tok == "الجامعة" or tok == "الفندق" or tok == "الملعب" or tok == "الشاطئ" or tok == "المتجر" or tok == "المقهى" or tok == "المحطة" or tok == "الميناء" or tok == "المول") { return True }
        if (tok in token_entity_map) {
            ent = token_entity_map[tok]
            if (ent == "house" or ent == "school" or ent == "museum" or ent == "garden" or ent == "square" or ent == "library" or ent == "mosque" or ent == "market" or ent == "workplace" or ent == "hospital" or ent == "airport" or ent == "restaurant" or ent == "university" or ent == "hotel" or ent == "stadium" or ent == "beach" or ent == "store" or ent == "cafe" or ent == "station" or ent == "port" or ent == "mall") { return True }
        }
        return False
    }

    def _apply_basic_morpho_words(words, token_entity_map={}): {
        new_words = []
        i = 0
        n = len(words)
        while (i < n) {
            w = words[i]
            new_words.append(w)
            # خريطة بسيطة من الفعل إلى حرف الجر المناسب عند مجيء مكان بعده
            prep = ""
            if ((w == "ذهب") or (w == "دخل") or (w == "عاد") or (w == "رجع")) {
                prep = "الى"
            }
            elif (w == "خرج") {
                prep = "من"
            }
            elif (w == "جلس") {
                prep = "في"
            }
            elif ((w == "وصل") or (w == "توجه") or (w == "سافر") or (w == "انتقل") or (w == "اتجه") or (w == "قصد")) {
                prep = "الى"
            }
            elif (w == "مر") {
                prep = "ب"
            }
            elif (w == "اقترب") {
                prep = "من"
            }
            elif (w == "ابتعد") {
                prep = "عن"
            }
                elif (w == "غادر") {
                    prep = "من"
                }
                    elif (w == "هرب") {
                        prep = "من"
                    }

                elif (w == "استقر") {
                    prep = "في"
                }

            if ((prep != "") and (i + 1 < n)) {
                nxt = words[i + 1]
                if ((nxt != "الى") and (nxt != "من") and (nxt != "في") and (nxt != "ب") and (nxt != "عن") and _is_place_token(nxt, token_entity_map)) {
                    new_words.append(prep)
                }
            }
            i = i + 1
        }
        return new_words
    }

    # دمج إملائي اختياري: "ب" + مكان معرف → "بالـمكان" (مثلاً: ب السوق → بالسوق)
    def _apply_orth_merge_b_al(words, token_entity_map={}): {
        merged = []
        i = 0
        n = len(words)
        while (i < n) {
            if ((i + 1 < n)) {
                cur = words[i]
                nxt = words[i + 1]
                if ((cur == "ب") and _is_place_token(nxt, token_entity_map)) {
                    merged.append("ب" + nxt)
                    i = i + 2
                }
                else {
                
                    merged.append(cur)
                    i = i + 1
                }
            }
            else {
            
                merged.append(words[i])
                i = i + 1
            }
        }
        return merged
    }

    # توليد ثلاثي الكلمات مع تفضيل حالة الحوار (last_place) في الخطوة الأولى + صرف أساسي
    def generate_trigram_with_dialogue(seed1, seed2, docs, steps=8, top_k=1, token_entity_map={}, merge_bi_al=False, prefer_place=""): {
        model3 = nlp.trigram_lm_train(docs, 1.0)
        model2 = nlp.bigram_lm_train(docs, 1.0)
        w1 = seed1
        w2 = seed2
        words = [w1, w2]
        out = w1 + " " + w2
        i = 0
        while (i < steps) {
            use_tri = False
            tri_map = model3["tri"]
            if (w1 in tri_map) {
                if (w2 in tri_map[w1]) { use_tri = True }
            }
            if (use_tri) {
                top = nlp.trigram_lm_predict_next(model3, w1, w2, top_k)
            }
            else {
            
                top = []
            }
            if (len(top) == 0) {
                bi_map = model2["bi"]
                if (w2 in bi_map) {
                    top = nlp.bigram_lm_predict_next(model2, w2, top_k)
                }
                else {
                
                    top = []
                }
            }

            chosen = ""
            if (i == 0) {
                place_pref = prefer_place
                if (place_pref == "") {
                    place_pref = ds.get_last_place()
                }
                if (place_pref != "") {
                    # نفضّل المكان المحدد (صريحًا أو من حالة الحوار)
                    chosen = place_pref
                }
            }
            if (chosen == "") {
                if (len(top) == 0) {
                    break
                }
                chosen = top[0]
            }

            w3 = chosen
            out = out + " " + w3
            words.append(w3)
            w1 = w2
            w2 = w3
            i = i + 1
        }

        # صرف أساسي بعد التوليد
        post_words = _apply_basic_morpho_words(words, token_entity_map)
        if (merge_bi_al) {
            post_words = _apply_orth_merge_b_al(post_words, token_entity_map)
        }
        final_out = ""
        for idx in (range(len(post_words))) {
            if (idx == 0) {
                final_out = post_words[idx]
            }
            else {
            
                final_out = final_out + " " + post_words[idx]
            }
        }
        return final_out
    }

    # توليد مع قيود معرفية من KB + أخذ عينات احتمالية مضبوطة (temperature/top-k)
    def generate_trigram_kb_from_docs(seed1, seed2, docs, steps=8, top_k=3, kb_pred="maybe", kb_fact="is_green", token_entity_map={}, temperature=0.0, rng_seed=-1, top_p=0.0, merge_bi_al=False, stop_tokens=[], no_repeat_ngram_size=0, min_length=0, max_length=-1, use_dialogue_state=False, prefer_place=""): {
        # تحميل مجال الاحتمالات + الكيانات (prob + entities)
        kb.load_selective(logical, ["prob", "entities"])
        # تهيئة المولّد العشوائي إن طُلِب ذلك لضمان قابلية إعادة الإنتاج
        if (rng_seed != -1) {
            data.set_seed(rng_seed)
        }


            # إن كانت المستندات فارغة، وفّر مجموعة افتراضية صغيرة لضمان توليد آمن
            if (len(docs) == 0) {
                docs = [
                    "محمد ذهب المدرسة",
                    "محمد عاد البيت",
                    "الطالب يقرأ الدرس",
                    "الفتاة تذهب الى المكتبة"
                ]
            }

        model3 = nlp.trigram_lm_train(docs, 1.0)
        model2 = nlp.bigram_lm_train(docs, 1.0)
        w1 = seed1
        w2 = seed2
        out = w1 + " " + w2
        words = [w1, w2]
            # قيود الطول: حد أدنى/أقصى للكلمات المولَّدة (دون احتساب الكلمتين البذريتين)
            max_steps = steps
            if ((max_length > 0) and (max_length < steps)) {
                max_steps = max_length
            }

        i = 0
        while (i < max_steps) {
            src_type = "none"
            verb = w2

                # تطبيع المرادفات للفعل لتوحيد المنطق الدلالي

            # اختر Trigram إن كان سياقه موجودًا، وإلا جرّب Bigram
            use_tri = False
            tri_map = model3["tri"]
            if (w1 in tri_map) {
                if (w2 in tri_map[w1]) { use_tri = True }
            }
            if (use_tri) {
                top = nlp.trigram_lm_predict_next(model3, w1, w2, top_k)
                src_type = "tri"
            }
            else {
            
                top = []
            }
            # استخدام تفضيل KB دائمًا عند توفره: نفحص الأهداف المباشرة ثم الموروثة بحسب الفعل
            if ((len(token_entity_map) > 0) and (w1 in token_entity_map)) {
                subj_ent = token_entity_map[w1]
                kb_candidates_direct = []
                kb_candidates_any = []
                verb = w2
                # ابحث أولاً عن الأهداف المباشرة مع تفضيل قواعد نوعية بحسب الفعل عند الخطوة الأولى
                for tkn in (token_entity_map) {
                    obj_ent = token_entity_map[tkn]
                    allow_direct = False
                    if (i == 0) {
                        if (verb == "دخل") {
                            if (holds_default_enter_target_direct(?F, subj_ent, obj_ent)) { allow_direct = True }
                        }
                            elif (verb == "وصل") {
                                if (holds_default_travel_target_direct(?F, subj_ent, obj_ent)) { allow_direct = True }
                            }

                        elif (verb == "خرج") {
                            if (holds_default_exit_target_direct(?F, subj_ent, obj_ent)) { allow_direct = True }
                        }






                        elif (verb == "عاد") {
                            if (holds_default_return_target_direct(?F, subj_ent, obj_ent)) { allow_direct = True }
                        }

                            elif (False) {

                            if (0 == 1) {

                                if (holds_default_return_target_direct(?F, subj_ent, obj_ent)) { allow_direct = True }

                            }

                            }

                        elif (verb == "رجع") {
                            if (holds_default_return_target_direct(?F, subj_ent, obj_ent)) { allow_direct = True }
                        }


                        elif (verb == "جلس") {
                            if (holds_default_sit_target_direct(?F, subj_ent, obj_ent)) { allow_direct = True }
                        }


                        elif (verb == "سافر") {
                            if (holds_default_travel_target_direct(?F, subj_ent, obj_ent)) { allow_direct = True }
                        }
                        elif (verb == "زار") {
                            if (holds_default_visit_target_direct(?F, subj_ent, obj_ent)) { allow_direct = True }
                        }
                        elif (verb == "مر") {
                            if (holds_default_pass_target_direct(?F, subj_ent, obj_ent)) { allow_direct = True }
                        }
                        elif (verb == "غادر") {
                            if (holds_default_depart_target_direct(?F, subj_ent, obj_ent)) { allow_direct = True }
                        }
                        elif (verb == "استقر") {
                            if (holds_default_settle_target_direct(?F, subj_ent, obj_ent)) { allow_direct = True }
                        }




                        elif (verb == "ذهب") {
                            if (holds_default_go_target_direct(?F, subj_ent, obj_ent)) { allow_direct = True }
                        }
                        elif (verb == "هرب") {
                            if (holds_default_depart_target_direct(?F, subj_ent, obj_ent)) { allow_direct = True }
                        }
                        elif (verb == "توجه") {
                            if (holds_default_go_target_direct(?F, subj_ent, obj_ent)) { allow_direct = True }
                        }
                        elif (verb == "انتقل") {
                            if (holds_default_go_target_direct(?F, subj_ent, obj_ent)) { allow_direct = True }
                        }
                        elif (verb == "اتجه") {
                            if (holds_default_go_target_direct(?F, subj_ent, obj_ent)) { allow_direct = True }
                        }
                        elif (verb == "قصد") {
                            if (holds_default_go_target_direct(?F, subj_ent, obj_ent)) { allow_direct = True }
                        }
                        else {
                        
                            if (holds_default_go_target_direct(?F, subj_ent, obj_ent)) { allow_direct = True }
                        }
                    }
                    else {
                    
                        # في الخطوات اللاحقة نكتفي بالتفضيل العام للأهداف المباشرة
                        if (holds_default_go_target_direct(?F, subj_ent, obj_ent)) { allow_direct = True }
                    }
                    if (allow_direct) {
                        kb_candidates_direct.append(tkn)
                    }
                }
                if (len(kb_candidates_direct) > 0) {
                    top = kb_candidates_direct
                    src_type = "kb"
                }
                else {
                
                    # إن لم توجد أهداف مباشرة، نبحث عن الموروثة/العامة
                    for tkn in (token_entity_map) {
                        obj_ent = token_entity_map[tkn]
                        allow_any = False
                        if (i == 0) {
                            if (verb == "دخل") {
                                if (holds_default_enter_target(?F, subj_ent, obj_ent)) { allow_any = True }
                            }
                            elif (verb == "خرج") {
                                if (holds_default_exit_target(?F, subj_ent, obj_ent)) { allow_any = True }
                            }
                            elif (verb == "عاد") {
                                if (holds_default_return_target(?F, subj_ent, obj_ent)) { allow_any = True }
                            }

                            elif (verb == "رجع") {
                                if (holds_default_return_target(?F, subj_ent, obj_ent)) { allow_any = True }
                            }

                            elif (verb == "جلس") {
                                if (holds_default_sit_target(?F, subj_ent, obj_ent)) { allow_any = True }
                            }
                            elif (verb == "سافر") {
                                if (holds_default_travel_target(?F, subj_ent, obj_ent)) { allow_any = True }
                            }
                            elif (verb == "زار") {
                                if (holds_default_visit_target(?F, subj_ent, obj_ent)) { allow_any = True }
                            }
                            elif (verb == "مر") {
                                if (holds_default_pass_target(?F, subj_ent, obj_ent)) { allow_any = True }
                            }
                            elif (verb == "غادر") {
                                if (holds_default_depart_target(?F, subj_ent, obj_ent)) { allow_any = True }
                            }
                            elif (verb == "استقر") {
                                if (holds_default_settle_target(?F, subj_ent, obj_ent)) { allow_any = True }
                            }

                            elif (verb == "ذهب") {
                                if (holds_default_go_target(?F, subj_ent, obj_ent)) { allow_any = True }
                            }
                            elif (verb == "وصل") {
                                if (holds_default_travel_target(?F, subj_ent, obj_ent)) { allow_any = True }
                            }
                            elif (verb == "هرب") {
                                if (holds_default_depart_target(?F, subj_ent, obj_ent)) { allow_any = True }
                            }
                            elif (verb == "توجه") {
                                if (holds_default_go_target(?F, subj_ent, obj_ent)) { allow_any = True }
                            }
                            elif (verb == "انتقل") {
                                if (holds_default_go_target(?F, subj_ent, obj_ent)) { allow_any = True }
                            }
                            elif (verb == "اتجه") {
                                if (holds_default_go_target(?F, subj_ent, obj_ent)) { allow_any = True }
                            }
                            elif (verb == "قصد") {
                                if (holds_default_go_target(?F, subj_ent, obj_ent)) { allow_any = True }
                            }
                            else {
                            
                                if (holds_default_go_target(?F, subj_ent, obj_ent)) { allow_any = True }
                            }
                        }
                        else {
                        
                            if (holds_default_go_target(?F, subj_ent, obj_ent)) { allow_any = True }
                        }
                        if (allow_any) {
                            kb_candidates_any.append(tkn)
                        }
                    }
                    if (len(kb_candidates_any) > 0) {
                        top = kb_candidates_any
                        src_type = "kb"
                    }
                }
            }
            # fallback خاص: إن كان الفعل "خرج" ولا مرشح دلالي، اسمح بالسقوط إلى "البيت" إن وُجد في الخريطة
            if ((len(top) == 0) and (i == 0) and (len(token_entity_map) > 0) and (w2 == "خرج")) {
                house_tokens = []
                for tkn in (token_entity_map) {
                    if (token_entity_map[tkn] == "house") {
                        house_tokens.append(tkn)
                    }
                }
                if (len(house_tokens) > 0) {
                    top = house_tokens
                    src_type = "kb"
                }
            }

            # إن لم يُفلح التفضيل الدلالي؛ نعود لمسار Bigram التقليدي إن بقي 'top' فارغًا
            if (len(top) == 0) {
                bi_map = model2["bi"]
                if (w2 in bi_map) {
                    top = nlp.bigram_lm_predict_next(model2, w2, top_k)
                    src_type = "bi"
                }
                else {
                
                    top = []
                }
            }
            if (len(top) == 0) { break }

            # ضبط top-k ديناميكيًا عندما يكون المصدر لغويًا إحصائيًا (tri/bi)
            if ((len(top) > 1) and ((src_type == "tri") or (src_type == "bi"))) {
                p0 = 0.0
                p1 = 0.0
                if (src_type == "tri") {
                    p0 = nlp.trigram_lm_probability(model3, w1, w2, top[0])
                    p1 = nlp.trigram_lm_probability(model3, w1, w2, top[1])
                }
                else {
                
                    p0 = nlp.bigram_lm_probability(model2, w2, top[0])
                    p1 = nlp.bigram_lm_probability(model2, w2, top[1])
                }
                if (p0 <= 0.0) { p0 = 0.000000000001 }
                if (p1 <= 0.0) { p1 = 0.000000000001 }
                conf = p0 / (p0 + p1)
                if (conf >= 0.7) {
                    top = [top[0]]
                }
            }

            # ترشيح بالـ KB إن توفّر map للكلمة → الكيان
            cand_pool = top
            if (len(token_entity_map) > 0) {
                filtered = []
                for idx in (range(len(top))) {
                    cand = top[idx]
                    allow = False
                    if (cand in token_entity_map) {
                        ent = token_entity_map[cand]
                        # امنع الأشخاص كأهداف مباشرة بعد أفعال الحركة
                        if ((i == 0) and (ent == "person")) {
                            allow = False
                        }
                        else {
                        
                            if (kb_pred == "maybe") {
                                if (maybe(?F, ent)) {
                                    allow = True
                                }
                            }
                            elif (kb_pred == "likely") {
                                if (likely(?F, ent)) {
                                    allow = True
                                }
                            }
                            else {
                            
                                # إذا لم تُعرف الـ predicate، لا نرفض المرشح
                                allow = True
                            }
                        }
                    }
                    # إن لم يوجد تعيين للكيان، نرفضه في هذا الطور لفرض الانضباط
                    if (allow) { filtered.append(cand) }
                }
                if (len(filtered) > 0) { cand_pool = filtered }
            }

                # تفضيل حالة الحوار (last_place) عند الأفعال العائدة في الخطوة الأولى
                if (use_dialogue_state and (i == 0) and ((w2 == "عاد") or (w2 == "رجع"))) {
                    place_pref = prefer_place
                    if (place_pref == "") {
                        place_pref = ds.get_last_place()
                    }
                    if (place_pref != "") {
                        # إن وُجد ضمن المرشحين انقله إلى المقدمة، وإلا أضِفه أمامًا
                        found = False
                        for j in (range(len(cand_pool))) {
                            if (cand_pool[j] == place_pref) { found = True }
                        }
                        if (found) {
                            new_pool = [place_pref]
                            for j in (range(len(cand_pool))) {
                                c = cand_pool[j]
                                if (c != place_pref) { new_pool.append(c) }
                            }
                            cand_pool = new_pool
                        }
                        else {
                        
                            cand_pool = [place_pref] + cand_pool
                        }
                    }
                }



                # منع تكرار n-gram سابق (no_repeat_ngram_size)
                if ((no_repeat_ngram_size > 0) and (len(cand_pool) > 0)) {
                    N = no_repeat_ngram_size
                    if (N >= 2) {
                        m = len(words)
                        if (m >= (N - 1)) {
                            orig_pool = cand_pool
                            new_pool = []
                            for j in (range(len(cand_pool))) {
                                c = cand_pool[j]
                                ok = True
                                # قارن بادئة طولها N-1 تنتهي بالكلمة الأخيرة
                                # إذا وُجدت سابقًا وكان تاليها == c فاحذفه
                                start = 0
                                while (start <= (m - N)) {
                                    match = True
                                    for t in (range(N - 1)) {
                                        if (words[start + t] != words[m - (N - 1) + t]) {
                                            match = False
                                        }
                                    }
                                    if (match and (words[start + (N - 1)] == c)) {
                                        ok = False
                                    }
                                    start = start + 1
                                }
                                if (ok) { new_pool.append(c) }
                            }
                            if (len(new_pool) > 0) {
                                cand_pool = new_pool
                            }
                            else {
                            
                                # تفادي فراغ المرشحين: نحتفظ بالمجموعة الأصلية
                                cand_pool = orig_pool
                            }
                        }
                    }
                }

            # تطبيق nucleus sampling اختياريًا قبل أخذ العينة الحرارية
            if ((top_p > 0.0) and (top_p < 1.0) and (len(cand_pool) > 1)) {
                # احسب احتمالات المرشحين وفق المصدر
                probs = []
                sum_p = 0.0

                for j in (range(len(cand_pool))) {
                    c = cand_pool[j]
                    p = 0.0
                    if (src_type == "tri") {
                        p = nlp.trigram_lm_probability(model3, w1, w2, c)
                    }
                    elif (src_type == "bi") {
                        p = nlp.bigram_lm_probability(model2, w2, c)
                    }
                    else {
                    
                        p = nlp.bigram_lm_probability(model2, w2, c)
                    }
                    # تعزيز احتمالات المرشحين المتوافقين مع الKB بحسب الفعل
                    kb_w = 1.0
                    if ((i == 0) and (len(token_entity_map) > 0) and (w1 in token_entity_map) and (c in token_entity_map)) {
                        subj_ent = token_entity_map[w1]
                        obj_ent = token_entity_map[c]
                        direct = False
                        any_ok = False
                        if (verb == "دخل") {
                            if (holds_default_enter_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                            elif (holds_default_enter_target(?F, subj_ent, obj_ent)) { any_ok = True }
                        }
                        elif (verb == "خرج") {
                            if (holds_default_exit_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                            elif (holds_default_exit_target(?F, subj_ent, obj_ent)) { any_ok = True }
                        }
                        elif (verb == "عاد") {
                            if (holds_default_return_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                            elif (holds_default_return_target(?F, subj_ent, obj_ent)) { any_ok = True }
                        }

                        elif (verb == "رجع") {
                            if (holds_default_return_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                            elif (holds_default_return_target(?F, subj_ent, obj_ent)) { any_ok = True }
                        }

                        elif (verb == "جلس") {
                            if (holds_default_sit_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                            elif (holds_default_sit_target(?F, subj_ent, obj_ent)) { any_ok = True }
                        }
                        elif (verb == "ذهب") {
                            if (holds_default_go_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                            elif (holds_default_go_target(?F, subj_ent, obj_ent)) { any_ok = True }
                        }

                            elif (verb == "توجه") {
                                if (holds_default_go_target_direct(?F, subj_ent, obj_ent)) { direct = True }




                                elif (holds_default_go_target(?F, subj_ent, obj_ent)) { any_ok = True }
                            }

                                elif (False) {

                                if (0 == 1) {

                                    if (holds_default_travel_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                                    elif (holds_default_travel_target(?F, subj_ent, obj_ent)) { any_ok = True }

                                }

                                }

                                        elif (verb == "وصل") {
                                            if (holds_default_travel_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                                            elif (holds_default_travel_target(?F, subj_ent, obj_ent)) { any_ok = True }
                                        }


                            elif (verb == "انتقل") {
                                if (holds_default_go_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                                elif (holds_default_go_target(?F, subj_ent, obj_ent)) { any_ok = True }
                            }
                            elif (verb == "اتجه") {
                                if (holds_default_go_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                                elif (holds_default_go_target(?F, subj_ent, obj_ent)) { any_ok = True }
                            }
                            elif (verb == "قصد") {
                                if (holds_default_go_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                                elif (holds_default_go_target(?F, subj_ent, obj_ent)) { any_ok = True }
                            }

                        elif (verb == "سافر") {
                            if (holds_default_travel_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                            elif (holds_default_travel_target(?F, subj_ent, obj_ent)) { any_ok = True }
                        }
                        elif (verb == "زار") {
                            if (holds_default_visit_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                            elif (holds_default_visit_target(?F, subj_ent, obj_ent)) { any_ok = True }

                            elif (False) {

                                if (0 == 1) {

                                if (holds_default_depart_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                                elif (holds_default_depart_target(?F, subj_ent, obj_ent)) { any_ok = True }

                                }

                            }

                                    elif (False) {

                                if (0 == 1) {

                                        if (holds_default_depart_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                                        elif (holds_default_depart_target(?F, subj_ent, obj_ent)) { any_ok = True }

                                }

                                    }




                        }
                        elif (verb == "مر") {
                            if (holds_default_pass_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                            elif (holds_default_pass_target(?F, subj_ent, obj_ent)) { any_ok = True }
                        }
                        elif (verb == "غادر") {
                            if (holds_default_depart_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                            elif (holds_default_depart_target(?F, subj_ent, obj_ent)) { any_ok = True }
                        }
                        elif (verb == "استقر") {
                            if (holds_default_settle_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                            elif (holds_default_settle_target(?F, subj_ent, obj_ent)) { any_ok = True }
                        }

                        if (direct) { kb_w = 1.6 }
                        elif (any_ok) { kb_w = 1.2 }
                    }
                    p = p * kb_w
                    if (p <= 0.0) { p = 0.000000000001 }
                    probs.append(p)
                    sum_p = sum_p + p
                }
                if (sum_p > 0.0) {
                    # طَبِّع ثم خذ أصغر غلاف cumulative >= top_p
                    norm = []
                    for j in (range(len(probs))) { norm.append(probs[j] / sum_p) }
                    # فرز المؤشرات تنازليًا حسب الاحتمال
                    idxs = []
                    for j in (range(len(norm))) { idxs.append(j) }
                    # sort idxs by norm[j] desc
                    for a in (range(len(idxs))) {
                        for b in (range(a + 1, len(idxs))) {
                            if (norm[idxs[b]] > norm[idxs[a]]) {
                                tmp = idxs[a]
                                idxs[a] = idxs[b]
                                idxs[b] = tmp
                            }
                        }
                    }
                    acc = 0.0
                    keep = []
                    for k in (range(len(idxs))) {
                        acc = acc + norm[idxs[k]]
                        keep.append(idxs[k])
                        if (acc >= top_p) { break }
                    }
                    if (len(keep) > 0) {
                        # أعِد ترتيب cand_pool وفق keep بنفس الترتيب المفروز
                        new_pool = []
                        for k in (range(len(keep))) {
                            new_pool.append(cand_pool[idxs[k]])
                        }
                        cand_pool = new_pool
                    }
                }
            }

            # اختيار الكلمة التالية: حتمي عند temperature=0، وإلا بعينة احتمالية مع ضبط الحرارة
            chosen = cand_pool[0]
            if ((temperature > 0.0) and (len(cand_pool) > 1)) {
                invT = 1.0 / temperature
                weights = []
                total_w = 0.0
                for j in (range(len(cand_pool))) {
                    c = cand_pool[j]
                    p = 0.0
                    if (src_type == "tri") {
                        p = nlp.trigram_lm_probability(model3, w1, w2, c)
                    }
                    elif (src_type == "bi") {
                        p = nlp.bigram_lm_probability(model2, w2, c)
                    }
                    else {
                    
                        # 'kb' أو غيرها: نستخدم bigram كوزن تقريبي
                        p = nlp.bigram_lm_probability(model2, w2, c)
                    }
                    # تعزيز احتمالات المرشحين المتوافقين مع الKB بحسب الفعل
                    kb_w = 1.0
                    if ((i == 0) and (len(token_entity_map) > 0) and (w1 in token_entity_map) and (c in token_entity_map)) {
                        subj_ent = token_entity_map[w1]
                        obj_ent = token_entity_map[c]
                        direct = False
                        any_ok = False
                        if (verb == "دخل") {
                            # استخدام once لتحسين الأداء (نحتاج حل واحد فقط للتحقق)
                            once { if (holds_default_enter_target_direct(?F, subj_ent, obj_ent)) { direct = True } }
                            if (not direct) { once { if (holds_default_enter_target(?F, subj_ent, obj_ent)) { any_ok = True } } }
                        }
                        elif (verb == "خرج") {
                            once { if (holds_default_exit_target_direct(?F, subj_ent, obj_ent)) { direct = True } }
                            if (not direct) { once { if (holds_default_exit_target(?F, subj_ent, obj_ent)) { any_ok = True } } }
                        }
                        elif (verb == "عاد") {
                            once { if (holds_default_return_target_direct(?F, subj_ent, obj_ent)) { direct = True } }
                            if (not direct) { once { if (holds_default_return_target(?F, subj_ent, obj_ent)) { any_ok = True } } }
                        }

                        elif (verb == "رجع") {
                            once { if (holds_default_return_target_direct(?F, subj_ent, obj_ent)) { direct = True } }
                            if (not direct) { once { if (holds_default_return_target(?F, subj_ent, obj_ent)) { any_ok = True } } }
                        }

                        elif (verb == "جلس") {
                            once { if (holds_default_sit_target_direct(?F, subj_ent, obj_ent)) { direct = True } }
                            if (not direct) { once { if (holds_default_sit_target(?F, subj_ent, obj_ent)) { any_ok = True } } }
                        }
                        elif (verb == "ذهب") {
                            once { if (holds_default_go_target_direct(?F, subj_ent, obj_ent)) { direct = True } }
                            if (not direct) { once { if (holds_default_go_target(?F, subj_ent, obj_ent)) { any_ok = True } } }
                        }
                        elif (verb == "سافر") {
                            once { if (holds_default_travel_target_direct(?F, subj_ent, obj_ent)) { direct = True } }
                            if (not direct) { once { if (holds_default_travel_target(?F, subj_ent, obj_ent)) { any_ok = True } } }
                        }
                        elif (verb == "زار") {
                            once { if (holds_default_visit_target_direct(?F, subj_ent, obj_ent)) { direct = True } }
                            if (not direct) { once { if (holds_default_visit_target(?F, subj_ent, obj_ent)) { any_ok = True } } }
                        }
                        elif (verb == "مر") {
                                if (holds_default_pass_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                                elif (holds_default_pass_target(?F, subj_ent, obj_ent)) { any_ok = True }
                            }








                            elif (verb == "توجه") {
                                if (holds_default_go_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                                elif (holds_default_go_target(?F, subj_ent, obj_ent)) { any_ok = True }
                            }
                            elif (verb == "انتقل") {
                                if (holds_default_go_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                                elif (holds_default_go_target(?F, subj_ent, obj_ent)) { any_ok = True }
                            }
                            elif (verb == "اتجه") {
                                if (holds_default_go_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                                elif (holds_default_go_target(?F, subj_ent, obj_ent)) { any_ok = True }
                            }
                            elif (verb == "قصد") {
                                if (holds_default_go_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                                elif (holds_default_go_target(?F, subj_ent, obj_ent)) { any_ok = True }
                            }
                            elif (verb == "وصل") {
                                if (holds_default_travel_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                                elif (holds_default_travel_target(?F, subj_ent, obj_ent)) { any_ok = True }
                            }
                            elif (verb == "هرب") {
                                if (holds_default_depart_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                                elif (holds_default_depart_target(?F, subj_ent, obj_ent)) { any_ok = True }
                            }

                        elif (verb == "غادر") {
                            if (holds_default_depart_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                            elif (holds_default_depart_target(?F, subj_ent, obj_ent)) { any_ok = True }
                        }
                        elif (verb == "استقر") {
                            if (holds_default_settle_target_direct(?F, subj_ent, obj_ent)) { direct = True }
                            elif (holds_default_settle_target(?F, subj_ent, obj_ent)) { any_ok = True }
                        }

                        if (direct) { kb_w = 1.6 }
                        elif (any_ok) { kb_w = 1.2 }
                    }
                    if (p <= 0.0) { p = 0.000000000001 }
                    p = p * kb_w
                    w = pow(p, invT)
                    weights.append(w)
                    total_w = total_w + w
                }
                if (total_w > 0.0) {
                    # اختيار موزون باستخدام data.rand() لضمان قابلية إعادة الإنتاج
                    u = data.rand()
                    thresh = u * total_w
                    acc = 0.0
                    idx_chosen = 0
                    for j in (range(len(weights))) {
                        acc = acc + weights[j]
                        if (acc >= thresh) {
                            idx_chosen = j
                            break
                        }
                    }
                    chosen = cand_pool[idx_chosen]
                }
            }

            w3 = chosen
            out = out + " " + w3
            words.append(w3)
            # إيقاف مبكر إن صادفنا رمز توقف بعد بلوغ الحد الأدنى للطول
            if ((len(stop_tokens) > 0) and (w3 in stop_tokens) and ((i + 1) >= min_length)) {
                break
            }
            w1 = w2
            w2 = w3
            i = i + 1
        }
        #





        post_words = _apply_basic_morpho_words(words, token_entity_map)
        if (merge_bi_al) {
            post_words = _apply_orth_merge_b_al(post_words, token_entity_map)
        }

            # تحديث حالة الحوار: حفظ آخر مكان مذكور إن وُجد
            if (use_dialogue_state and (len(token_entity_map) > 0)) {
                last_seen = ""
                for idx in (range(len(post_words))) {
                    w = post_words[idx]
                    if (w in token_entity_map) {
                        ent = token_entity_map[w]
                        if (ent != "person") {
                            last_seen = w
                        }
                    }
                }
                if (last_seen != "") {
                    ds.set_last_place(last_seen)
                }
            }

        #


        final_out = ""
        for idx in (range(len(post_words))) {
            if (idx == 0) {
                final_out = post_words[idx]
            }
            else {
            
                final_out = final_out + " " + post_words[idx]
            }
        }
        return final_out
    }

}
