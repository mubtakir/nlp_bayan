#!/usr/bin/env python3
"""
ğŸ§¬ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø«ÙˆØ±ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„ - Ù†Ø¸Ø§Ù… Ø¨ØµÙŠØ±Ø©
ğŸŒ‰ ÙŠØ¯Ù…Ø¬ Ø¬Ù…ÙŠØ¹ Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù…Ø¹ Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«Ù„Ø§Ø« Ø§Ù„Ø«ÙˆØ±ÙŠØ©
ğŸ“š Ø§Ù„Ù‡Ø¯Ù: Ø¨Ù†Ø§Ø¡ Ù…ÙƒØªØ¨Ø© Ù…Ø¹Ø±ÙÙŠØ© Ø°Ø§ØªÙŠØ© Ù…Ø³ØªÙ‚Ù„Ø© ØªØ¯Ø±ÙŠØ¬ÙŠØ§Ù‹

Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø°Ù‡Ø¨ÙŠØ©:
1. Ø§Ù„Ø¨Ø¯Ø¡ Ø¨Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ© (APIs)
2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø¨Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«ÙˆØ±ÙŠØ©
3. Ø¨Ù†Ø§Ø¡ Ù…ÙƒØªØ¨Ø© Ø°Ø§ØªÙŠØ© ØºÙ†ÙŠØ©
4. Ø§Ù„ØªØ­ÙˆÙ„ Ù„Ù„Ø§Ø³ØªÙ‚Ù„Ø§Ù„ÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø©

Ø§Ù„Ù…Ø·ÙˆØ±: Ø¨Ø§Ø³Ù„ ÙŠØ­ÙŠÙ‰ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡
"""

import json
import sqlite3
import os
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from .knowledge_harvester import KnowledgeHarvester
import hashlib

class RevolutionaryKnowledgeSystem:
    """
    ğŸ§¬ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø«ÙˆØ±ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„
    ÙŠØ¯Ù…Ø¬ Ø¬Ù…ÙŠØ¹ Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù…Ø¹ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«Ù„Ø§Ø«
    """
    
    def __init__(self, db_path: str = "databases/revolutionary_knowledge_system.db"):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø´Ø§Ù…Ù„"""
        self.db_path = db_path
        self.setup_master_database()
        
        # Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„ÙØ±Ø¹ÙŠØ©
        self.harvester = KnowledgeHarvester()
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
        self.total_knowledge_items = 0
        self.external_sources_count = 0
        self.internal_knowledge_count = 0
        
        print("ğŸ§¬âš¡ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø«ÙˆØ±ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„")
        print("   ğŸŒ‰ ÙŠØ¯Ù…Ø¬ Ø¬Ù…ÙŠØ¹ Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø¹Ø±ÙØ©")
        print("   ğŸ“š ÙŠØ·Ø¨Ù‚ Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«Ù„Ø§Ø« Ø§Ù„Ø«ÙˆØ±ÙŠØ©")
        print("   ğŸ¯ Ø§Ù„Ù‡Ø¯Ù: Ø§Ù„Ø§Ø³ØªÙ‚Ù„Ø§Ù„ÙŠØ© Ø§Ù„ØªØ¯Ø±ÙŠØ¬ÙŠØ©")
        
        self.initialize_system()
    
    def setup_master_database(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ÙˆØ­Ø¯
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS unified_knowledge (
                id INTEGER PRIMARY KEY,
                content TEXT NOT NULL,
                source_type TEXT NOT NULL,  -- internal, wikipedia, file
                source_name TEXT NOT NULL,
                category TEXT,
                language TEXT DEFAULT 'ar',
                zero_duality_score REAL,
                perpendicularity_factor REAL,
                filament_connections TEXT,
                confidence_score REAL DEFAULT 0.5,
                usage_count INTEGER DEFAULT 0,
                last_accessed TIMESTAMP,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                revolutionary_id TEXT UNIQUE,
                content_hash TEXT UNIQUE
            )
        """)
        
        # Ø¬Ø¯ÙˆÙ„ Ù…ØªØ¬Ù‡Ø§Øª Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙˆØ­Ø¯
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS unified_word_vectors (
                id INTEGER PRIMARY KEY,
                word TEXT NOT NULL,
                vector_data TEXT,
                source_model TEXT,
                language TEXT DEFAULT 'ar',
                frequency INTEGER DEFAULT 1,
                zero_duality_embedding REAL,
                perpendicularity_embedding REAL,
                filament_embedding TEXT,
                confidence REAL DEFAULT 0.5,
                revolutionary_vector_id TEXT UNIQUE
            )
        """)
        
        # Ø¬Ø¯ÙˆÙ„ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…ØµØ§Ø¯Ø±
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS source_statistics (
                id INTEGER PRIMARY KEY,
                source_type TEXT NOT NULL,
                source_name TEXT NOT NULL,
                total_items INTEGER DEFAULT 0,
                successful_extractions INTEGER DEFAULT 0,
                failed_extractions INTEGER DEFAULT 0,
                average_quality REAL DEFAULT 0.0,
                last_update TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                revolutionary_efficiency REAL DEFAULT 0.0
            )
        """)
        
        conn.commit()
        conn.close()
        print("ğŸ“Š ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©")
    
    def initialize_system(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù… ÙˆØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©"""
        print("\nğŸš€ ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø«ÙˆØ±ÙŠ:")
        
        # 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø­Ù„ÙŠØ©
        print("   ğŸ“š ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø­Ù„ÙŠØ©...")
        self.load_internal_knowledge()
        
        # 2. ÙØ­Øµ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©
        print("   ğŸ”— ÙØ­Øµ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©...")
        self.check_external_sources()
        
        # 3. ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        print("   ğŸ“Š ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª...")
        self.update_system_statistics()
        
        print("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ù†Ø¬Ø§Ø­!")
    
    def load_internal_knowledge(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© Ù…Ù† Ø§Ù„Ø­Ø§ØµØ¯"""
        try:
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù…Ù† Ø§Ù„Ø­Ø§ØµØ¯
            harvester_stats = self.harvester.get_knowledge_stats()
            
            if harvester_stats.get('total_knowledge', 0) == 0:
                # Ø¥Ø°Ø§ Ù„Ù… ØªÙˆØ¬Ø¯ Ù…Ø¹Ø±ÙØ©ØŒ Ù‚Ù… Ø¨Ø­ØµØ§Ø¯Ù‡Ø§
                print("     ğŸŒ¾ Ø­ØµØ§Ø¯ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©...")
                self.harvester.harvest_sample_knowledge()
                self.harvester.harvest_arabic_words()
            
            # Ù†Ø³Ø® Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø¥Ù„Ù‰ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ÙˆØ­Ø¯
            self._sync_harvester_knowledge()
            
            print(f"     âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©")
            
        except Exception as e:
            print(f"     âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©: {e}")
    
    def check_external_sources(self):
        """ÙØ­Øµ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ© Ø§Ù„Ù…ØªØ§Ø­Ø©"""
        external_sources = {
            "wikipedia": True,  # Ù…ØªØ§Ø­ Ø¯Ø§Ø¦Ù…Ø§Ù‹
            "local_files": True  # Ù…ØªØ§Ø­ Ø¯Ø§Ø¦Ù…Ø§Ù‹
        }
        
        available_sources = [source for source, available in external_sources.items() if available]
        print(f"     ğŸ”— Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…ØªØ§Ø­Ø©: {available_sources}")
        
        self.external_sources_count = len(available_sources)
    
    def _sync_harvester_knowledge(self):
        """Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù…Ù† Ø§Ù„Ø­Ø§ØµØ¯ Ø¥Ù„Ù‰ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ÙˆØ­Ø¯"""
        try:
            # Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø§ØµØ¯
            harvester_conn = sqlite3.connect(self.harvester.db_path)
            harvester_cursor = harvester_conn.cursor()
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ø±ÙØ©
            harvester_cursor.execute("""
                SELECT content, source, category, language, 
                       zero_duality_score, perpendicularity_factor, 
                       filament_connections, revolutionary_id
                FROM knowledge_base
            """)
            
            knowledge_items = harvester_cursor.fetchall()
            harvester_conn.close()
            
            # Ø¥Ø¯Ø±Ø§Ø¬ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ÙˆØ­Ø¯
            unified_conn = sqlite3.connect(self.db_path)
            unified_cursor = unified_conn.cursor()
            
            for item in knowledge_items:
                content_hash = hashlib.sha256(item[0].encode()).hexdigest()
                
                unified_cursor.execute("""
                    INSERT OR IGNORE INTO unified_knowledge 
                    (content, source_type, source_name, category, language,
                     zero_duality_score, perpendicularity_factor, 
                     filament_connections, revolutionary_id, content_hash)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    item[0],  # content
                    "internal",  # source_type
                    item[1],  # source_name
                    item[2],  # category
                    item[3],  # language
                    item[4],  # zero_duality_score
                    item[5],  # perpendicularity_factor
                    item[6],  # filament_connections
                    item[7],  # revolutionary_id
                    content_hash
                ))
            
            unified_conn.commit()
            unified_conn.close()
            
            self.internal_knowledge_count = len(knowledge_items)
            
        except Exception as e:
            print(f"     âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©: {e}")
    
    def extract_from_external_source(self, source_type: str, query: str) -> Optional[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±ÙØ© Ù…Ù† Ù…ØµØ¯Ø± Ø®Ø§Ø±Ø¬ÙŠ"""
        try:
            content = None
            
            if source_type == "wikipedia":
                # ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù† ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠØ§ Ù‡Ù†Ø§
                pass
            
            if content:
                # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ÙˆØ­Ø¯
                self._save_external_knowledge(content, source_type, query)
                return content
            
            return None
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù† {source_type}: {e}")
            return None
    
    def _save_external_knowledge(self, content: str, source_type: str, query: str):
        """Ø­ÙØ¸ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† Ù…ØµØ¯Ø± Ø®Ø§Ø±Ø¬ÙŠ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«ÙˆØ±ÙŠØ©
            zero_duality = self._calculate_zero_duality(content)
            perpendicularity = self._calculate_perpendicularity(content)
            filaments = self._calculate_filament_connections(content)
            
            content_hash = hashlib.sha256(content.encode()).hexdigest()
            revolutionary_id = f"ext_{source_type}_{content_hash[:12]}"
            
            cursor.execute("""
                INSERT OR IGNORE INTO unified_knowledge 
                (content, source_type, source_name, category, 
                 zero_duality_score, perpendicularity_factor, 
                 filament_connections, revolutionary_id, content_hash)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                content,
                source_type,
                f"{source_type}_extraction",
                "external_knowledge",
                zero_duality,
                perpendicularity,
                json.dumps(filaments),
                revolutionary_id,
                content_hash
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©: {e}")
    
    def search_unified_knowledge(self, query: str, limit: int = 10) -> List[Dict[str, Any]]:
        """Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ÙˆØ­Ø¯Ø©"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT content, source_type, source_name, category,
                       zero_duality_score, perpendicularity_factor,
                       confidence_score, usage_count
                FROM unified_knowledge 
                WHERE content LIKE ? 
                ORDER BY zero_duality_score DESC, confidence_score DESC
                LIMIT ?
            """, (f"%{query}%", limit))
            
            results = []
            for row in cursor.fetchall():
                results.append({
                    'content': row[0][:200] + "..." if len(row[0]) > 200 else row[0],
                    'source_type': row[1],
                    'source_name': row[2],
                    'category': row[3],
                    'zero_duality_score': row[4],
                    'perpendicularity_factor': row[5],
                    'confidence_score': row[6],
                    'usage_count': row[7]
                })
            
            # ØªØ­Ø¯ÙŠØ« Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
            cursor.execute("""
                UPDATE unified_knowledge 
                SET usage_count = usage_count + 1, 
                    last_accessed = CURRENT_TIMESTAMP
                WHERE content LIKE ?
            """, (f"%{query}%",))
            
            conn.commit()
            conn.close()
            
            return results
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø«: {e}")
            return []
    
    def get_system_statistics(self) -> Dict[str, Any]:
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø´Ø§Ù…Ù„Ø©"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø¹Ø±ÙØ©
            cursor.execute("SELECT COUNT(*) FROM unified_knowledge")
            total_knowledge = cursor.fetchone()[0]
            
            # Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø­Ø³Ø¨ Ø§Ù„Ù…ØµØ¯Ø±
            cursor.execute("""
                SELECT source_type, COUNT(*) 
                FROM unified_knowledge 
                GROUP BY source_type
            """)
            by_source = dict(cursor.fetchall())
            
            # Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø­Ø³Ø¨ Ø§Ù„ÙØ¦Ø©
            cursor.execute("""
                SELECT category, COUNT(*) 
                FROM unified_knowledge 
                GROUP BY category
            """)
            by_category = dict(cursor.fetchall())
            
            # Ù…ØªÙˆØ³Ø· Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©
            cursor.execute("""
                SELECT AVG(zero_duality_score), AVG(confidence_score)
                FROM unified_knowledge
            """)
            avg_quality = cursor.fetchone()
            
            conn.close()
            
            return {
                'total_knowledge': total_knowledge,
                'by_source': by_source,
                'by_category': by_category,
                'average_zero_duality': round(avg_quality[0] or 0, 4),
                'average_confidence': round(avg_quality[1] or 0, 4),
                'external_sources_available': self.external_sources_count,
                'system_status': 'operational'
            }
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª: {e}")
            return {}
    
    def update_system_statistics(self):
        """ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…"""
        stats = self.get_system_statistics()
        self.total_knowledge_items = stats.get('total_knowledge', 0)
        
        print(f"     ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø¹Ø±ÙØ©: {self.total_knowledge_items}")
        print(f"     ğŸ”— Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©: {self.external_sources_count}")
        print(f"     ğŸ“š Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©: {self.internal_knowledge_count}")
    
    # Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«ÙˆØ±ÙŠØ© (Ù†Ø³Ø® Ù…Ø¨Ø³Ø·Ø©)
    def _calculate_zero_duality(self, content: str) -> float:
        words = content.split()
        if not words:
            return 0.0
        avg_length = sum(len(w) for w in words) / len(words)
        return round((avg_length * 0.618) % 1.0, 4)
    
    def _calculate_perpendicularity(self, content: str) -> float:
        sentences = len([s for s in content.split('.') if s.strip()])
        return round((sentences * 90.0) % 180.0 / 180.0, 4)
    
    def _calculate_filament_connections(self, content: str) -> List[str]:
        words = content.split()
        return [f"{w}:{len(w)}" for w in words[:5] if len(w) > 3]

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø´Ø§Ù…Ù„"""
    
    print("ğŸ§¬âš¡ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø«ÙˆØ±ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„ - Ù†Ø¸Ø§Ù… Ø¨ØµÙŠØ±Ø©")
    print("=" * 70)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù…
    system = RevolutionaryKnowledgeSystem()
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    print("\nğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…:")
    stats = system.get_system_statistics()
    print(f"   ğŸ“ˆ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø¹Ø±ÙØ©: {stats.get('total_knowledge', 0)}")
    print(f"   ğŸ”— Ø§Ù„Ù…ØµØ§Ø¯Ø±: {list(stats.get('by_source', {}).keys())}")
    print(f"   ğŸ“‚ Ø§Ù„ÙØ¦Ø§Øª: {list(stats.get('by_category', {}).keys())}")
    print(f"   ğŸ§¬ Ù…ØªÙˆØ³Ø· Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙØ±: {stats.get('average_zero_duality', 0)}")
    print(f"   âš–ï¸ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«Ù‚Ø©: {stats.get('average_confidence', 0)}")
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨Ø­Ø«
    print("\nğŸ” Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ÙˆØ­Ø¯Ø©:")
    search_terms = ["Ø°ÙƒØ§Ø¡", "Ø±ÙŠØ§Ø¶ÙŠØ§Øª", "Ø¹Ø±Ø¨ÙŠØ©"]
    
    for term in search_terms:
        results = system.search_unified_knowledge(term, limit=2)
        print(f"\n   ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† '{term}': {len(results)} Ù†ØªÙŠØ¬Ø©")
        for i, result in enumerate(results, 1):
            print(f"      {i}. {result['content'][:80]}...")
            print(f"         Ø§Ù„Ù…ØµØ¯Ø±: {result['source_type']} | Ø§Ù„Ø«Ù‚Ø©: {result['confidence_score']}")
    
    print(f"\nğŸ‰ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø´Ø§Ù…Ù„ ÙŠØ¹Ù…Ù„ Ø¨ÙƒÙØ§Ø¡Ø©!")
    print("ğŸ§¬ Ø¬Ø§Ù‡Ø² Ù„Ø¨Ù†Ø§Ø¡ Ù…ÙƒØªØ¨Ø© Ù…Ø¹Ø±ÙÙŠØ© Ø«ÙˆØ±ÙŠØ© Ù…Ø³ØªÙ‚Ù„Ø©!")

if __name__ == "__main__":
    main()
