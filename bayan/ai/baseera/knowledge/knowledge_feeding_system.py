#!/usr/bin/env python3
"""
knowledge_feeding_system.py - Ù†Ø¸Ø§Ù… ØªØºØ°ÙŠØ© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨ØµÙŠØ±Ø© Ø§Ù„Ø«ÙˆØ±ÙŠ

ğŸ§  Ù†Ø¸Ø§Ù… Ø´Ø§Ù…Ù„ Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ù„Ù…Ø¹Ø±ÙØ© ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
ğŸ“ ÙŠØ¯Ø¹Ù… Ø£Ù†ÙˆØ§Ø¹ Ù…Ù„ÙØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø© ÙˆÙ…ØµØ§Ø¯Ø± Ù…Ø¹Ø±ÙØ© Ù…Ø®ØªÙ„ÙØ©
ğŸ”„ ØªØ­ÙˆÙŠÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬

ğŸ§¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£ÙÙƒØ§Ø± ÙˆØ§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ù…Ù† Ø¥Ø¨Ø¯Ø§Ø¹ Ø¨Ø§Ø³Ù„ ÙŠØ­ÙŠÙ‰ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡
"""

import os
import json
import csv
import xml.etree.ElementTree as ET
import sqlite3
import pandas as pd
from pathlib import Path
from typing import Dict, List, Any, Optional, Union
from datetime import datetime
from enum import Enum
import uuid
import re

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
try:
    from complete_specialized_databases import CompleteSpecializedDatabases, ThinkingLayerType, LearningSource
    DATABASES_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ ØªØ­Ø°ÙŠØ±: Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©: {e}")
    DATABASES_AVAILABLE = False

try:
    from specialized_knowledge_systems import SpecializedKnowledgeSystem, KnowledgeItem, KnowledgeType, KnowledgeLevel
    KNOWLEDGE_SYSTEM_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ ØªØ­Ø°ÙŠØ±: Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø¹Ø±ÙØ© ØºÙŠØ± Ù…ØªÙˆÙØ±: {e}")
    KNOWLEDGE_SYSTEM_AVAILABLE = False
    # ØªØ¹Ø±ÙŠÙ Ø¨Ø¯ÙŠÙ„ Ù„Ù„ÙØ¦Ø§Øª
    class KnowledgeType:
        MATHEMATICAL = "mathematical"
        SCIENTIFIC = "scientific"
        TECHNICAL = "technical"
        PHILOSOPHICAL = "philosophical"
        GENERAL = "general"

    class KnowledgeLevel:
        BASIC = "basic"
        INTERMEDIATE = "intermediate"
        ADVANCED = "advanced"

class FileType(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©"""
    JSON = "json"
    CSV = "csv"
    TXT = "txt"
    XML = "xml"
    XLSX = "xlsx"
    SQL = "sql"
    MD = "md"
    PDF = "pdf"
    DOCX = "docx"

class KnowledgeCategory(Enum):
    """ÙØ¦Ø§Øª Ø§Ù„Ù…Ø¹Ø±ÙØ©"""
    MATHEMATICAL = "mathematical"
    SCIENTIFIC = "scientific"
    LINGUISTIC = "linguistic"
    HISTORICAL = "historical"
    TECHNICAL = "technical"
    PHILOSOPHICAL = "philosophical"
    CULTURAL = "cultural"
    GENERAL = "general"

class DataSource(Enum):
    """Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    FILE_IMPORT = "file_import"
    DATABASE_IMPORT = "database_import"
    WEB_SCRAPING = "web_scraping"
    MANUAL_INPUT = "manual_input"
    API_IMPORT = "api_import"
    BULK_UPLOAD = "bulk_upload"

class KnowledgeFeedingSystem:
    """
    Ù†Ø¸Ø§Ù… ØªØºØ°ÙŠØ© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø´Ø§Ù…Ù„
    
    ğŸ§  ÙŠØ­ÙˆÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…ØµØ§Ø¯Ø± Ù…Ø®ØªÙ„ÙØ© Ø¥Ù„Ù‰ Ù…Ø¹Ø±ÙØ© Ù…Ù†Ø¸Ù…Ø©
    ğŸ“Š ÙŠØ¯Ø¹Ù… Ø£Ù†ÙˆØ§Ø¹ Ù…Ù„ÙØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø©
    ğŸ”„ ÙŠÙˆØ²Ø¹ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø¹Ù„Ù‰ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
    """
    
    def __init__(self, knowledge_base_path: str = "knowledge_base"):
        self.knowledge_base_path = knowledge_base_path
        self.creation_time = datetime.now()
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©
        os.makedirs(knowledge_base_path, exist_ok=True)
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
        self.total_files_processed = 0
        self.total_knowledge_items = 0
        self.processing_errors = 0
        self.supported_formats = list(FileType)
        
        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª
        self._initialize_components()
        
        # Ø³Ø¬Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        self.processing_log = []
        
        print(f"ğŸ§ ğŸ“š ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø¸Ø§Ù… ØªØºØ°ÙŠØ© Ø§Ù„Ù…Ø¹Ø±ÙØ©")
        print(f"   ğŸ“ Ù…Ø³Ø§Ø± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©: {knowledge_base_path}")
        print(f"   ğŸ“‹ Ø§Ù„ØµÙŠØº Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©: {len(self.supported_formats)}")
    
    def _initialize_components(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…"""
        if DATABASES_AVAILABLE:
            try:
                self.specialized_databases = CompleteSpecializedDatabases()
                print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ®ØµØµØ©")
            except:
                self.specialized_databases = None
                print("âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ®ØµØµØ©")
        else:
            self.specialized_databases = None
            print("âŒ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ®ØµØµØ© ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©")

        if KNOWLEDGE_SYSTEM_AVAILABLE:
            try:
                self.knowledge_system = SpecializedKnowledgeSystem()
                print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ØªØ®ØµØµ")
            except:
                self.knowledge_system = None
                print("âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ØªØ®ØµØµ")
        else:
            self.knowledge_system = None
            print("âŒ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ØªØ®ØµØµ ØºÙŠØ± Ù…ØªÙˆÙØ±")
    
    def detect_file_type(self, file_path: str) -> Optional[FileType]:
        """ÙƒØ´Ù Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù"""
        extension = Path(file_path).suffix.lower()
        
        type_mapping = {
            '.json': FileType.JSON,
            '.csv': FileType.CSV,
            '.txt': FileType.TXT,
            '.xml': FileType.XML,
            '.xlsx': FileType.XLSX,
            '.xls': FileType.XLSX,
            '.sql': FileType.SQL,
            '.md': FileType.MD,
            '.pdf': FileType.PDF,
            '.docx': FileType.DOCX
        }
        
        return type_mapping.get(extension)
    
    def process_file(self, file_path: str, category: KnowledgeCategory = KnowledgeCategory.GENERAL,
                    custom_metadata: Dict[str, Any] = None) -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù…Ù†Ù‡"""
        
        if not os.path.exists(file_path):
            return {"success": False, "error": "Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"}
        
        file_type = self.detect_file_type(file_path)
        if not file_type:
            return {"success": False, "error": "Ù†ÙˆØ¹ Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…"}
        
        print(f"\nğŸ“ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù: {Path(file_path).name}")
        print(f"   ğŸ“‹ Ø§Ù„Ù†ÙˆØ¹: {file_type.value}")
        print(f"   ğŸ·ï¸ Ø§Ù„ÙØ¦Ø©: {category.value}")
        
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù
            if file_type == FileType.JSON:
                data = self._process_json_file(file_path)
            elif file_type == FileType.CSV:
                data = self._process_csv_file(file_path)
            elif file_type == FileType.TXT:
                data = self._process_txt_file(file_path)
            elif file_type == FileType.XML:
                data = self._process_xml_file(file_path)
            elif file_type == FileType.XLSX:
                data = self._process_excel_file(file_path)
            elif file_type == FileType.MD:
                data = self._process_markdown_file(file_path)
            else:
                return {"success": False, "error": f"Ù…Ø¹Ø§Ù„Ø¬ {file_type.value} ØºÙŠØ± Ù…Ø·Ø¨Ù‚ Ø¨Ø¹Ø¯"}
            
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ù…Ø¹Ø±ÙØ© Ù…Ù†Ø¸Ù…Ø©
            knowledge_items = self._convert_to_knowledge(data, category, file_path, custom_metadata)
            
            # Ø­ÙØ¸ Ø§Ù„Ù…Ø¹Ø±ÙØ© ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…
            saved_items = self._save_knowledge_items(knowledge_items)
            
            # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            result = {
                "success": True,
                "file_path": file_path,
                "file_type": file_type.value,
                "category": category.value,
                "items_extracted": len(knowledge_items),
                "items_saved": len(saved_items),
                "processing_time": datetime.now()
            }
            
            self.processing_log.append(result)
            self.total_files_processed += 1
            self.total_knowledge_items += len(saved_items)
            
            print(f"   âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(knowledge_items)} Ø¹Ù†ØµØ± Ù…Ø¹Ø±ÙÙŠ")
            print(f"   ğŸ’¾ ØªÙ… Ø­ÙØ¸ {len(saved_items)} Ø¹Ù†ØµØ±")
            
            return result
            
        except Exception as e:
            self.processing_errors += 1
            error_result = {
                "success": False,
                "file_path": file_path,
                "error": str(e),
                "processing_time": datetime.now()
            }
            self.processing_log.append(error_result)
            print(f"   âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {e}")
            return error_result
    
    def _process_json_file(self, file_path: str) -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù JSON"""
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _process_csv_file(self, file_path: str) -> List[Dict[str, Any]]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù CSV"""
        data = []
        with open(file_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                data.append(dict(row))
        return data
    
    def _process_txt_file(self, file_path: str) -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù Ù†ØµÙŠ"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙÙ‚Ø±Ø§Øª
        paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
        
        return {
            "content": content,
            "paragraphs": paragraphs,
            "word_count": len(content.split()),
            "line_count": len(content.split('\n'))
        }
    
    def _process_xml_file(self, file_path: str) -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù XML"""
        tree = ET.parse(file_path)
        root = tree.getroot()
        
        def xml_to_dict(element):
            result = {}
            if element.text and element.text.strip():
                result['text'] = element.text.strip()
            
            for child in element:
                child_data = xml_to_dict(child)
                if child.tag in result:
                    if not isinstance(result[child.tag], list):
                        result[child.tag] = [result[child.tag]]
                    result[child.tag].append(child_data)
                else:
                    result[child.tag] = child_data
            
            result.update(element.attrib)
            return result
        
        return {root.tag: xml_to_dict(root)}
    
    def _process_excel_file(self, file_path: str) -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù Excel"""
        try:
            # Ù‚Ø±Ø§Ø¡Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£ÙˆØ±Ø§Ù‚
            excel_data = pd.read_excel(file_path, sheet_name=None)
            
            result = {}
            for sheet_name, df in excel_data.items():
                result[sheet_name] = df.to_dict('records')
            
            return result
        except Exception as e:
            print(f"âš ï¸ ØªØ­Ø°ÙŠØ±: ÙØ´Ù„ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© ExcelØŒ Ù…Ø­Ø§ÙˆÙ„Ø© CSV: {e}")
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ù‚Ø±Ø§Ø¡Ø© ÙƒÙ€ CSV
            df = pd.read_csv(file_path)
            return {"data": df.to_dict('records')}
    
    def _process_markdown_file(self, file_path: str) -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù Markdown"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†
        headers = re.findall(r'^#+\s+(.+)$', content, re.MULTILINE)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
        links = re.findall(r'\[([^\]]+)\]\(([^)]+)\)', content)
        
        # ØªÙ‚Ø³ÙŠÙ… Ø¥Ù„Ù‰ Ø£Ù‚Ø³Ø§Ù…
        sections = re.split(r'^#+\s+', content, flags=re.MULTILINE)[1:]
        
        return {
            "content": content,
            "headers": headers,
            "links": links,
            "sections": sections,
            "word_count": len(content.split())
        }
    
    def _convert_to_knowledge(self, data: Any, category: KnowledgeCategory,
                            source_file: str, metadata: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        """ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø¹Ù†Ø§ØµØ± Ù…Ø¹Ø±ÙÙŠØ©"""
        knowledge_items = []
        
        if isinstance(data, dict):
            knowledge_items.extend(self._process_dict_data(data, category, source_file, metadata))
        elif isinstance(data, list):
            knowledge_items.extend(self._process_list_data(data, category, source_file, metadata))
        else:
            # Ø¨ÙŠØ§Ù†Ø§Øª Ù†ØµÙŠØ© Ø¨Ø³ÙŠØ·Ø©
            item = self._create_knowledge_item(
                title=f"Ù…Ø­ØªÙˆÙ‰ Ù…Ù† {Path(source_file).name}",
                content=str(data),
                category=category,
                source_file=source_file,
                metadata=metadata
            )
            knowledge_items.append(item)
        
        return knowledge_items
    
    def _process_dict_data(self, data: Dict[str, Any], category: KnowledgeCategory,
                          source_file: str, metadata: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù†ÙˆØ¹ Dictionary"""
        items = []
        
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ù†Ø§ØµØ± Ù…Ø¹Ø±ÙÙŠØ© Ù…Ù†Ø¸Ù…Ø©
        if 'title' in data and 'content' in data:
            item = self._create_knowledge_item(
                title=data['title'],
                content=data['content'],
                category=category,
                source_file=source_file,
                metadata={**(metadata or {}), **data}
            )
            items.append(item)
        else:
            # ØªØ­ÙˆÙŠÙ„ ÙƒÙ„ Ù…ÙØªØ§Ø­-Ù‚ÙŠÙ…Ø© Ø¥Ù„Ù‰ Ø¹Ù†ØµØ± Ù…Ø¹Ø±ÙÙŠ
            for key, value in data.items():
                if isinstance(value, (str, int, float)):
                    item = self._create_knowledge_item(
                        title=key,
                        content=str(value),
                        category=category,
                        source_file=source_file,
                        metadata=metadata
                    )
                    items.append(item)
                elif isinstance(value, dict):
                    item = self._create_knowledge_item(
                        title=key,
                        content=json.dumps(value, ensure_ascii=False, indent=2),
                        category=category,
                        source_file=source_file,
                        metadata=metadata
                    )
                    items.append(item)
        
        return items
    
    def _process_list_data(self, data: List[Any], category: KnowledgeCategory,
                          source_file: str, metadata: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù†ÙˆØ¹ List"""
        items = []
        
        for i, item_data in enumerate(data):
            if isinstance(item_data, dict):
                items.extend(self._process_dict_data(item_data, category, source_file, metadata))
            else:
                item = self._create_knowledge_item(
                    title=f"Ø¹Ù†ØµØ± {i+1} Ù…Ù† {Path(source_file).name}",
                    content=str(item_data),
                    category=category,
                    source_file=source_file,
                    metadata=metadata
                )
                items.append(item)
        
        return items
    
    def _create_knowledge_item(self, title: str, content: str, category: KnowledgeCategory,
                              source_file: str, metadata: Dict[str, Any] = None) -> Dict[str, Any]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù†ØµØ± Ù…Ø¹Ø±ÙÙŠ"""
        
        # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø¹Ø±ÙØ© ÙˆÙ…Ø³ØªÙˆØ§Ù‡Ø§
        knowledge_type = self._determine_knowledge_type(category, content)
        knowledge_level = self._determine_knowledge_level(content)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª
        tags = self._extract_tags(title, content, category)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ù†ØµØ± Ø§Ù„Ù…Ø¹Ø±ÙÙŠ
        if KNOWLEDGE_SYSTEM_AVAILABLE:
            try:
                item = KnowledgeItem(
                    title=title[:200],  # ØªØ­Ø¯ÙŠØ¯ Ø·ÙˆÙ„ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
                    content=content,
                    knowledge_type=knowledge_type,
                    knowledge_level=knowledge_level,
                    tags=tags,
                    related_equations=[]
                )
                return item
            except:
                pass

        # Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù†ØµØ± Ø¨Ø³ÙŠØ· ÙÙŠ Ø­Ø§Ù„Ø© Ø¹Ø¯Ù… ØªÙˆÙØ± Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
        return {
            "title": title[:200],
            "content": content,
            "category": category.value if hasattr(category, 'value') else str(category),
            "source_file": source_file,
            "metadata": metadata or {},
            "creation_time": datetime.now().isoformat(),
            "knowledge_type": knowledge_type,
            "knowledge_level": knowledge_level,
            "tags": tags
        }
    
    def _determine_knowledge_type(self, category: KnowledgeCategory, content: str) -> KnowledgeType:
        """ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø¹Ø±ÙØ©"""
        try:
            if category == KnowledgeCategory.MATHEMATICAL:
                return KnowledgeType.MATHEMATICAL
            elif category == KnowledgeCategory.SCIENTIFIC:
                return KnowledgeType.SCIENTIFIC
            elif category == KnowledgeCategory.TECHNICAL:
                return KnowledgeType.TECHNICAL
            elif category == KnowledgeCategory.PHILOSOPHICAL:
                return KnowledgeType.PHILOSOPHICAL
            else:
                return KnowledgeType.GENERAL
        except:
            return "general"
    
    def _determine_knowledge_level(self, content: str) -> KnowledgeLevel:
        """ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø¹Ø±ÙØ©"""
        try:
            content_length = len(content)
            if content_length > 1000:
                return KnowledgeLevel.ADVANCED
            elif content_length > 300:
                return KnowledgeLevel.INTERMEDIATE
            else:
                return KnowledgeLevel.BASIC
        except:
            return "basic"
    
    def _extract_tags(self, title: str, content: str, category: KnowledgeCategory) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª"""
        tags = [category.value]
        
        # ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ø´Ø§Ø¦Ø¹Ø©
        keywords = {
            'Ø±ÙŠØ§Ø¶ÙŠØ§Øª': ['Ù…Ø¹Ø§Ø¯Ù„Ø©', 'Ø­Ø³Ø§Ø¨', 'Ø±Ù‚Ù…', 'Ø¯Ø§Ù„Ø©'],
            'Ø¹Ù„ÙˆÙ…': ['ØªØ¬Ø±Ø¨Ø©', 'Ù†Ø¸Ø±ÙŠØ©', 'Ù‚Ø§Ù†ÙˆÙ†', 'Ø¸Ø§Ù‡Ø±Ø©'],
            'ØªÙ‚Ù†ÙŠØ©': ['Ø¨Ø±Ù…Ø¬Ø©', 'Ù†Ø¸Ø§Ù…', 'ØªØ·Ø¨ÙŠÙ‚', 'Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ©'],
            'ÙÙ„Ø³ÙØ©': ['ÙÙƒØ±', 'Ù…ÙÙ‡ÙˆÙ…', 'Ù†Ø¸Ø±ÙŠØ©', 'ØªØ£Ù…Ù„']
        }
        
        text = (title + " " + content).lower()
        for tag, words in keywords.items():
            if any(word in text for word in words):
                tags.append(tag)
        
        return list(set(tags))
    
    def _save_knowledge_items(self, knowledge_items: List[Any]) -> List[str]:
        """Ø­ÙØ¸ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ø¹Ø±ÙÙŠØ© ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…"""
        saved_ids = []
        
        for item in knowledge_items:
            try:
                if self.knowledge_system and hasattr(item, 'title'):
                    # Ø­ÙØ¸ ÙÙŠ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ØªØ®ØµØµ
                    item_id = self.knowledge_system.add_knowledge_item(item)
                    saved_ids.append(item_id)
                
                # Ø­ÙØ¸ ÙÙŠ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ®ØµØµØ©
                if self.specialized_databases:
                    self._distribute_to_specialized_databases(item)
                
            except Exception as e:
                print(f"   âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ø¹Ù†ØµØ±: {e}")
        
        return saved_ids
    
    def _distribute_to_specialized_databases(self, item: Any):
        """ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø¹Ù„Ù‰ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ®ØµØµØ©"""
        try:
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
            if hasattr(item, 'knowledge_type'):
                if 'mathematical' in str(item.knowledge_type).lower():
                    self.specialized_databases.store_learning_for_layer(
                        ThinkingLayerType.MATHEMATICAL, 
                        {"knowledge_item": item.__dict__ if hasattr(item, '__dict__') else item},
                        LearningSource.USER_INTERACTION
                    )
                elif 'linguistic' in str(item.knowledge_type).lower():
                    self.specialized_databases.store_learning_for_layer(
                        ThinkingLayerType.LINGUISTIC,
                        {"knowledge_item": item.__dict__ if hasattr(item, '__dict__') else item},
                        LearningSource.USER_INTERACTION
                    )
        except Exception as e:
            print(f"   âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙˆØ²ÙŠØ¹: {e}")
    
    def process_directory(self, directory_path: str, category: KnowledgeCategory = KnowledgeCategory.GENERAL) -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙŠ Ù…Ø¬Ù„Ø¯"""
        if not os.path.exists(directory_path):
            return {"success": False, "error": "Ø§Ù„Ù…Ø¬Ù„Ø¯ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"}
        
        results = []
        total_files = 0
        successful_files = 0
        
        print(f"\nğŸ“ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¬Ù„Ø¯: {directory_path}")
        
        for root, dirs, files in os.walk(directory_path):
            for file in files:
                file_path = os.path.join(root, file)
                if self.detect_file_type(file_path):
                    total_files += 1
                    result = self.process_file(file_path, category)
                    results.append(result)
                    if result["success"]:
                        successful_files += 1
        
        summary = {
            "success": True,
            "directory": directory_path,
            "total_files": total_files,
            "successful_files": successful_files,
            "failed_files": total_files - successful_files,
            "results": results,
            "processing_time": datetime.now()
        }
        
        print(f"   ğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:")
        print(f"   ğŸ“ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª: {total_files}")
        print(f"   âœ… Ù†Ø¬Ø­: {successful_files}")
        print(f"   âŒ ÙØ´Ù„: {total_files - successful_files}")
        
        return summary
    
    def get_statistics(self) -> Dict[str, Any]:
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…"""
        return {
            "total_files_processed": self.total_files_processed,
            "total_knowledge_items": self.total_knowledge_items,
            "processing_errors": self.processing_errors,
            "supported_formats": [f.value for f in self.supported_formats],
            "success_rate": (self.total_files_processed - self.processing_errors) / max(self.total_files_processed, 1) * 100,
            "creation_time": self.creation_time.isoformat(),
            "last_processing": self.processing_log[-1] if self.processing_log else None
        }


# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
if __name__ == "__main__":
    print("ğŸ§ ğŸ“š Ø§Ø®ØªØ¨Ø§Ø± Ù†Ø¸Ø§Ù… ØªØºØ°ÙŠØ© Ø§Ù„Ù…Ø¹Ø±ÙØ©")
    print("=" * 60)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù…
    feeding_system = KnowledgeFeedingSystem()
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    stats = feeding_system.get_statistics()
    print(f"\nğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…:")
    for key, value in stats.items():
        print(f"   {key}: {value}")
    
    print(f"\nğŸ¯ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¬Ø§Ù‡Ø² Ù„ØªØºØ°ÙŠØ© Ø§Ù„Ù…Ø¹Ø±ÙØ©!")
    print(f"   ğŸ“‹ Ø§Ù„ØµÙŠØº Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©: {', '.join([f.value for f in FileType])}")
    print(f"   ğŸ·ï¸ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©: {', '.join([c.value for c in KnowledgeCategory])}")
