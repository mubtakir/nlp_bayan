#!/usr/bin/env python3
"""
ğŸŒ‰ Ø¬Ø³Ø± Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ© - Ù†Ø¸Ø§Ù… Ø¨ØµÙŠØ±Ø© Ø§Ù„Ø«ÙˆØ±ÙŠ
ğŸ”— Ø±Ø¨Ø· Ù…Ø¤Ù‚Øª Ø¨Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ© Ù…Ø¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØ­ÙØ¸ Ø§Ù„Ù…Ø¹Ø±ÙØ©
ğŸ§¬ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«Ù„Ø§Ø« Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©

Ø§Ù„Ù‡Ø¯Ù: Ø¨Ù†Ø§Ø¡ Ù…ÙƒØªØ¨Ø© Ù…Ø¹Ø±ÙÙŠØ© Ø°Ø§ØªÙŠØ© ØªØ¯Ø±ÙŠØ¬ÙŠØ§Ù‹
Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©: Ø§Ø³ØªØ®Ø±Ø§Ø¬ â†’ ØªØ­Ù„ÙŠÙ„ â†’ Ø­ÙØ¸ â†’ Ø§Ø³ØªÙ‚Ù„Ø§Ù„ÙŠØ©

Ø§Ù„Ù…Ø·ÙˆØ±: Ø¨Ø§Ø³Ù„ ÙŠØ­ÙŠÙ‰ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡
"""

import requests
import json
import sqlite3
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
import hashlib
import time
from datetime import datetime
import os

@dataclass
class KnowledgeEntry:
    """Ù…Ø¯Ø®Ù„ Ù…Ø¹Ø±ÙÙŠ Ù…Ø¹ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«ÙˆØ±ÙŠØ©"""
    content: str
    source: str
    category: str
    language: str
    zero_duality_score: float
    perpendicularity_factor: float
    filament_connections: List[str]
    extraction_date: str
    revolutionary_id: str

class ExternalKnowledgeBridge:
    """
    ğŸŒ‰ Ø¬Ø³Ø± Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©
    ÙŠØ±Ø¨Ø· Ù†Ø¸Ø§Ù… Ø¨ØµÙŠØ±Ø© Ø¨Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ© Ù…Ø¤Ù‚ØªØ§Ù‹
    """
    
    def __init__(self, db_path: str = "databases/external_knowledge.db"):
        """ØªÙ‡ÙŠØ¦Ø© Ø¬Ø³Ø± Ø§Ù„Ù…Ø¹Ø±ÙØ©"""
        self.db_path = db_path
        self.setup_database()
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ
        self.wikipedia_api = "https://ar.wikipedia.org/api/rest_v1"
        
        # Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«ÙˆØ±ÙŠØ©
        self.zero_duality_factor = 0.618
        self.perpendicularity_angle = 90.0
        self.filament_strength = 0.85
        
        print("ğŸŒ‰âš¡ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø³Ø± Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©")
        print("   ğŸ”— Ø¬Ø§Ù‡Ø² Ù„Ù„Ø±Ø¨Ø· Ù…Ø¹ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©")
        print("   ğŸ§¬ Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«Ù„Ø§Ø«: Ù†Ø´Ø·Ø©")
        print("   ğŸ’¾ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØ­ÙØ¸ Ø§Ù„Ù…Ø¹Ø±ÙØ©: Ù…ÙØ¹Ù„")
    
    def extract_from_wikipedia(self, topic: str, language: str = "ar") -> Optional[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±ÙØ© Ù…Ù† ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠØ§"""
        try:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ù‚Ø§Ù„
            search_url = f"https://{language}.wikipedia.org/api/rest_v1/page/summary/{topic}"
            
            response = requests.get(search_url, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                content = data.get('extract', '')
                
                if content:
                    # Ø­ÙØ¸ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
                    knowledge_entry = self._create_knowledge_entry(
                        content=content,
                        source=f"wikipedia_{language}",
                        category="encyclopedia",
                        language=language
                    )
                    
                    self._save_knowledge_entry(knowledge_entry)
                    print(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±ÙØ© Ù…Ù† ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠØ§: {topic}")
                    return content
                else:
                    print(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ù„Ù„Ù…ÙˆØ¶ÙˆØ¹: {topic}")
                    return None
            else:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠØ§: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù…Ù† ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠØ§: {e}")
            return None
    
    def _create_knowledge_entry(self, content: str, source: str, 
                               category: str, language: str) -> KnowledgeEntry:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯Ø®Ù„ Ù…Ø¹Ø±ÙÙŠ Ù…Ø¹ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«ÙˆØ±ÙŠØ©"""
        
        # ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ© Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙØ±
        zero_duality_score = self._calculate_zero_duality(content)
        
        # ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ© ØªØ¹Ø§Ù…Ø¯ Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯
        perpendicularity_factor = self._calculate_perpendicularity(content)
        
        # ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ© Ø§Ù„ÙØªØ§Ø¦Ù„
        filament_connections = self._calculate_filament_connections(content)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¹Ø±Ù Ø«ÙˆØ±ÙŠ
        content_hash = hashlib.sha256(content.encode()).hexdigest()[:16]
        revolutionary_id = f"rev_{source}_{content_hash}"
        
        return KnowledgeEntry(
            content=content,
            source=source,
            category=category,
            language=language,
            zero_duality_score=zero_duality_score,
            perpendicularity_factor=perpendicularity_factor,
            filament_connections=filament_connections,
            extraction_date=datetime.now().isoformat(),
            revolutionary_id=revolutionary_id
        )
    
    def _calculate_zero_duality(self, content: str) -> float:
        """Ø­Ø³Ø§Ø¨ Ù†Ù‚Ø§Ø· Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙØ± Ù„Ù„Ù…Ø­ØªÙˆÙ‰"""
        # ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¨Ø³Ø· Ù„Ù†Ø¸Ø±ÙŠØ© Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙØ±
        char_count = len(content)
        word_count = len(content.split())
        
        if word_count == 0:
            return 0.0
        
        balance_ratio = char_count / word_count
        zero_duality_score = (balance_ratio * self.zero_duality_factor) % 1.0
        
        return round(zero_duality_score, 4)
    
    def _calculate_perpendicularity(self, content: str) -> float:
        """Ø­Ø³Ø§Ø¨ Ø¹Ø§Ù…Ù„ Ø§Ù„ØªØ¹Ø§Ù…Ø¯ Ù„Ù„Ù…Ø­ØªÙˆÙ‰"""
        # ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¨Ø³Ø· Ù„Ù†Ø¸Ø±ÙŠØ© ØªØ¹Ø§Ù…Ø¯ Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯
        sentences = content.split('.')
        sentence_count = len([s for s in sentences if s.strip()])
        
        if sentence_count == 0:
            return 0.0
        
        perpendicularity = (sentence_count * self.perpendicularity_angle) % 180.0 / 180.0
        return round(perpendicularity, 4)
    
    def _calculate_filament_connections(self, content: str) -> List[str]:
        """Ø­Ø³Ø§Ø¨ Ø§ØªØµØ§Ù„Ø§Øª Ø§Ù„ÙØªØ§Ø¦Ù„ Ù„Ù„Ù…Ø­ØªÙˆÙ‰"""
        # ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¨Ø³Ø· Ù„Ù†Ø¸Ø±ÙŠØ© Ø§Ù„ÙØªØ§Ø¦Ù„
        words = content.split()
        connections = []
        
        # Ø£ÙˆÙ„ 5 ÙƒÙ„Ù…Ø§Øª ÙƒØ§ØªØµØ§Ù„Ø§Øª ÙØªØ§Ø¦Ù„
        for i, word in enumerate(words[:5]):
            if len(word) > 2:  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù‚ØµÙŠØ±Ø©
                connections.append(f"{word}:{len(word)}")
        
        return connections
    
    def _save_knowledge_entry(self, entry: KnowledgeEntry):
        """Ø­ÙØ¸ Ø§Ù„Ù…Ø¯Ø®Ù„ Ø§Ù„Ù…Ø¹Ø±ÙÙŠ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            content_hash = hashlib.sha256(entry.content.encode()).hexdigest()
            
            cursor.execute("""
                INSERT OR IGNORE INTO extracted_knowledge 
                (content, source, category, language, zero_duality_score, 
                 perpendicularity_factor, filament_connections, extraction_date, 
                 revolutionary_id, content_hash)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                entry.content,
                entry.source,
                entry.category,
                entry.language,
                entry.zero_duality_score,
                entry.perpendicularity_factor,
                json.dumps(entry.filament_connections),
                entry.extraction_date,
                entry.revolutionary_id,
                content_hash
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ù…Ø¹Ø±ÙØ©: {e}")
    
    def get_knowledge_stats(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
            cursor.execute("SELECT COUNT(*) FROM extracted_knowledge")
            total_knowledge = cursor.fetchone()[0]
            
            # Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø­Ø³Ø¨ Ø§Ù„Ù…ØµØ¯Ø±
            cursor.execute("""
                SELECT source, COUNT(*) 
                FROM extracted_knowledge 
                GROUP BY source
            """)
            by_source = dict(cursor.fetchall())
            
            # Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø­Ø³Ø¨ Ø§Ù„ÙØ¦Ø©
            cursor.execute("""
                SELECT category, COUNT(*) 
                FROM extracted_knowledge 
                GROUP BY category
            """)
            by_category = dict(cursor.fetchall())
            
            conn.close()
            
            return {
                'total_knowledge': total_knowledge,
                'by_source': by_source,
                'by_category': by_category,
                'database_path': self.db_path
            }
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª: {e}")
            return {}
    
    def search_knowledge(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT content, source, category, zero_duality_score, 
                       perpendicularity_factor, filament_connections
                FROM extracted_knowledge 
                WHERE content LIKE ? 
                ORDER BY zero_duality_score DESC
                LIMIT ?
            """, (f"%{query}%", limit))
            
            results = []
            for row in cursor.fetchall():
                results.append({
                    'content': row[0][:200] + "..." if len(row[0]) > 200 else row[0],
                    'source': row[1],
                    'category': row[2],
                    'zero_duality_score': row[3],
                    'perpendicularity_factor': row[4],
                    'filament_connections': json.loads(row[5]) if row[5] else []
                })
            
            conn.close()
            return results
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø«: {e}")
            return []

def demo_external_knowledge_bridge():
    """Ø¹Ø±Ø¶ ØªÙˆØ¶ÙŠØ­ÙŠ Ù„Ø¬Ø³Ø± Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©"""
    
    print("ğŸŒ‰âš¡ Ø¹Ø±Ø¶ ØªÙˆØ¶ÙŠØ­ÙŠ Ù„Ø¬Ø³Ø± Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©")
    print("=" * 60)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø³Ø±
    bridge = ExternalKnowledgeBridge()
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ù…Ø¹ Ollama
    print("\nğŸ”— Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ù…Ø¹ Ollama:")
    ollama_available = bridge.check_ollama_connection()
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù† ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠØ§
    print("\nğŸ“š Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±ÙØ© Ù…Ù† ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠØ§:")
    topics = ["Ø§Ù„Ø°ÙƒØ§Ø¡_Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", "Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª", "Ø§Ù„ÙÙŠØ²ÙŠØ§Ø¡"]
    
    for topic in topics:
        content = bridge.extract_from_wikipedia(topic)
        if content:
            print(f"   âœ… {topic}: {len(content)} Ø­Ø±Ù")
        else:
            print(f"   âŒ ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬: {topic}")
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    print("\nğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©:")
    stats = bridge.get_knowledge_stats()
    print(f"   ğŸ“ˆ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø¹Ø±ÙØ©: {stats.get('total_knowledge', 0)}")
    print(f"   ğŸ”— Ø§Ù„Ù…ØµØ§Ø¯Ø±: {list(stats.get('by_source', {}).keys())}")
    print(f"   ğŸ“‚ Ø§Ù„ÙØ¦Ø§Øª: {list(stats.get('by_category', {}).keys())}")
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨Ø­Ø«
    print("\nğŸ” Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø¹Ø±ÙØ©:")
    results = bridge.search_knowledge("Ø°ÙƒØ§Ø¡", limit=3)
    for i, result in enumerate(results, 1):
        print(f"   {i}. {result['content'][:100]}...")
        print(f"      Ø§Ù„Ù…ØµØ¯Ø±: {result['source']} | Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙØ±: {result['zero_duality_score']}")
    
    print("\nğŸ‰ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠ!")
    print("ğŸ§¬ Ø¬Ø³Ø± Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ© Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…!")

if __name__ == "__main__":
    demo_external_knowledge_bridge()
