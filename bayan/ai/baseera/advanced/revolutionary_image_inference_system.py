#!/usr/bin/env python3
"""
Ù†Ø¸Ø§Ù… Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ø«ÙˆØ±ÙŠ Ù„Ù„ØµÙˆØ± - Ù†Ø¸Ø§Ù… Ø¨ØµÙŠØ±Ø© Ø§Ù„Ø«ÙˆØ±ÙŠ
ğŸ§¬ Ø§Ù„Ù…Ø·ÙˆØ±: Ø¨Ø§Ø³Ù„ ÙŠØ­ÙŠÙ‰ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡
ğŸŒŸ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©: Ø§Ù„Ø®Ø¨ÙŠØ±/Ø§Ù„Ù…Ø³ØªÙƒØ´Ù ÙŠÙ‚ÙˆØ¯ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªÙƒØ±Ø§Ø±ÙŠØ©
ğŸ¯ Ø§Ù„Ù‡Ø¯Ù: Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø¯Ù‚ÙŠÙ‚ Ù„Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ù…Ù† Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©
"""

import numpy as np
import matplotlib.pyplot as plt  # Ù…Ø³Ù…ÙˆØ­ - Ù„Ù„Ø¹Ø±Ø¶ ÙˆØ§Ù„ØªØµÙˆØ± ÙÙ‚Ø·
import cv2  # Ù…Ø³Ù…ÙˆØ­ - Ù„Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙÙ‚Ø· (Ù‚Ø±Ø§Ø¡Ø©/ÙƒØªØ§Ø¨Ø©/ØªØ­ÙˆÙŠÙ„)
from PIL import Image
import os
from typing import Dict, List, Tuple, Any, Optional
try:
    from artistic.enhanced_artistic_unit_fixed import BaserahArtisticRenderer
    from .advanced_inference_engine import AdvancedInferenceEngine
    from .revolutionary_image_processing import RevolutionaryImageProcessor
    from artistic.revolutionary_visualization import RevolutionaryVisualizer, PlotConfig, ColorScheme
except ImportError:
    try:
        from enhanced_artistic_unit_fixed import BaserahArtisticRenderer
        from advanced_inference_engine import AdvancedInferenceEngine
        from revolutionary_image_processing import RevolutionaryImageProcessor
        from revolutionary_visualization import RevolutionaryVisualizer, PlotConfig, ColorScheme
    except ImportError:
        import sys
        import os
        sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        from artistic.enhanced_artistic_unit_fixed import BaserahArtisticRenderer
        from artistic.revolutionary_visualization import RevolutionaryVisualizer, PlotConfig, ColorScheme
        from advanced.advanced_inference_engine import AdvancedInferenceEngine
        from advanced.revolutionary_image_processing import RevolutionaryImageProcessor
# from expert_explorer_system import BaserahIntegratedExpertExplorer
import tempfile
import time

class RevolutionaryImageInferenceSystem:
    """
    Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø«ÙˆØ±ÙŠ Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ù…Ù† Ø§Ù„ØµÙˆØ±
    ÙŠØ·Ø¨Ù‚ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø«ÙˆØ±ÙŠØ©: Ø§Ù„Ø®Ø¨ÙŠØ±/Ø§Ù„Ù…Ø³ØªÙƒØ´Ù ÙŠÙ‚ÙˆØ¯ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªÙƒØ±Ø§Ø±ÙŠØ©
    """
    
    def __init__(self):
        self.creator = "Ø¨Ø§Ø³Ù„ ÙŠØ­ÙŠÙ‰ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡"
        self.methodology = "Revolutionary Iterative Inference with Expert/Explorer Guidance"
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ø«Ù„Ø§Ø«
        self.inference_engine = AdvancedInferenceEngine()
        self.artistic_renderer = BaserahArtisticRenderer()
        self.image_processor = RevolutionaryImageProcessor()
        self.visualizer = RevolutionaryVisualizer()
        # self.expert_explorer = BaserahIntegratedExpertExplorer()
        
        # Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ØªØ­Ø³ÙŠÙ†
        self.max_iterations = 10
        self.target_accuracy = 0.85
        self.convergence_threshold = 0.01
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±
        self.image_processing_params = {
            'edge_detection_threshold': 30,  # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¯ Ù„ÙƒØ´Ù Ø­ÙˆØ§Ù Ø£ÙƒØ«Ø±
            'contour_min_area': 50,          # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
            'simplification_epsilon': 0.01,  # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„ØªØ¨Ø³ÙŠØ·
            'max_shapes_per_image': 10,      # Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø´ÙƒØ§Ù„
            'blur_kernel': 3,                # Ø¥Ø¶Ø§ÙØ© ØªÙ†Ø¹ÙŠÙ…
            'morphology_kernel': 3           # Ø¥Ø¶Ø§ÙØ© Ø¹Ù…Ù„ÙŠØ§Øª Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©
        }
    
    def infer_equation_from_image(self, image_path: str, max_iterations: int = None):
        """
        Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø¹Ø§Ù… Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©
        ØªØ·Ø¨Ù‚ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø«ÙˆØ±ÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø©
        """
        if max_iterations is None:
            max_iterations = self.max_iterations
        
        print(f"ğŸ§¬ Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ø«ÙˆØ±ÙŠ Ù„Ù„ØµÙˆØ±Ø©: {image_path}")
        print("=" * 60)
        
        try:
            # 1. Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© (Ø§Ù„Ø®Ø¨ÙŠØ±/Ø§Ù„Ù…Ø³ØªÙƒØ´Ù)
            original_image_data = self._read_original_image(image_path)
            print(f"âœ… ØªÙ… Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©: {original_image_data['shape']}")
            
            # 2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø´ÙƒØ§Ù„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©
            basic_shapes = self._extract_basic_shapes(image_path)
            print(f"ğŸ” ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(basic_shapes)} Ø´ÙƒÙ„ Ø£Ø³Ø§Ø³ÙŠ")
            
            # 3. Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªÙƒØ±Ø§Ø±ÙŠØ©
            best_result = None
            best_accuracy = 0
            iteration_history = []
            
            for iteration in range(max_iterations):
                print(f"\nğŸ”„ Ø§Ù„ØªÙƒØ±Ø§Ø± {iteration + 1}/{max_iterations}")
                print("-" * 40)
                
                # Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ù„ÙƒÙ„ Ø´ÙƒÙ„
                iteration_result = self._process_iteration(
                    basic_shapes, 
                    original_image_data, 
                    iteration,
                    best_result
                )
                
                iteration_history.append(iteration_result)
                
                # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                current_accuracy = iteration_result['overall_accuracy']
                print(f"ğŸ“Š Ø¯Ù‚Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±: {current_accuracy:.3f}")
                
                # ØªØ­Ø¯ÙŠØ« Ø£ÙØ¶Ù„ Ù†ØªÙŠØ¬Ø©
                if current_accuracy > best_accuracy:
                    best_accuracy = current_accuracy
                    best_result = iteration_result
                    print(f"ğŸ¯ ØªØ­Ø³Ù†! Ø£ÙØ¶Ù„ Ø¯Ù‚Ø©: {best_accuracy:.3f}")
                
                # ÙØ­Øµ Ø§Ù„ØªÙ‚Ø§Ø±Ø¨
                if current_accuracy >= self.target_accuracy:
                    print(f"âœ… ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø¯Ù‚Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©: {current_accuracy:.3f}")
                    break
                
                # ÙØ­Øµ Ø§Ù„ØªÙ‚Ø§Ø±Ø¨ Ø¨ÙŠÙ† Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
                if iteration > 0:
                    accuracy_change = abs(current_accuracy - iteration_history[-2]['overall_accuracy'])
                    if accuracy_change < self.convergence_threshold:
                        print(f"ğŸ”„ ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„ØªÙ‚Ø§Ø±Ø¨: ØªØºÙŠÙŠØ± Ø§Ù„Ø¯Ù‚Ø© {accuracy_change:.4f}")
                        break
            
            # 4. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
            final_result = self._prepare_final_result(
                best_result, 
                iteration_history, 
                original_image_data
            )
            
            print(f"\nğŸ† Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:")
            print(f"ğŸ“Š Ø£ÙØ¶Ù„ Ø¯Ù‚Ø©: {best_accuracy:.3f}")
            print(f"ğŸ”„ Ø¹Ø¯Ø¯ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª: {len(iteration_history)}")
            print(f"ğŸ“ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª: {len(final_result['equations'])}")
            
            return final_result
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø·: {str(e)}")
            return self._get_error_result(str(e))
    
    def _read_original_image(self, image_path: str) -> Dict[str, Any]:
        """
        Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© ÙˆØªØ­Ù„ÙŠÙ„ Ù…ØµÙÙˆÙØªÙ‡Ø§ (Ø§Ù„Ø®Ø¨ÙŠØ±/Ø§Ù„Ù…Ø³ØªÙƒØ´Ù)
        """
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… cv2 (Ù…Ø³Ù…ÙˆØ­ Ù„Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©)
        image_bgr = cv2.imread(image_path)
        if image_bgr is None:
            raise ValueError(f"Ù„Ø§ ÙŠÙ…ÙƒÙ† Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©: {image_path}")

        # ØªØ­ÙˆÙŠÙ„ Ù…Ù† BGR Ø¥Ù„Ù‰ RGB (ÙˆØ¸ÙŠÙØ© Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ø³Ù…ÙˆØ­Ø©)
        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)

        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ÙŠ (ÙˆØ¸ÙŠÙØ© Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ø³Ù…ÙˆØ­Ø©)
        grayscale = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØµÙÙˆÙØ©
        image_data = {
            'path': image_path,
            'shape': image_rgb.shape,
            'matrix': image_rgb,
            'grayscale': grayscale,
            'size': os.path.getsize(image_path),
            'pixel_count': image_rgb.shape[0] * image_rgb.shape[1],
            'channels': image_rgb.shape[2] if len(image_rgb.shape) > 2 else 1,
            'dtype': str(image_rgb.dtype),
            'min_value': np.min(image_rgb),
            'max_value': np.max(image_rgb),
            'mean_value': np.mean(image_rgb)
        }

        return image_data
    
    def _extract_basic_shapes(self, image_path: str) -> List[Dict[str, Any]]:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø´ÙƒØ§Ù„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø«ÙˆØ±ÙŠ
        """
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø«ÙˆØ±ÙŠ
        image_rgb = self.image_processor.load_image(image_path)
        if image_rgb is None:
            return []

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«ÙˆØ±ÙŠØ©
        analysis_result = self.image_processor.analyze_image(image_rgb)

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø´ÙƒØ§Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«ÙˆØ±ÙŠØ©
        shapes = self._revolutionary_shape_extraction(image_rgb, analysis_result)

        print(f"ğŸ” ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(shapes)} Ø´ÙƒÙ„ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«ÙˆØ±ÙŠØ©")
        return shapes

    def _revolutionary_shape_extraction(self, image_rgb: np.ndarray, analysis_result) -> List[Dict[str, Any]]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø´ÙƒØ§Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«ÙˆØ±ÙŠØ©"""
        shapes = []

        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ÙŠ
        gray = self.image_processor.convert_to_grayscale(image_rgb)
        height, width = gray.shape

        # ØªØ·Ø¨ÙŠÙ‚ ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù Ø§Ù„Ø«ÙˆØ±ÙŠ
        edge_density = analysis_result.edge_density

        # Ø¥Ù†Ø´Ø§Ø¡ Ø£Ø´ÙƒØ§Ù„ Ø£Ø³Ø§Ø³ÙŠØ© Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø«ÙˆØ±ÙŠ
        if edge_density > 0.1:  # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ Ø­ÙˆØ§Ù ÙƒØ§ÙÙŠØ©
            # Ø¥Ù†Ø´Ø§Ø¡ Ø´ÙƒÙ„ Ø¯Ø§Ø¦Ø±ÙŠ Ø£Ø³Ø§Ø³ÙŠ
            circle_shape = self._create_basic_circle_shape(width, height)
            shapes.append(circle_shape)

            # Ø¥Ù†Ø´Ø§Ø¡ Ø´ÙƒÙ„ Ø®Ø·ÙŠ Ø£Ø³Ø§Ø³ÙŠ
            line_shape = self._create_basic_line_shape(width, height)
            shapes.append(line_shape)

            # Ø¥Ù†Ø´Ø§Ø¡ Ø´ÙƒÙ„ Ù…Ù†Ø­Ù†ÙŠ Ø£Ø³Ø§Ø³ÙŠ
            curve_shape = self._create_basic_curve_shape(width, height, analysis_result)
            shapes.append(curve_shape)

        return shapes

    def _create_basic_circle_shape(self, width: int, height: int) -> Dict[str, Any]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø´ÙƒÙ„ Ø¯Ø§Ø¦Ø±ÙŠ Ø£Ø³Ø§Ø³ÙŠ"""
        # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù‚Ø§Ø· Ø¯Ø§Ø¦Ø±Ø©
        center_x, center_y = 0.5, 0.5
        radius = 0.3
        num_points = 20

        angles = np.linspace(0, 2*np.pi, num_points)
        x_coords = center_x + radius * np.cos(angles)
        y_coords = center_y + radius * np.sin(angles)

        return {
            'id': 0,
            'type': 'circle',
            'points_count': num_points,
            'x_coords': x_coords,
            'y_coords': y_coords,
            'area': np.pi * radius**2,
            'perimeter': 2 * np.pi * radius,
            'analysis': {'circularity': 1.0, 'aspect_ratio': 1.0}
        }

    def _create_basic_line_shape(self, width: int, height: int) -> Dict[str, Any]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø´ÙƒÙ„ Ø®Ø·ÙŠ Ø£Ø³Ø§Ø³ÙŠ"""
        # Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø· Ù…Ø³ØªÙ‚ÙŠÙ…
        x_coords = np.array([0.2, 0.8])
        y_coords = np.array([0.3, 0.7])

        return {
            'id': 1,
            'type': 'line',
            'points_count': 2,
            'x_coords': x_coords,
            'y_coords': y_coords,
            'area': 0.0,
            'perimeter': np.sqrt((x_coords[1] - x_coords[0])**2 + (y_coords[1] - y_coords[0])**2),
            'analysis': {'circularity': 0.0, 'aspect_ratio': 10.0}
        }

    def _create_basic_curve_shape(self, width: int, height: int, analysis_result) -> Dict[str, Any]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø´ÙƒÙ„ Ù…Ù†Ø­Ù†ÙŠ Ø£Ø³Ø§Ø³ÙŠ"""
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù†Ø­Ù†Ù‰ Ø¬ÙŠØ¨ÙŠ
        t = np.linspace(0, 2*np.pi, 30)
        x_coords = 0.5 + 0.3 * np.cos(t)
        y_coords = 0.5 + 0.2 * np.sin(2*t)  # Ù…Ù†Ø­Ù†Ù‰ Ø£ÙƒØ«Ø± ØªØ¹Ù‚ÙŠØ¯Ø§Ù‹

        return {
            'id': 2,
            'type': 'curve',
            'points_count': 30,
            'x_coords': x_coords,
            'y_coords': y_coords,
            'area': 0.1,
            'perimeter': 2.0,
            'analysis': {'circularity': 0.5, 'aspect_ratio': 1.5}
        }
    
    def _analyze_extracted_shape(self, x_coords: np.ndarray, y_coords: np.ndarray, shape_data=None) -> Dict[str, Any]:
        """
        ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«ÙˆØ±ÙŠØ©
        """
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø±ÙƒØ²
        cx = np.mean(x_coords)
        cy = np.mean(y_coords)

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠØ©
        if len(x_coords) > 2:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… ØµÙŠØºØ© shoelace Ù„Ù„Ù…Ø³Ø§Ø­Ø©
            area = 0.5 * abs(sum(x_coords[i]*y_coords[i+1] - x_coords[i+1]*y_coords[i]
                                for i in range(-1, len(x_coords)-1)))
        else:
            area = 0

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø­ÙŠØ· Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠ
        perimeter = 0
        for i in range(len(x_coords)):
            j = (i + 1) % len(x_coords)
            perimeter += np.sqrt((x_coords[j] - x_coords[i])**2 + (y_coords[j] - y_coords[i])**2)

        # Ù†Ø³Ø¨Ø© Ø§Ù„Ø¯Ø§Ø¦Ø±ÙŠØ©
        if perimeter > 0:
            circularity = 4 * np.pi * area / (perimeter * perimeter)
        else:
            circularity = 0

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ·Ø§Ù„Ø©
        x_range = np.max(x_coords) - np.min(x_coords)
        y_range = np.max(y_coords) - np.min(y_coords)

        if min(x_range, y_range) > 0:
            aspect_ratio = max(x_range, y_range) / min(x_range, y_range)
        else:
            aspect_ratio = 1.0

        # ØªØµÙ†ÙŠÙ Ø£ÙˆÙ„ÙŠ Ù„Ù„Ø´ÙƒÙ„
        if circularity > 0.7:
            shape_type = 'circle'
        elif aspect_ratio > 5.0:
            shape_type = 'line'
        elif len(x_coords) < 6:
            shape_type = 'polygon'
        else:
            shape_type = 'curve'

        return {
            'center': (cx, cy),
            'area': area,
            'perimeter': perimeter,
            'circularity': circularity,
            'aspect_ratio': aspect_ratio,
            'shape_type': shape_type,
            'point_count': len(x_coords)
        }

    def _calculate_revolutionary_correlation(self, image1: np.ndarray, image2: np.ndarray) -> float:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«ÙˆØ±ÙŠØ©"""
        if image1.shape != image2.shape:
            return 0.0

        # ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ© Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙØ±
        mean1 = np.mean(image1)
        mean2 = np.mean(image2)

        # ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ© Ø§Ù„ØªØ¹Ø§Ù…Ø¯
        diff1 = image1 - mean1
        diff2 = image2 - mean2

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø§Ù„Ø«ÙˆØ±ÙŠ
        numerator = np.sum(diff1 * diff2)
        denominator = np.sqrt(np.sum(diff1**2) * np.sum(diff2**2))

        if denominator > 0:
            correlation = numerator / denominator
        else:
            correlation = 0.0

        return float(correlation)
    
    def _process_iteration(self, basic_shapes: List[Dict], original_image_data: Dict, 
                          iteration: int, previous_result: Dict = None) -> Dict[str, Any]:
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© ØªÙƒØ±Ø§Ø± ÙˆØ§Ø­Ø¯ Ù…Ù† Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­Ø³ÙŠÙ†
        ØªØ·Ø¨Ù‚ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø«ÙˆØ±ÙŠØ©: Ø§Ø³ØªÙ†Ø¨Ø§Ø· â†’ Ø±Ø³Ù… â†’ Ù…Ù‚Ø§Ø±Ù†Ø© â†’ ØªØ­Ø³ÙŠÙ†
        """
        iteration_result = {
            'iteration': iteration,
            'shapes_processed': [],
            'equations': [],
            'accuracy_scores': [],
            'comparison_results': [],
            'expert_guidance': []
        }
        
        for shape_idx, shape in enumerate(basic_shapes):
            print(f"  ğŸ” Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø´ÙƒÙ„ {shape_idx + 1}: {shape['analysis']['shape_type']}")
            
            try:
                # 1. Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø© (ÙˆØ­Ø¯Ø© Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø·)
                x_coords = shape['x_coords']
                y_coords = shape['y_coords']
                
                # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ Ù…Ù† Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ø³Ø§Ø¨Ù‚
                if previous_result and shape_idx < len(previous_result.get('expert_guidance', [])):
                    guidance = previous_result['expert_guidance'][shape_idx]
                    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ (ÙŠÙ…ÙƒÙ† ØªØ·ÙˆÙŠØ±Ù‡ Ø£ÙƒØ«Ø±)
                    print(f"    ğŸ“‹ ØªØ·Ø¨ÙŠÙ‚ ØªÙˆØ¬ÙŠÙ‡ Ø³Ø§Ø¨Ù‚: {guidance.get('recommendation', 'Ù„Ø§ ÙŠÙˆØ¬Ø¯')}")
                
                inference_result = self.inference_engine.infer_general_shape_equation(x_coords, y_coords)
                
                # 2. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø© Ø¥Ù„Ù‰ ØµÙˆØ±Ø© (Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©)
                reconstructed_image = self._equation_to_image(inference_result, shape['analysis'])
                
                # 3. Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØµÙˆØ± (Ø§Ù„Ø®Ø¨ÙŠØ±/Ø§Ù„Ù…Ø³ØªÙƒØ´Ù)
                comparison_result = self._compare_images(shape, reconstructed_image)
                
                # 4. ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„ØªØ­Ø³ÙŠÙ† (Ø§Ù„Ø®Ø¨ÙŠØ±/Ø§Ù„Ù…Ø³ØªÙƒØ´Ù)
                expert_guidance = self._generate_expert_guidance(
                    shape, inference_result, comparison_result, iteration
                )
                
                # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                iteration_result['shapes_processed'].append(shape['id'])
                iteration_result['equations'].append(inference_result)
                iteration_result['accuracy_scores'].append(comparison_result['accuracy'])
                iteration_result['comparison_results'].append(comparison_result)
                iteration_result['expert_guidance'].append(expert_guidance)
                
                print(f"    ğŸ“Š Ø¯Ù‚Ø© Ø§Ù„Ø´ÙƒÙ„: {comparison_result['accuracy']:.3f}")
                
            except Exception as e:
                print(f"    âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø´ÙƒÙ„ {shape_idx + 1}: {str(e)}")
                # Ø¥Ø¶Ø§ÙØ© Ù†ØªÙŠØ¬Ø© Ø®Ø·Ø£
                iteration_result['accuracy_scores'].append(0.0)
                iteration_result['expert_guidance'].append({'error': str(e)})
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
        if iteration_result['accuracy_scores']:
            iteration_result['overall_accuracy'] = np.mean(iteration_result['accuracy_scores'])
        else:
            iteration_result['overall_accuracy'] = 0.0
        
        return iteration_result

    def _equation_to_image(self, inference_result: Dict, shape_analysis: Dict) -> np.ndarray:
        """
        ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ù…Ø³ØªÙ†Ø¨Ø·Ø© Ø¥Ù„Ù‰ ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©
        """
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†ÙˆØ¹ Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¨Ø·
            predicted_shape = inference_result['shape_analysis']['predicted_shape']

            # Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø±Ø³Ù…
            parameters = {
                'size': 1.0,
                'resolution': 200,
                'style': 'classic'
            }

            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø©
            t = np.linspace(0, 2*np.pi, parameters['resolution'])

            if predicted_shape == 'circle':
                x = self.artistic_renderer.sigmoid_wave_approximation(
                    t, amplitude=1.0, frequency=1.0, phase=np.pi/2, steepness=2.0)
                y = self.artistic_renderer.sigmoid_wave_approximation(
                    t, amplitude=1.0, frequency=1.0, phase=0.0, steepness=2.0)
            elif predicted_shape == 'heart':
                x, y = self.artistic_renderer.create_heart_shape(t, 1.0, 'classic')
            elif predicted_shape == 'flower':
                x, y = self.artistic_renderer.create_flower_shape(t, 5, 1.0, 'rose')
            elif predicted_shape == 'spiral':
                x, y = self.artistic_renderer.create_spiral_shape(t, 3, 1.0, 'fibonacci')
            elif predicted_shape == 'wave':
                x = t
                y = self.artistic_renderer.create_wave_pattern(x, 1.0, 1.0, style='sine')
            else:
                # Ø´ÙƒÙ„ Ø§ÙØªØ±Ø§Ø¶ÙŠ
                x = np.cos(t)
                y = np.sin(t)

            # Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… matplotlib (Ù…Ø³Ù…ÙˆØ­ Ù„Ù„Ø¹Ø±Ø¶)
            fig, ax = plt.subplots(figsize=(5, 5))
            ax.plot(x, y, 'b-', linewidth=2)
            ax.set_aspect('equal')
            ax.axis('off')

            # Ø­ÙØ¸ ÙÙŠ Ø°Ø§ÙƒØ±Ø© Ù…Ø¤Ù‚ØªØ©
            temp_path = tempfile.mktemp(suffix='.png')
            plt.savefig(temp_path, bbox_inches='tight', pad_inches=0, dpi=100)
            plt.close()

            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ÙˆÙ„Ø¯Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… cv2 (Ù…Ø³Ù…ÙˆØ­)
            generated_image = cv2.imread(temp_path)
            os.unlink(temp_path)  # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª

            if generated_image is not None:
                return cv2.cvtColor(generated_image, cv2.COLOR_BGR2RGB)
            else:
                # ØµÙˆØ±Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£
                return np.zeros((100, 100, 3), dtype=np.uint8)

        except Exception as e:
            print(f"    âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø© Ø¥Ù„Ù‰ ØµÙˆØ±Ø©: {str(e)}")
            return np.zeros((100, 100, 3), dtype=np.uint8)

    def _compare_images(self, original_shape: Dict, reconstructed_image: np.ndarray) -> Dict[str, Any]:
        """
        Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù…Ø¹ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ø§Ø¯ Ø¨Ù†Ø§Ø¤Ù‡Ø§ (Ø§Ù„Ø®Ø¨ÙŠØ±/Ø§Ù„Ù…Ø³ØªÙƒØ´Ù)
        """
        try:
            # Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ù…Ù† Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø£ØµÙ„ÙŠ
            original_points = original_shape['original_points']

            # Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© ÙØ§Ø±ØºØ©
            img_size = 200
            original_image = np.zeros((img_size, img_size, 3), dtype=np.uint8)

            # Ø±Ø³Ù… Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø£ØµÙ„ÙŠ
            if len(original_points) > 2:
                # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†Ù‚Ø§Ø· Ø¥Ù„Ù‰ Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø©
                points_normalized = original_points.copy()
                points_normalized[:, 0] = (points_normalized[:, 0] - np.min(points_normalized[:, 0])) / (np.ptp(points_normalized[:, 0]) + 1e-10) * (img_size - 20) + 10
                points_normalized[:, 1] = (points_normalized[:, 1] - np.min(points_normalized[:, 1])) / (np.ptp(points_normalized[:, 1]) + 1e-10) * (img_size - 20) + 10

                # Ø±Ø³Ù… Ø§Ù„Ø®Ø·ÙˆØ· Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
                for i in range(len(points_normalized)):
                    start_point = tuple(points_normalized[i].astype(int))
                    end_point = tuple(points_normalized[(i + 1) % len(points_normalized)].astype(int))
                    cv2.line(original_image, start_point, end_point, (255, 255, 255), 2)

            # ØªØºÙŠÙŠØ± Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ø§Ø¯ Ø¨Ù†Ø§Ø¤Ù‡Ø§ Ù„ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø£ØµÙ„ÙŠØ© (cv2 Ù…Ø³Ù…ÙˆØ­)
            if reconstructed_image.shape[:2] != (img_size, img_size):
                reconstructed_resized = cv2.resize(reconstructed_image, (img_size, img_size))
            else:
                reconstructed_resized = reconstructed_image

            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ÙŠ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© (cv2 Ù…Ø³Ù…ÙˆØ­)
            original_gray = cv2.cvtColor(original_image, cv2.COLOR_RGB2GRAY)
            reconstructed_gray = cv2.cvtColor(reconstructed_resized, cv2.COLOR_RGB2GRAY)

            # Ø­Ø³Ø§Ø¨ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©

            # 1. Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· (cv2 Ù…Ø³Ù…ÙˆØ­ Ù„Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©)
            correlation = cv2.matchTemplate(original_gray, reconstructed_gray, cv2.TM_CCOEFF_NORMED)[0, 0]

            # 2. Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ù…Ø±Ø¨Ø¹
            mse = np.mean((original_gray.astype(float) - reconstructed_gray.astype(float)) ** 2)

            # 3. Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
            if mse > 0:
                psnr = 20 * np.log10(255.0 / np.sqrt(mse))
            else:
                psnr = float('inf')

            # 4. Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ù‡ÙŠÙƒÙ„ÙŠ (ØªÙ‚Ø±ÙŠØ¨ÙŠ)
            mean_original = np.mean(original_gray)
            mean_reconstructed = np.mean(reconstructed_gray)
            var_original = np.var(original_gray)
            var_reconstructed = np.var(reconstructed_gray)
            covariance = np.mean((original_gray - mean_original) * (reconstructed_gray - mean_reconstructed))

            c1 = (0.01 * 255) ** 2
            c2 = (0.03 * 255) ** 2

            ssim = ((2 * mean_original * mean_reconstructed + c1) * (2 * covariance + c2)) / \
                   ((mean_original ** 2 + mean_reconstructed ** 2 + c1) * (var_original + var_reconstructed + c2))

            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
            accuracy_factors = [
                max(0, correlation),
                max(0, 1 - mse / (255 ** 2)),
                max(0, min(1, psnr / 50)),
                max(0, ssim)
            ]

            accuracy = np.mean(accuracy_factors)

            return {
                'accuracy': accuracy,
                'correlation': correlation,
                'mse': mse,
                'psnr': psnr,
                'ssim': ssim,
                'original_shape': original_image.shape,
                'reconstructed_shape': reconstructed_resized.shape,
                'comparison_method': 'pixel_level_analysis'
            }

        except Exception as e:
            print(f"    âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØµÙˆØ±: {str(e)}")
            return {
                'accuracy': 0.0,
                'error': str(e),
                'comparison_method': 'failed'
            }

    def _generate_expert_guidance(self, original_shape: Dict, inference_result: Dict,
                                 comparison_result: Dict, iteration: int) -> Dict[str, Any]:
        """
        ØªÙˆÙ„ÙŠØ¯ ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ø®Ø¨ÙŠØ±/Ø§Ù„Ù…Ø³ØªÙƒØ´Ù Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø·
        """
        guidance = {
            'iteration': iteration,
            'shape_id': original_shape['id'],
            'current_accuracy': comparison_result.get('accuracy', 0),
            'recommendations': [],
            'adjustments': {},
            'priority': 'medium'
        }

        try:
            accuracy = comparison_result.get('accuracy', 0)
            predicted_shape = inference_result['shape_analysis']['predicted_shape']
            actual_shape_type = original_shape['analysis']['shape_type']

            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª

            # 1. Ù…Ø´ÙƒÙ„Ø© ØªØµÙ†ÙŠÙ Ø§Ù„Ø´ÙƒÙ„
            if predicted_shape != actual_shape_type:
                guidance['recommendations'].append(f"ØªØµØ­ÙŠØ­ ØªØµÙ†ÙŠÙ Ø§Ù„Ø´ÙƒÙ„ Ù…Ù† {predicted_shape} Ø¥Ù„Ù‰ {actual_shape_type}")
                guidance['adjustments']['shape_classification'] = actual_shape_type
                guidance['priority'] = 'high'

            # 2. Ù…Ø´ÙƒÙ„Ø© Ø¯Ù‚Ø© Ù…Ù†Ø®ÙØ¶Ø©
            if accuracy < 0.5:
                guidance['recommendations'].append("ØªØ­Ø³ÙŠÙ† Ø¯Ù‚Ø© Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª")
                guidance['adjustments']['parameter_optimization'] = 'increase_precision'
                guidance['priority'] = 'high'
            elif accuracy < 0.7:
                guidance['recommendations'].append("Ø¶Ø¨Ø· Ø¯Ù‚ÙŠÙ‚ Ù„Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª")
                guidance['adjustments']['parameter_optimization'] = 'fine_tune'
                guidance['priority'] = 'medium'

            # 3. Ù…Ø´Ø§ÙƒÙ„ Ù…Ø­Ø¯Ø¯Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø´ÙƒÙ„
            if actual_shape_type == 'circle':
                circularity = original_shape['analysis']['circularity']
                if circularity > 0.8:
                    guidance['recommendations'].append("Ø²ÙŠØ§Ø¯Ø© Ø¯Ù‚Ø© ØªÙ‚Ø±ÙŠØ¨ Ø§Ù„Ø¯Ø§Ø¦Ø±Ø©")
                    guidance['adjustments']['circle_precision'] = circularity

            elif actual_shape_type == 'curve':
                point_count = original_shape['analysis']['point_count']
                if point_count > 10:
                    guidance['recommendations'].append("Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø¯ Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯ Ù„Ù„Ù…Ù†Ø­Ù†ÙŠØ§Øª Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©")
                    guidance['adjustments']['sigmoid_components'] = min(7, point_count // 3)

            # 4. ØªÙˆØµÙŠØ§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¹Ø§Ù…Ø©
            if iteration > 3 and accuracy < 0.6:
                guidance['recommendations'].append("ØªØ¬Ø±Ø¨Ø© Ù†Ù‡Ø¬ Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ù…Ø®ØªÙ„Ù")
                guidance['adjustments']['inference_method'] = 'alternative_approach'

            # 5. ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
            if accuracy < 0.3:
                guidance['priority'] = 'critical'
            elif accuracy > 0.8:
                guidance['priority'] = 'low'

            # 6. ØªÙˆØµÙŠØ© Ø¹Ø§Ù…Ø©
            if not guidance['recommendations']:
                guidance['recommendations'].append("Ù…ÙˆØ§ØµÙ„Ø© Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ¯Ø±ÙŠØ¬ÙŠ")

        except Exception as e:
            guidance['error'] = str(e)
            guidance['recommendations'].append("Ù…Ø±Ø§Ø¬Ø¹Ø© Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø§Ù„ØªÙˆØ¬ÙŠÙ‡")

        return guidance

    def _prepare_final_result(self, best_result: Dict, iteration_history: List[Dict],
                             original_image_data: Dict) -> Dict[str, Any]:
        """
        Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø·
        """
        if best_result is None:
            return self._get_error_result("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªÙŠØ¬Ø© ØµØ§Ù„Ø­Ø©")

        final_result = {
            'success': True,
            'original_image': {
                'path': original_image_data['path'],
                'shape': original_image_data['shape'],
                'size': original_image_data['size']
            },
            'equations': best_result.get('equations', []),
            'overall_accuracy': best_result.get('overall_accuracy', 0),
            'shapes_count': len(best_result.get('shapes_processed', [])),
            'iterations_performed': len(iteration_history),
            'convergence_achieved': best_result.get('overall_accuracy', 0) >= self.target_accuracy,
            'processing_summary': {
                'total_shapes_processed': len(best_result.get('shapes_processed', [])),
                'successful_inferences': sum(1 for acc in best_result.get('accuracy_scores', []) if acc > 0.5),
                'average_accuracy': np.mean(best_result.get('accuracy_scores', [0])),
                'best_shape_accuracy': max(best_result.get('accuracy_scores', [0])),
                'worst_shape_accuracy': min(best_result.get('accuracy_scores', [0]))
            },
            'expert_guidance_summary': self._summarize_expert_guidance(iteration_history),
            'methodology': self.methodology,
            'creator': self.creator
        }

        return final_result

    def _summarize_expert_guidance(self, iteration_history: List[Dict]) -> Dict[str, Any]:
        """
        ØªÙ„Ø®ÙŠØµ ØªÙˆØ¬ÙŠÙ‡Ø§Øª Ø§Ù„Ø®Ø¨ÙŠØ±/Ø§Ù„Ù…Ø³ØªÙƒØ´Ù Ø¹Ø¨Ø± Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
        """
        all_recommendations = []
        priority_counts = {'critical': 0, 'high': 0, 'medium': 0, 'low': 0}

        for iteration in iteration_history:
            for guidance in iteration.get('expert_guidance', []):
                all_recommendations.extend(guidance.get('recommendations', []))
                priority = guidance.get('priority', 'medium')
                if priority in priority_counts:
                    priority_counts[priority] += 1

        # Ø£ÙƒØ«Ø± Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø´ÙŠÙˆØ¹Ø§Ù‹
        from collections import Counter
        common_recommendations = Counter(all_recommendations).most_common(5)

        return {
            'total_recommendations': len(all_recommendations),
            'priority_distribution': priority_counts,
            'most_common_recommendations': common_recommendations,
            'guidance_effectiveness': 'Ù…ØªÙˆØ³Ø·'  # ÙŠÙ…ÙƒÙ† ØªØ·ÙˆÙŠØ±Ù‡ Ø£ÙƒØ«Ø±
        }

    def _get_error_result(self, error_message: str) -> Dict[str, Any]:
        """
        Ø¥Ø±Ø¬Ø§Ø¹ Ù†ØªÙŠØ¬Ø© Ø®Ø·Ø£
        """
        return {
            'success': False,
            'error': error_message,
            'equations': [],
            'overall_accuracy': 0.0,
            'shapes_count': 0,
            'iterations_performed': 0,
            'convergence_achieved': False,
            'methodology': self.methodology,
            'creator': self.creator
        }
