#!/usr/bin/env python3
"""
ÙˆØ­Ø¯Ø© Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© - Ù†Ø¸Ø§Ù… Ø¨ØµÙŠØ±Ø© Ø§Ù„Ø«ÙˆØ±ÙŠ
ğŸ§¬ Ø§Ù„Ù…Ø·ÙˆØ±: Ø¨Ø§Ø³Ù„ ÙŠØ­ÙŠÙ‰ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡
ğŸŒŸ Ø§Ù„Ø£ÙÙƒØ§Ø± Ø§Ù„Ø«ÙˆØ±ÙŠØ©: Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ù…Ù† Ø¥Ø¨Ø¯Ø§Ø¹ Ø¨Ø§Ø³Ù„ ÙŠØ­ÙŠÙ‰ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡
ğŸ¯ Ø§Ù„Ù…Ù†Ù‡Ø¬ÙŠØ©: Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø¯Ù‚ÙŠÙ‚ Ù„Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ù…Ù† Ø§Ù„Ø£Ø´ÙƒØ§Ù„ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
ğŸ“ Ø§Ù„Ø¹ÙƒØ³ Ø§Ù„Ø¯Ù‚ÙŠÙ‚ Ù„Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©: Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø¹Ø§Ù…
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import minimize, differential_evolution, curve_fit
from scipy.interpolate import UnivariateSpline
from scipy.signal import find_peaks
from typing import Dict, List, Tuple, Any, Optional
import warnings
warnings.filterwarnings('ignore')

# ==========================================
# ğŸ§¬ Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ© Ø§Ù„Ø«ÙˆØ±ÙŠØ© (Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©)
# ==========================================

def baserah_sigmoid(x, alpha=1.0, k=1.0, x0=0.0, n=1):
    """
    Ø¯Ø§Ù„Ø© Ø§Ù„Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯ Ø§Ù„Ø«ÙˆØ±ÙŠØ© Ù…Ø¹ Ø¹Ø§Ù…Ù„ Ø§Ù„ØªÙƒÙ…ÙŠÙ…
    Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù†Ø¸Ø§Ù… Ø¨ØµÙŠØ±Ø© (Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©)
    """
    try:
        if hasattr(x, '__len__'):
            quantized_x = np.round(np.array(x) * n) / n if n > 0 else np.array(x)
        else:
            quantized_x = round(x * n) / n if n > 0 else x
        return alpha / (1 + np.exp(-k * (quantized_x - x0)))
    except:
        return np.zeros_like(x) if hasattr(x, '__len__') else 0.0

def baserah_linear(x, beta=1.0, gamma=0.0, n=1):
    """
    Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø· Ø§Ù„Ù…Ø³ØªÙ‚ÙŠÙ… Ø§Ù„Ø«ÙˆØ±ÙŠØ© Ù…Ø¹ Ø¹Ø§Ù…Ù„ Ø§Ù„ØªÙƒÙ…ÙŠÙ…
    Ø§Ù„Ù…ÙƒÙˆÙ† Ø§Ù„Ø«Ø§Ù†ÙŠ Ù„Ù„Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©)
    """
    try:
        if hasattr(x, '__len__'):
            quantized_x = np.round(np.array(x) * n) / n if n > 0 else np.array(x)
        else:
            quantized_x = round(x * n) / n if n > 0 else x
        return beta * quantized_x + gamma
    except:
        return np.zeros_like(x) if hasattr(x, '__len__') else 0.0

class AdvancedInferenceEngine:
    """
    ÙˆØ­Ø¯Ø© Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© - Ø§Ù„Ø¹ÙƒØ³ Ø§Ù„Ø¯Ù‚ÙŠÙ‚ Ù„Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©
    ØªØ³ØªÙ†Ø¨Ø· Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø¹Ø§Ù… Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: fÌ‚(x) = Î£(Î±áµ¢Â·Ïƒâ‚™áµ¢(x; káµ¢, xâ‚€áµ¢) + Î²áµ¢x + Î³áµ¢)
    ØªØ·Ø¨Ù‚ Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«ÙˆØ±ÙŠØ© Ø§Ù„Ø«Ù„Ø§Ø« Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ù…Ù† Ø§Ù„Ø£Ø´ÙƒØ§Ù„
    """

    def __init__(self):
        self.creator = "Ø¨Ø§Ø³Ù„ ÙŠØ­ÙŠÙ‰ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡"
        self.methodology = "Reverse Engineering of Artistic Unit - Image to General Shape Equation"
        self.theories = ["Zero Duality", "Perpendicular Opposites", "Filament Theory"]

        # Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ† (Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù‚Ø¯Ø±Ø§Øª Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©)
        self.max_sigmoid_components = 7  # Ù…Ø·Ø§Ø¨Ù‚ Ù„Ø¹Ø¯Ø¯ Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ±Ø§Ø¨Ø· ÙÙŠ sigmoid_wave_approximation
        self.max_linear_components = 3
        self.optimization_iterations = 2000
        self.convergence_tolerance = 1e-8

        # Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø´ÙƒØ§Ù„ Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ© (Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©)
        self.known_shape_patterns = {
            'circle': {
                'sigmoid_components': 2,  # x Ùˆ y components
                'linear_components': 0,
                'characteristic': 'closed_curve_constant_radius',
                'phase_difference': np.pi/2  # Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† x Ùˆ y
            },
            'heart': {
                'sigmoid_components': 5,  # sin, cos, cos2, cos3, cos4 approximations
                'linear_components': 0,
                'characteristic': 'closed_curve_cusp_symmetry',
                'special_powers': [1, 1, 2, 3, 4]  # powers in heart equation
            },
            'flower': {
                'sigmoid_components': 3,  # r(t), cos(t), sin(t) approximations
                'linear_components': 1,
                'characteristic': 'radial_symmetry_petals',
                'petal_frequency': 5  # default petals
            },
            'spiral': {
                'sigmoid_components': 2,  # cos(t), sin(t) approximations
                'linear_components': 1,  # r(t) = linear growth
                'characteristic': 'expanding_curve_rotation',
                'growth_rate': 'linear'
            },
            'wave': {
                'sigmoid_components': 1,  # wave approximation
                'linear_components': 0,
                'characteristic': 'periodic_oscillation',
                'domain': 'linear'
            }
        }

    def infer_general_shape_equation(self, x_data, y_data):
        """
        Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø¹Ø§Ù… Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        Ø§Ù„Ø¹ÙƒØ³ Ø§Ù„Ø¯Ù‚ÙŠÙ‚ Ù„Ø¹Ù…Ù„ÙŠØ© render_shape ÙÙŠ Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©
        """
        try:
            # 1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø´ÙƒÙ„
            shape_analysis = self.analyze_shape_characteristics(x_data, y_data)

            # 2. ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«ÙˆØ±ÙŠØ© Ø§Ù„Ø«Ù„Ø§Ø«
            revolutionary_analysis = self.apply_revolutionary_theories(x_data, y_data)

            # 3. Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ­Ø³ÙŠÙ†
            equation_parameters = self.optimize_equation_parameters(x_data, y_data, shape_analysis)

            # 4. Ø¨Ù†Ø§Ø¡ Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø¹Ø§Ù…
            general_equation = self.construct_general_equation(equation_parameters, shape_analysis)

            # 5. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¯Ù‚Ø© Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø·
            accuracy_score = self.validate_equation_accuracy(x_data, y_data, equation_parameters)

            return {
                'equation_parameters': equation_parameters,
                'general_equation': general_equation,
                'shape_analysis': shape_analysis,
                'revolutionary_analysis': revolutionary_analysis,
                'accuracy_score': accuracy_score,
                'confidence': min(1.0, accuracy_score * shape_analysis.get('pattern_confidence', 0.5))
            }

        except Exception as e:
            return self._get_default_inference_result(str(e))

    def analyze_shape_characteristics(self, x_data, y_data):
        """
        ØªØ­Ù„ÙŠÙ„ Ø®ØµØ§Ø¦Øµ Ø§Ù„Ø´ÙƒÙ„ Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†ÙˆØ¹ ÙˆØ§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ© ÙÙŠ ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø´ÙƒÙ„
        """
        x = np.array(x_data)
        y = np.array(y_data)

        analysis = {}

        # 1. ÙØ­Øµ Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ (Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©)
        is_closed = self._check_curve_closure(x, y)
        analysis['is_closed'] = is_closed

        # 2. ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ…Ø§Ø«Ù„ (Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù…Ù†Ø·Ù‚ create_heart_shape)
        symmetry_analysis = self._analyze_symmetry_patterns(x, y)
        analysis.update(symmetry_analysis)

        # 3. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¯ÙˆØ±ÙŠØ© (Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù…Ù†Ø·Ù‚ create_flower_shape)
        periodicity_analysis = self._analyze_periodicity(x, y)
        analysis.update(periodicity_analysis)

        # 4. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ù…Ùˆ (Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù…Ù†Ø·Ù‚ create_spiral_shape)
        growth_analysis = self._analyze_growth_pattern(x, y)
        analysis.update(growth_analysis)

        # 5. ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ù…Ø­ØªÙ…Ù„
        predicted_shape = self._classify_shape_type(analysis)
        analysis['predicted_shape'] = predicted_shape
        analysis['pattern_confidence'] = self._calculate_pattern_confidence(analysis)

        return analysis

    def _check_curve_closure(self, x, y, tolerance=0.1):
        """
        ÙØ­Øµ Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù…Ù†Ø­Ù†Ù‰ (Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©)
        """
        if len(x) < 3:
            return False

        start_point = np.array([x[0], y[0]])
        end_point = np.array([x[-1], y[-1]])
        distance = np.linalg.norm(end_point - start_point)

        # Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø³Ø§ÙØ© Ø¥Ù„Ù‰ Ø­Ø¬Ù… Ø§Ù„Ø´ÙƒÙ„
        shape_size = max(np.ptp(x), np.ptp(y))
        relative_distance = distance / (shape_size + 1e-10)

        return relative_distance < tolerance

    def _analyze_symmetry_patterns(self, x, y):
        """
        ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØªÙ…Ø§Ø«Ù„ (Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù…Ù†Ø·Ù‚ create_heart_shape)
        """
        symmetry = {}

        # Ù…Ø±ÙƒØ² Ø§Ù„Ø´ÙƒÙ„
        center_x = np.mean(x)
        center_y = np.mean(y)

        # Ø§Ù„ØªÙ…Ø§Ø«Ù„ Ø§Ù„Ø±Ø£Ø³ÙŠ (Ù…Ù‡Ù… Ù„Ù„Ù‚Ù„Ø¨)
        x_centered = x - center_x
        y_centered = y - center_y

        # ÙØ­Øµ Ø§Ù„ØªÙ…Ø§Ø«Ù„ Ø­ÙˆÙ„ Ø§Ù„Ù…Ø­ÙˆØ± Ø§Ù„Ø±Ø£Ø³ÙŠ
        try:
            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†Ù‚Ø§Ø· Ø­Ø³Ø¨ x
            sorted_indices = np.argsort(x_centered)
            x_sorted = x_centered[sorted_indices]
            y_sorted = y_centered[sorted_indices]

            # ÙØ­Øµ Ø§Ù„ØªÙ…Ø§Ø«Ù„
            left_side = x_sorted < 0
            right_side = x_sorted > 0

            if np.sum(left_side) > 0 and np.sum(right_side) > 0:
                # Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠÙ†
                y_left = y_sorted[left_side]
                x_left = -x_sorted[left_side]  # Ø§Ù†Ø¹ÙƒØ§Ø³

                y_right_interp = np.interp(x_left, x_sorted[right_side], y_sorted[right_side])

                if len(y_left) > 0 and len(y_right_interp) > 0:
                    symmetry_error = np.mean(np.abs(y_left - y_right_interp))
                    shape_scale = np.std(y_centered)
                    symmetry['vertical_symmetry'] = max(0, 1 - symmetry_error / (shape_scale + 1e-10))
                else:
                    symmetry['vertical_symmetry'] = 0.5
            else:
                symmetry['vertical_symmetry'] = 0.5

        except:
            symmetry['vertical_symmetry'] = 0.5

        # Ø§Ù„ØªÙ…Ø§Ø«Ù„ Ø§Ù„Ø´Ø¹Ø§Ø¹ÙŠ (Ù…Ù‡Ù… Ù„Ù„Ø²Ù‡Ø±Ø©)
        try:
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ù‚Ø·Ø¨ÙŠØ©
            r = np.sqrt(x_centered**2 + y_centered**2)
            theta = np.arctan2(y_centered, x_centered)

            # ÙØ­Øµ Ø§Ù„Ø¯ÙˆØ±ÙŠØ© ÙÙŠ r
            if len(r) > 10:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… FFT Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¯ÙˆØ±ÙŠØ©
                fft = np.fft.fft(r - np.mean(r))
                power_spectrum = np.abs(fft)**2

                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªØ±Ø¯Ø¯Ø§Øª Ø§Ù„Ù…Ù‡ÙŠÙ…Ù†Ø©
                freqs = np.fft.fftfreq(len(r))
                dominant_freq_idx = np.argmax(power_spectrum[1:len(power_spectrum)//2]) + 1

                if power_spectrum[dominant_freq_idx] > 0.1 * np.sum(power_spectrum):
                    symmetry['radial_symmetry'] = power_spectrum[dominant_freq_idx] / np.sum(power_spectrum)
                    symmetry['radial_frequency'] = abs(freqs[dominant_freq_idx]) * len(r) / (2 * np.pi)
                else:
                    symmetry['radial_symmetry'] = 0.1
                    symmetry['radial_frequency'] = 0
            else:
                symmetry['radial_symmetry'] = 0.1
                symmetry['radial_frequency'] = 0

        except:
            symmetry['radial_symmetry'] = 0.1
            symmetry['radial_frequency'] = 0

        return symmetry

    def _analyze_periodicity(self, x, y):
        """
        ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¯ÙˆØ±ÙŠØ© (Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù…Ù†Ø·Ù‚ create_flower_shape Ùˆ create_wave_pattern)
        """
        periodicity = {}

        try:
            # ÙØ­Øµ Ø§Ù„Ø¯ÙˆØ±ÙŠØ© ÙÙŠ y Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù€ x
            if len(y) > 8:
                # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù…
                y_detrended = y - np.polyval(np.polyfit(x, y, 1), x)

                # Ø§Ø³ØªØ®Ø¯Ø§Ù… FFT
                fft = np.fft.fft(y_detrended)
                freqs = np.fft.fftfreq(len(y), d=np.mean(np.diff(x)))
                power_spectrum = np.abs(fft)**2

                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªØ±Ø¯Ø¯Ø§Øª Ø§Ù„Ù…Ù‡ÙŠÙ…Ù†Ø©
                positive_freqs = freqs[:len(freqs)//2]
                positive_power = power_spectrum[:len(power_spectrum)//2]

                if len(positive_power) > 1:
                    dominant_freq_idx = np.argmax(positive_power[1:]) + 1
                    dominant_frequency = positive_freqs[dominant_freq_idx]

                    periodicity['dominant_frequency'] = abs(dominant_frequency)
                    periodicity['periodicity_strength'] = positive_power[dominant_freq_idx] / np.sum(positive_power)

                    # ØªÙ‚Ø¯ÙŠØ± Ø¹Ø¯Ø¯ Ø§Ù„Ø¯ÙˆØ±Ø§Øª
                    x_range = np.ptp(x)
                    if dominant_frequency > 0:
                        periodicity['estimated_cycles'] = abs(dominant_frequency) * x_range
                    else:
                        periodicity['estimated_cycles'] = 0
                else:
                    periodicity['dominant_frequency'] = 0
                    periodicity['periodicity_strength'] = 0
                    periodicity['estimated_cycles'] = 0
            else:
                periodicity['dominant_frequency'] = 0
                periodicity['periodicity_strength'] = 0
                periodicity['estimated_cycles'] = 0

        except:
            periodicity['dominant_frequency'] = 0
            periodicity['periodicity_strength'] = 0
            periodicity['estimated_cycles'] = 0

        return periodicity

    def _analyze_growth_pattern(self, x, y):
        """
        ØªØ­Ù„ÙŠÙ„ Ù†Ù…Ø· Ø§Ù„Ù†Ù…Ùˆ (Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù…Ù†Ø·Ù‚ create_spiral_shape)
        """
        growth = {}

        try:
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ù‚Ø·Ø¨ÙŠØ©
            center_x = np.mean(x)
            center_y = np.mean(y)

            x_centered = x - center_x
            y_centered = y - center_y

            r = np.sqrt(x_centered**2 + y_centered**2)
            theta = np.arctan2(y_centered, x_centered)

            # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ø²Ø§ÙˆÙŠØ©
            sorted_indices = np.argsort(theta)
            theta_sorted = theta[sorted_indices]
            r_sorted = r[sorted_indices]

            # ÙØ­Øµ Ø§Ù„Ù†Ù…Ùˆ Ø§Ù„Ø®Ø·ÙŠ ÙÙŠ r
            if len(r_sorted) > 3:
                # Ø­Ø³Ø§Ø¨ Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø¨ÙŠÙ† theta Ùˆ r
                correlation = np.corrcoef(theta_sorted, r_sorted)[0, 1]
                growth['radial_growth_correlation'] = abs(correlation) if not np.isnan(correlation) else 0

                # Ø­Ø³Ø§Ø¨ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù…Ùˆ
                if np.ptp(theta_sorted) > 0:
                    growth_rate = np.ptp(r_sorted) / np.ptp(theta_sorted)
                    growth['growth_rate'] = growth_rate
                else:
                    growth['growth_rate'] = 0

                # ÙØ­Øµ Ø§Ù„Ù†Ù…Ùˆ Ø§Ù„Ø­Ù„Ø²ÙˆÙ†ÙŠ
                if abs(correlation) > 0.7 and np.ptp(theta_sorted) > np.pi:
                    growth['is_spiral'] = True
                    # ØªÙ‚Ø¯ÙŠØ± Ø¹Ø¯Ø¯ Ø§Ù„Ù„ÙØ§Øª
                    total_angle = np.ptp(theta_sorted)
                    growth['estimated_turns'] = total_angle / (2 * np.pi)
                else:
                    growth['is_spiral'] = False
                    growth['estimated_turns'] = 0
            else:
                growth['radial_growth_correlation'] = 0
                growth['growth_rate'] = 0
                growth['is_spiral'] = False
                growth['estimated_turns'] = 0

        except:
            growth['radial_growth_correlation'] = 0
            growth['growth_rate'] = 0
            growth['is_spiral'] = False
            growth['estimated_turns'] = 0

        return growth

    def _classify_shape_type(self, analysis):
        """
        ØªØµÙ†ÙŠÙ Ù†ÙˆØ¹ Ø§Ù„Ø´ÙƒÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ (Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©)
        """
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø®ØµØ§Ø¦Øµ
        is_closed = analysis.get('is_closed', False)
        vertical_symmetry = analysis.get('vertical_symmetry', 0)
        radial_symmetry = analysis.get('radial_symmetry', 0)
        radial_frequency = analysis.get('radial_frequency', 0)
        periodicity_strength = analysis.get('periodicity_strength', 0)
        is_spiral = analysis.get('is_spiral', False)

        # Ù…Ù†Ø·Ù‚ Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø­Ø³Ù† (Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©)

        # Ø­Ø³Ø§Ø¨ Ù†Ù‚Ø§Ø· Ù„ÙƒÙ„ Ø´ÙƒÙ„
        shape_scores = {}

        # Ù†Ù‚Ø§Ø· Ø§Ù„Ø­Ù„Ø²ÙˆÙ†
        spiral_score = 0
        if is_spiral:
            spiral_score += 0.5
        if analysis.get('estimated_turns', 0) > 1:
            spiral_score += 0.3
        if analysis.get('radial_growth_correlation', 0) > 0.5:
            spiral_score += 0.2
        shape_scores['spiral'] = spiral_score

        # Ù†Ù‚Ø§Ø· Ø§Ù„Ù…ÙˆØ¬Ø©
        wave_score = 0
        if not is_closed:
            wave_score += 0.4
        if periodicity_strength > 0.2:
            wave_score += 0.4
        if analysis.get('estimated_cycles', 0) > 1:
            wave_score += 0.2
        shape_scores['wave'] = wave_score

        # Ù†Ù‚Ø§Ø· Ø§Ù„Ø²Ù‡Ø±Ø©
        flower_score = 0
        if is_closed:
            flower_score += 0.2
        if radial_frequency > 3:
            flower_score += 0.4
        if radial_symmetry > 0.3:
            flower_score += 0.4
        shape_scores['flower'] = flower_score

        # Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚Ù„Ø¨
        heart_score = 0
        if is_closed:
            heart_score += 0.3
        if vertical_symmetry > 0.6:
            heart_score += 0.4
        if radial_frequency < 3:
            heart_score += 0.2
        if analysis.get('curvature_points', 0) > 2:
            heart_score += 0.1
        shape_scores['heart'] = heart_score

        # Ù†Ù‚Ø§Ø· Ø§Ù„Ø¯Ø§Ø¦Ø±Ø©
        circle_score = 0
        if is_closed:
            circle_score += 0.4
        if vertical_symmetry > 0.4:
            circle_score += 0.2
        if radial_symmetry < 0.4:  # Ø§Ù„Ø¯Ø§Ø¦Ø±Ø© Ù„Ù‡Ø§ ØªÙ…Ø§Ø«Ù„ Ø´Ø¹Ø§Ø¹ÙŠ Ù…Ù†Ø®ÙØ¶
            circle_score += 0.2
        if radial_frequency < 2:
            circle_score += 0.2
        shape_scores['circle'] = circle_score

        # Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù†Ù‚Ø§Ø·
        if shape_scores:
            best_shape = max(shape_scores, key=shape_scores.get)
            best_score = shape_scores[best_shape]

            # ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ù†Ù‚Ø§Ø· Ø£ÙƒØ¨Ø± Ù…Ù† Ø­Ø¯ Ø£Ø¯Ù†Ù‰
            if best_score > 0.5:
                return best_shape

        return 'unknown'

    def _calculate_pattern_confidence(self, analysis):
        """
        Ø­Ø³Ø§Ø¨ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© ÙÙŠ ØªØµÙ†ÙŠÙ Ø§Ù„Ù†Ù…Ø·
        """
        predicted_shape = analysis.get('predicted_shape', 'unknown')

        if predicted_shape == 'unknown':
            return 0.3

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù‚ÙˆØ© Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù…Ù…ÙŠØ²Ø©
        confidence_factors = []

        if predicted_shape == 'circle':
            confidence_factors.append(analysis.get('vertical_symmetry', 0))
            confidence_factors.append(1 - analysis.get('radial_symmetry', 0))
        elif predicted_shape == 'heart':
            confidence_factors.append(analysis.get('vertical_symmetry', 0))
            confidence_factors.append(1 - analysis.get('radial_frequency', 0) / 5)
        elif predicted_shape == 'flower':
            confidence_factors.append(analysis.get('radial_symmetry', 0))
            confidence_factors.append(min(1, analysis.get('radial_frequency', 0) / 5))
        elif predicted_shape == 'spiral':
            confidence_factors.append(analysis.get('radial_growth_correlation', 0))
            confidence_factors.append(min(1, analysis.get('estimated_turns', 0) / 3))
        elif predicted_shape == 'wave':
            confidence_factors.append(analysis.get('periodicity_strength', 0))
            confidence_factors.append(1 - int(analysis.get('is_closed', False)))

        if confidence_factors:
            return np.mean(confidence_factors)
        else:
            return 0.5

    def optimize_equation_parameters(self, x_data, y_data, shape_analysis):
        """
        ØªØ­Ø³ÙŠÙ† Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø¹Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
        Ø§Ù„Ø¹ÙƒØ³ Ø§Ù„Ø¯Ù‚ÙŠÙ‚ Ù„Ø¹Ù…Ù„ÙŠØ© Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø£Ø´ÙƒØ§Ù„ ÙÙŠ Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©
        """
        x = np.array(x_data)
        y = np.array(y_data)

        predicted_shape = shape_analysis.get('predicted_shape', 'unknown')

        # ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø´ÙƒÙ„ (Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©)
        if predicted_shape in self.known_shape_patterns:
            pattern = self.known_shape_patterns[predicted_shape]
            n_sigmoid = pattern['sigmoid_components']
            n_linear = pattern['linear_components']
        else:
            # ØªÙ‚Ø¯ÙŠØ± ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            complexity = shape_analysis.get('periodicity_strength', 0) + shape_analysis.get('radial_symmetry', 0)
            n_sigmoid = min(self.max_sigmoid_components, max(1, int(complexity * 5) + 1))
            n_linear = min(self.max_linear_components, max(0, int(complexity * 2)))

        # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª
        try:
            if predicted_shape == 'circle':
                parameters = self._optimize_circle_parameters(x, y)
            elif predicted_shape == 'heart':
                parameters = self._optimize_heart_parameters(x, y)
            elif predicted_shape == 'flower':
                parameters = self._optimize_flower_parameters(x, y, shape_analysis)
            elif predicted_shape == 'spiral':
                parameters = self._optimize_spiral_parameters(x, y, shape_analysis)
            elif predicted_shape == 'wave':
                parameters = self._optimize_wave_parameters(x, y, shape_analysis)
            else:
                parameters = self._optimize_general_parameters(x, y, n_sigmoid, n_linear)

        except Exception as e:
            # ÙÙŠ Ø­Ø§Ù„Ø© ÙØ´Ù„ Ø§Ù„ØªØ­Ø³ÙŠÙ†ØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
            parameters = self._get_default_parameters(n_sigmoid, n_linear)
            parameters['optimization_error'] = str(e)

        return parameters

    def _optimize_circle_parameters(self, x, y):
        """
        ØªØ­Ø³ÙŠÙ† Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø¯Ø§Ø¦Ø±Ø© (Ø¹ÙƒØ³ create_circle ÙÙŠ Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©)
        """
        # Ø§Ù„Ø¯Ø§Ø¦Ø±Ø©: x = size * sigmoid_wave(t, phase=Ï€/2), y = size * sigmoid_wave(t, phase=0)

        # ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø­Ø¬Ù…
        center_x = np.mean(x)
        center_y = np.mean(y)
        radius = np.mean(np.sqrt((x - center_x)**2 + (y - center_y)**2))

        # Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯ Ù„Ù„Ø¯Ø§Ø¦Ø±Ø©
        sigmoid_components = [
            {
                'alpha': radius,
                'k': 2.0,  # steepness Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©
                'x0': 0.0,
                'n': 1,
                'component_type': 'x_component'
            },
            {
                'alpha': radius,
                'k': 2.0,
                'x0': np.pi/2,  # phase difference
                'n': 1,
                'component_type': 'y_component'
            }
        ]

        linear_components = []  # Ø§Ù„Ø¯Ø§Ø¦Ø±Ø© Ù„Ø§ ØªØ­ØªØ§Ø¬ Ù…ÙƒÙˆÙ†Ø§Øª Ø®Ø·ÙŠØ©

        return {
            'sigmoid_components': sigmoid_components,
            'linear_components': linear_components,
            'shape_type': 'circle',
            'estimated_size': radius,
            'center': (center_x, center_y)
        }

    def _optimize_heart_parameters(self, x, y):
        """
        ØªØ­Ø³ÙŠÙ† Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù‚Ù„Ø¨ (Ø¹ÙƒØ³ create_heart_shape ÙÙŠ Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©)
        """
        # Ø§Ù„Ù‚Ù„Ø¨: x = size * 16 * sinÂ³(t), y = size * (13*cos(t) - 5*cos(2t) - 2*cos(3t) - cos(4t))

        # ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø­Ø¬Ù…
        size = max(np.ptp(x), np.ptp(y)) / 32  # ØªÙ‚Ø¯ÙŠØ± ØªÙ‚Ø±ÙŠØ¨ÙŠ

        # Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯ Ù„Ù„Ù‚Ù„Ø¨ (Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©)
        sigmoid_components = [
            {
                'alpha': size * 16,
                'k': 3.0,  # steepness Ù„Ù„Ù‚Ù„Ø¨
                'x0': 0.0,
                'n': 1,
                'component_type': 'sin_cubed',
                'power': 3
            },
            {
                'alpha': size * 13,
                'k': 3.0,
                'x0': np.pi/2,  # cos approximation
                'n': 1,
                'component_type': 'cos_1'
            },
            {
                'alpha': -size * 5,
                'k': 3.0,
                'x0': np.pi/2,
                'n': 1,
                'component_type': 'cos_2',
                'frequency': 2
            },
            {
                'alpha': -size * 2,
                'k': 3.0,
                'x0': np.pi/2,
                'n': 1,
                'component_type': 'cos_3',
                'frequency': 3
            },
            {
                'alpha': -size,
                'k': 3.0,
                'x0': np.pi/2,
                'n': 1,
                'component_type': 'cos_4',
                'frequency': 4
            }
        ]

        linear_components = []

        return {
            'sigmoid_components': sigmoid_components,
            'linear_components': linear_components,
            'shape_type': 'heart',
            'estimated_size': size,
            'style': 'classic'
        }

    def _optimize_flower_parameters(self, x, y, shape_analysis):
        """
        ØªØ­Ø³ÙŠÙ† Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø²Ù‡Ø±Ø© (Ø¹ÙƒØ³ create_flower_shape ÙÙŠ Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©)
        """
        # Ø§Ù„Ø²Ù‡Ø±Ø©: r(t) = size * (1 + 0.4*cos(petals*t)), x = r*cos(t), y = r*sin(t)

        # ØªÙ‚Ø¯ÙŠØ± Ø¹Ø¯Ø¯ Ø§Ù„Ø¨ØªÙ„Ø§Øª
        petals = max(3, int(shape_analysis.get('radial_frequency', 5)))

        # ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø­Ø¬Ù…
        center_x = np.mean(x)
        center_y = np.mean(y)
        max_radius = np.max(np.sqrt((x - center_x)**2 + (y - center_y)**2))
        size = max_radius / 1.4  # ØªÙ‚Ø¯ÙŠØ± ØªÙ‚Ø±ÙŠØ¨ÙŠ

        sigmoid_components = [
            {
                'alpha': size,
                'k': 2.0,
                'x0': 0.0,
                'n': 1,
                'component_type': 'base_radius'
            },
            {
                'alpha': size * 0.4,
                'k': 2.0,
                'x0': np.pi/2,
                'n': 1,
                'component_type': 'petal_modulation',
                'frequency': petals
            },
            {
                'alpha': 1.0,
                'k': 2.0,
                'x0': np.pi/2,
                'n': 1,
                'component_type': 'cos_component'
            }
        ]

        linear_components = []

        return {
            'sigmoid_components': sigmoid_components,
            'linear_components': linear_components,
            'shape_type': 'flower',
            'estimated_size': size,
            'petals': petals,
            'style': 'rose'
        }

    def _optimize_spiral_parameters(self, x, y, shape_analysis):
        """
        ØªØ­Ø³ÙŠÙ† Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø­Ù„Ø²ÙˆÙ† (Ø¹ÙƒØ³ create_spiral_shape ÙÙŠ Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©)
        """
        # Ø§Ù„Ø­Ù„Ø²ÙˆÙ†: r(t) = size * t/(2Ï€*turns), x = r*cos(t), y = r*sin(t)

        # ØªÙ‚Ø¯ÙŠØ± Ø¹Ø¯Ø¯ Ø§Ù„Ù„ÙØ§Øª
        turns = max(1, int(shape_analysis.get('estimated_turns', 2)))

        # ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø­Ø¬Ù…
        center_x = np.mean(x)
        center_y = np.mean(y)
        max_radius = np.max(np.sqrt((x - center_x)**2 + (y - center_y)**2))
        size = max_radius / turns if turns > 0 else max_radius

        sigmoid_components = [
            {
                'alpha': 1.0,
                'k': 2.0,
                'x0': np.pi/2,
                'n': 1,
                'component_type': 'cos_component'
            },
            {
                'alpha': 1.0,
                'k': 2.0,
                'x0': 0.0,
                'n': 1,
                'component_type': 'sin_component'
            }
        ]

        linear_components = [
            {
                'beta': size / (2 * np.pi * turns),
                'gamma': 0.0,
                'n': 1,
                'component_type': 'radial_growth'
            }
        ]

        return {
            'sigmoid_components': sigmoid_components,
            'linear_components': linear_components,
            'shape_type': 'spiral',
            'estimated_size': size,
            'turns': turns,
            'style': 'fibonacci'
        }

    def _optimize_wave_parameters(self, x, y, shape_analysis):
        """
        ØªØ­Ø³ÙŠÙ† Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù…ÙˆØ¬Ø© (Ø¹ÙƒØ³ create_wave_pattern ÙÙŠ Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©)
        """
        # Ø§Ù„Ù…ÙˆØ¬Ø©: y = amplitude * sigmoid_wave(x, frequency)

        # ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø³Ø¹Ø©
        amplitude = (np.max(y) - np.min(y)) / 2

        # ØªÙ‚Ø¯ÙŠØ± Ø§Ù„ØªØ±Ø¯Ø¯
        frequency = shape_analysis.get('dominant_frequency', 1.0)
        if frequency == 0:
            frequency = 1.0

        sigmoid_components = [
            {
                'alpha': amplitude,
                'k': 2.0,
                'x0': 0.0,
                'n': 1,
                'component_type': 'wave_pattern',
                'frequency': frequency
            }
        ]

        linear_components = []

        return {
            'sigmoid_components': sigmoid_components,
            'linear_components': linear_components,
            'shape_type': 'wave',
            'amplitude': amplitude,
            'frequency': frequency,
            'style': 'sine'
        }

    def _optimize_general_parameters(self, x, y, n_sigmoid, n_linear):
        """
        ØªØ­Ø³ÙŠÙ† Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¹Ø§Ù…Ø© Ù„Ù„Ø£Ø´ÙƒØ§Ù„ ØºÙŠØ± Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©
        """
        # ØªÙ‚Ø¯ÙŠØ± Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¹Ø§Ù…Ø©
        y_range = np.ptp(y)
        x_range = np.ptp(x)

        sigmoid_components = []
        for i in range(n_sigmoid):
            sigmoid_components.append({
                'alpha': y_range / n_sigmoid,
                'k': 1.0,
                'x0': np.min(x) + i * x_range / n_sigmoid,
                'n': 1,
                'component_type': f'general_sigmoid_{i}'
            })

        linear_components = []
        for i in range(n_linear):
            linear_components.append({
                'beta': y_range / x_range if x_range > 0 else 0,
                'gamma': np.mean(y),
                'n': 1,
                'component_type': f'general_linear_{i}'
            })

        return {
            'sigmoid_components': sigmoid_components,
            'linear_components': linear_components,
            'shape_type': 'general',
            'optimization_method': 'general_estimation'
        }

    def apply_revolutionary_theories(self, x_data, y_data):
        """
        ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«ÙˆØ±ÙŠØ© Ø§Ù„Ø«Ù„Ø§Ø« ÙÙŠ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø·
        Ù…Ø·Ø§Ø¨Ù‚ Ù„ØªØ·Ø¨ÙŠÙ‚Ù‡Ø§ ÙÙŠ Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©
        """
        x = np.array(x_data)
        y = np.array(y_data)

        revolutionary_analysis = {}

        # 1. Ù†Ø¸Ø±ÙŠØ© Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙØ± - ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø²Ù†
        zero_duality = self._apply_zero_duality_theory(x, y)
        revolutionary_analysis['zero_duality'] = zero_duality

        # 2. Ù†Ø¸Ø±ÙŠØ© ØªØ¹Ø§Ù…Ø¯ Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯ - ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¹Ø§Ù…Ø¯
        perpendicular_opposites = self._apply_perpendicular_opposites_theory(x, y)
        revolutionary_analysis['perpendicular_opposites'] = perpendicular_opposites

        # 3. Ù†Ø¸Ø±ÙŠØ© Ø§Ù„ÙØªØ§Ø¦Ù„ - ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ±Ø§Ø¨Ø·
        filament_theory = self._apply_filament_theory(x, y)
        revolutionary_analysis['filament_theory'] = filament_theory

        return revolutionary_analysis

    def _apply_zero_duality_theory(self, x, y):
        """
        ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ© Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙØ± (Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©)
        """
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†Ù‚Ø§Ø· Ø§Ù„ØªÙˆØ§Ø²Ù† ÙˆØ§Ù„ØµÙØ±
        zero_crossings = []
        for i in range(len(y) - 1):
            if y[i] * y[i+1] < 0:
                zero_x = x[i] - y[i] * (x[i+1] - x[i]) / (y[i+1] - y[i])
                zero_crossings.append(zero_x)

        # Ø­Ø³Ø§Ø¨ Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„ØªÙˆØ§Ø²Ù†
        positive_area = np.sum(y[y > 0])
        negative_area = np.sum(y[y < 0])
        total_area = abs(positive_area) + abs(negative_area)

        if total_area > 0:
            balance_factor = 1 - abs(positive_area + negative_area) / total_area
        else:
            balance_factor = 1.0

        return {
            'zero_crossings': zero_crossings,
            'zero_count': len(zero_crossings),
            'positive_area': positive_area,
            'negative_area': negative_area,
            'balance_factor': balance_factor,
            'zero_proximity': abs(np.mean(y)) / (np.std(y) + 1e-10)
        }

    def _apply_perpendicular_opposites_theory(self, x, y):
        """
        ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ© ØªØ¹Ø§Ù…Ø¯ Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯ (Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©)
        """
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø´ØªÙ‚Ø§Øª Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ¹Ø§Ù…Ø¯
        if len(x) > 2:
            dx = np.diff(x)
            dy = np.diff(y)
            slopes = dy / (dx + 1e-10)

            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ØªØºÙŠÙŠØ±Ø§Øª Ø­Ø§Ø¯Ø© ÙÙŠ Ø§Ù„Ù…ÙŠÙ„ (ØªØ¹Ø§Ù…Ø¯)
            slope_changes = np.abs(np.diff(slopes))
            perpendicular_threshold = np.std(slope_changes) * 2

            perpendicular_points = np.where(slope_changes > perpendicular_threshold)[0]

            # Ø­Ø³Ø§Ø¨ Ø²ÙˆØ§ÙŠØ§ Ø§Ù„ØªØ¹Ø§Ù…Ø¯
            perpendicular_angles = []
            for i in perpendicular_points:
                if i > 0 and i < len(slopes) - 1:
                    angle1 = np.arctan(slopes[i])
                    angle2 = np.arctan(slopes[i+1])
                    angle_diff = abs(angle2 - angle1)
                    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø£Ù‚Ø±Ø¨ Ø²Ø§ÙˆÙŠØ© ØªØ¹Ø§Ù…Ø¯
                    perpendicular_angle = min(angle_diff, np.pi - angle_diff, abs(angle_diff - np.pi/2))
                    perpendicular_angles.append(perpendicular_angle)

            return {
                'perpendicular_points': len(perpendicular_points),
                'perpendicular_angles': perpendicular_angles,
                'average_perpendicular_angle': np.mean(perpendicular_angles) if perpendicular_angles else 0,
                'slope_variation': np.std(slopes),
                'max_slope_change': np.max(slope_changes) if len(slope_changes) > 0 else 0
            }
        else:
            return {
                'perpendicular_points': 0,
                'perpendicular_angles': [],
                'average_perpendicular_angle': 0,
                'slope_variation': 0,
                'max_slope_change': 0
            }

    def _apply_filament_theory(self, x, y):
        """
        ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ© Ø§Ù„ÙØªØ§Ø¦Ù„ (Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©)
        """
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ±Ø§Ø¨Ø· ÙˆØ§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©
        filament_structure = []

        # Ø§Ù„ÙØªÙŠÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        base_filament = {
            'id': 'base_filament',
            'type': 'fundamental',
            'energy': np.var(y),
            'stability': 1 - np.std(np.diff(y)) / (np.std(y) + 1e-10),
            'connectivity': len(x)
        }
        filament_structure.append(base_filament)

        # ÙØªØ§Ø¦Ù„ ÙØ±Ø¹ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯
        complexity_level = min(3, int(np.std(y) * len(x) / 100))

        for level in range(complexity_level):
            # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡
            segment_size = len(x) // (2 ** (level + 1))
            if segment_size < 3:
                break

            for i in range(2 ** (level + 1)):
                start_idx = i * segment_size
                end_idx = min((i + 1) * segment_size, len(x))

                if end_idx - start_idx > 2:
                    segment_y = y[start_idx:end_idx]

                    filament = {
                        'id': f'filament_level_{level}_segment_{i}',
                        'type': f'level_{level}',
                        'parent': filament_structure[-1]['id'] if level == 0 else f'filament_level_{level-1}_segment_{i//2}',
                        'energy': np.var(segment_y),
                        'stability': 1 - np.std(np.diff(segment_y)) / (np.std(segment_y) + 1e-10),
                        'connectivity': len(segment_y),
                        'start_idx': start_idx,
                        'end_idx': end_idx
                    }
                    filament_structure.append(filament)

        return {
            'filament_structure': filament_structure,
            'complexity_level': complexity_level,
            'total_filaments': len(filament_structure),
            'average_energy': np.mean([f['energy'] for f in filament_structure]),
            'average_stability': np.mean([f['stability'] for f in filament_structure])
        }

    def construct_general_equation(self, parameters, shape_analysis):
        """
        Ø¨Ù†Ø§Ø¡ Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø¹Ø§Ù… Ù…Ù† Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù…Ø³ØªÙ†Ø¨Ø·Ø©
        """
        sigmoid_components = parameters.get('sigmoid_components', [])
        linear_components = parameters.get('linear_components', [])
        shape_type = parameters.get('shape_type', 'unknown')

        # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ù†ØµÙŠØ©
        equation_parts = []

        # Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯ÙŠØ©
        for i, comp in enumerate(sigmoid_components):
            alpha = comp.get('alpha', 1.0)
            k = comp.get('k', 1.0)
            x0 = comp.get('x0', 0.0)
            n = comp.get('n', 1)
            comp_type = comp.get('component_type', f'sigmoid_{i}')

            if 'frequency' in comp:
                freq = comp['frequency']
                equation_parts.append(f"{alpha:.3f} Ã— Ïƒ({freq}t; k={k:.2f}, xâ‚€={x0:.3f}, n={n})")
            else:
                equation_parts.append(f"{alpha:.3f} Ã— Ïƒ(t; k={k:.2f}, xâ‚€={x0:.3f}, n={n})")

        # Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ø®Ø·ÙŠØ©
        for i, comp in enumerate(linear_components):
            beta = comp.get('beta', 1.0)
            gamma = comp.get('gamma', 0.0)
            equation_parts.append(f"{beta:.3f}t + {gamma:.3f}")

        # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø©
        if equation_parts:
            general_equation = "fÌ‚(t) = " + " + ".join(equation_parts)
        else:
            general_equation = "fÌ‚(t) = Ïƒ(t; k=1.0, xâ‚€=0.0, n=1)"

        return {
            'general_equation': general_equation,
            'equation_type': shape_type,
            'sigmoid_components_count': len(sigmoid_components),
            'linear_components_count': len(linear_components),
            'total_parameters': len(sigmoid_components) * 4 + len(linear_components) * 2
        }

    def validate_equation_accuracy(self, x_data, y_data, parameters):
        """
        Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¯Ù‚Ø© Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ù…Ø³ØªÙ†Ø¨Ø·Ø©
        """
        try:
            # Ø¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª
            reconstructed_y = self._reconstruct_data_from_parameters(x_data, parameters)

            # Ø­Ø³Ø§Ø¨ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø¯Ù‚Ø©
            mse = np.mean((y_data - reconstructed_y) ** 2)
            rmse = np.sqrt(mse)

            # Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·
            correlation = np.corrcoef(y_data, reconstructed_y)[0, 1]
            if np.isnan(correlation):
                correlation = 0

            # R-squared
            ss_res = np.sum((y_data - reconstructed_y) ** 2)
            ss_tot = np.sum((y_data - np.mean(y_data)) ** 2)
            r_squared = 1 - (ss_res / (ss_tot + 1e-10))

            # Ù†Ù‚Ø§Ø· Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
            accuracy_score = max(0, min(1, (abs(correlation) + max(0, r_squared)) / 2))

            return {
                'mse': mse,
                'rmse': rmse,
                'correlation': correlation,
                'r_squared': r_squared,
                'accuracy_score': accuracy_score
            }

        except Exception as e:
            return {
                'mse': float('inf'),
                'rmse': float('inf'),
                'correlation': 0,
                'r_squared': 0,
                'accuracy_score': 0,
                'error': str(e)
            }

    def _reconstruct_data_from_parameters(self, x_data, parameters):
        """
        Ø¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª (ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø¹Ø§Ù…)
        """
        x = np.array(x_data)
        result = np.zeros_like(x)

        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ø³ÙŠØ¬Ù…ÙˆÙŠØ¯ÙŠØ©
        for comp in parameters.get('sigmoid_components', []):
            alpha = comp.get('alpha', 1.0)
            k = comp.get('k', 1.0)
            x0 = comp.get('x0', 0.0)
            n = comp.get('n', 1)
            frequency = comp.get('frequency', 1)

            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ±Ø¯Ø¯ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
            if frequency != 1:
                x_modified = x * frequency
            else:
                x_modified = x

            sigmoid_part = baserah_sigmoid(x_modified, alpha, k, x0, n)

            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù‚ÙˆØ© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ÙˆØ¬ÙˆØ¯Ø©
            if 'power' in comp:
                sigmoid_part = sigmoid_part ** comp['power']

            result += sigmoid_part

        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ø®Ø·ÙŠØ©
        for comp in parameters.get('linear_components', []):
            beta = comp.get('beta', 1.0)
            gamma = comp.get('gamma', 0.0)
            n = comp.get('n', 1)

            linear_part = baserah_linear(x, beta, gamma, n)
            result += linear_part

        return result

    def _get_default_parameters(self, n_sigmoid=1, n_linear=0):
        """
        Ø¥Ø±Ø¬Ø§Ø¹ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠØ© ÙÙŠ Ø­Ø§Ù„Ø© ÙØ´Ù„ Ø§Ù„ØªØ­Ø³ÙŠÙ†
        """
        sigmoid_components = []
        for i in range(n_sigmoid):
            sigmoid_components.append({
                'alpha': 1.0,
                'k': 1.0,
                'x0': 0.0,
                'n': 1,
                'component_type': f'default_sigmoid_{i}'
            })

        linear_components = []
        for i in range(n_linear):
            linear_components.append({
                'beta': 0.0,
                'gamma': 0.0,
                'n': 1,
                'component_type': f'default_linear_{i}'
            })

        return {
            'sigmoid_components': sigmoid_components,
            'linear_components': linear_components,
            'shape_type': 'default',
            'optimization_status': 'failed_using_defaults'
        }

    def _get_default_inference_result(self, error_message=""):
        """
        Ø¥Ø±Ø¬Ø§Ø¹ Ù†ØªÙŠØ¬Ø© Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§ÙØªØ±Ø§Ø¶ÙŠØ© ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£
        """
        return {
            'equation_parameters': self._get_default_parameters(),
            'general_equation': {
                'general_equation': 'fÌ‚(t) = Ïƒ(t; k=1.0, xâ‚€=0.0, n=1)',
                'equation_type': 'default',
                'sigmoid_components_count': 1,
                'linear_components_count': 0,
                'total_parameters': 4
            },
            'shape_analysis': {
                'predicted_shape': 'unknown',
                'pattern_confidence': 0.1
            },
            'revolutionary_analysis': {},
            'accuracy_score': 0.1,
            'confidence': 0.1,
            'error': error_message
        }
        
    def analyze_data_structure(self, x, y):
        """
        ØªØ­Ù„ÙŠÙ„ Ø¹Ù…ÙŠÙ‚ Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø«ÙˆØ±ÙŠØ©
        """
        analysis = {}
        
        try:
            x = np.array(x)
            y = np.array(y)
            
            if len(x) == 0 or len(y) == 0:
                return self._get_default_analysis()
            
            # 1. ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ© Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙØ± - ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø²Ù†
            analysis['zero_duality'] = self._analyze_zero_duality(x, y)
            
            # 2. ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ© ØªØ¹Ø§Ù…Ø¯ Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯ - ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ…Ø§Ø«Ù„ ÙˆØ§Ù„ØªØ¶Ø§Ø¯
            analysis['perpendicular_opposites'] = self._analyze_perpendicular_opposites(x, y)
            
            # 3. ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ© Ø§Ù„ÙØªØ§Ø¦Ù„ - ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ ÙˆØ§Ù„Ø¨Ù†ÙŠØ©
            analysis['filament_structure'] = self._analyze_filament_structure(x, y)
            
            # 4. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
            analysis['mathematical_properties'] = self._analyze_mathematical_properties(x, y)
            
            # 5. ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
            analysis['function_type'] = self._determine_function_type(x, y, analysis)
            
        except Exception as e:
            analysis = self._get_default_analysis()
            analysis['error'] = str(e)
            
        return analysis
    
    def _analyze_zero_duality(self, x, y):
        """
        ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ© Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„ØµÙØ± - ØªØ­Ù„ÙŠÙ„ Ù†Ù‚Ø§Ø· Ø§Ù„ØªÙˆØ§Ø²Ù† ÙˆØ§Ù„ØµÙØ±
        """
        duality_analysis = {}
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†Ù‚Ø§Ø· Ø§Ù„ØµÙØ±
        zero_crossings = []
        for i in range(len(y) - 1):
            if y[i] * y[i+1] < 0:  # ØªØºÙŠÙŠØ± Ø§Ù„Ø¥Ø´Ø§Ø±Ø©
                # ØªÙ‚Ø¯ÙŠØ± Ù†Ù‚Ø·Ø© Ø§Ù„ØµÙØ± Ø¨Ø¯Ù‚Ø© Ø£ÙƒØ¨Ø±
                zero_x = x[i] - y[i] * (x[i+1] - x[i]) / (y[i+1] - y[i])
                zero_crossings.append(zero_x)
        
        duality_analysis['zero_crossings'] = zero_crossings
        duality_analysis['zero_count'] = len(zero_crossings)
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø²Ù† Ø­ÙˆÙ„ Ø§Ù„ØµÙØ±
        y_positive = np.sum(y > 0)
        y_negative = np.sum(y < 0)
        total_points = len(y)
        
        if total_points > 0:
            duality_analysis['positive_ratio'] = y_positive / total_points
            duality_analysis['negative_ratio'] = y_negative / total_points
            duality_analysis['balance_factor'] = 1 - abs(y_positive - y_negative) / total_points
        else:
            duality_analysis['positive_ratio'] = 0.5
            duality_analysis['negative_ratio'] = 0.5
            duality_analysis['balance_factor'] = 1.0
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙˆØ³Ø· ÙˆØ§Ù„Ø§Ù†Ø­Ø±Ø§Ù
        duality_analysis['mean_value'] = np.mean(y)
        duality_analysis['std_value'] = np.std(y)
        duality_analysis['zero_proximity'] = abs(np.mean(y)) / (np.std(y) + 1e-10)
        
        return duality_analysis
    
    def _analyze_perpendicular_opposites(self, x, y):
        """
        ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ© ØªØ¹Ø§Ù…Ø¯ Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯ - ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ…Ø§Ø«Ù„ ÙˆØ§Ù„ØªØ¹Ø§Ù…Ø¯
        """
        perpendicular_analysis = {}
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ…Ø§Ø«Ù„
        center_x = np.mean(x)
        center_y = np.mean(y)
        
        # ÙØ­Øµ Ø§Ù„ØªÙ…Ø§Ø«Ù„ Ø­ÙˆÙ„ Ø§Ù„Ù…Ø­Ø§ÙˆØ±
        x_centered = x - center_x
        y_centered = y - center_y
        
        # ØªÙ…Ø§Ø«Ù„ Ø­ÙˆÙ„ Ø§Ù„Ù…Ø­ÙˆØ± Ø§Ù„Ø±Ø£Ø³ÙŠ
        y_reflected = np.interp(-x_centered, x_centered, y_centered)
        vertical_symmetry = 1 - np.mean(np.abs(y_centered - y_reflected)) / (np.std(y_centered) + 1e-10)
        
        # ØªÙ…Ø§Ø«Ù„ Ø­ÙˆÙ„ Ø§Ù„Ù…Ø­ÙˆØ± Ø§Ù„Ø£ÙÙ‚ÙŠ
        horizontal_symmetry = 1 - np.mean(np.abs(y_centered + y_centered)) / (2 * np.std(y_centered) + 1e-10)
        
        perpendicular_analysis['vertical_symmetry'] = max(0, min(1, vertical_symmetry))
        perpendicular_analysis['horizontal_symmetry'] = max(0, min(1, horizontal_symmetry))
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø²ÙˆØ§ÙŠØ§ ÙˆØ§Ù„ØªØ¹Ø§Ù…Ø¯
        if len(x) > 2:
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø´ØªÙ‚Ø© Ø§Ù„Ø¹Ø¯Ø¯ÙŠØ©
            dx = np.diff(x)
            dy = np.diff(y)
            slopes = dy / (dx + 1e-10)
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ¹Ø§Ù…Ø¯ (ØªØºÙŠÙŠØ± Ø­Ø§Ø¯ ÙÙŠ Ø§Ù„Ù…ÙŠÙ„)
            slope_changes = np.abs(np.diff(slopes))
            perpendicular_points = find_peaks(slope_changes, height=np.std(slope_changes))[0]
            
            perpendicular_analysis['perpendicular_points'] = len(perpendicular_points)
            perpendicular_analysis['slope_variation'] = np.std(slopes)
            perpendicular_analysis['max_slope_change'] = np.max(slope_changes) if len(slope_changes) > 0 else 0
        else:
            perpendicular_analysis['perpendicular_points'] = 0
            perpendicular_analysis['slope_variation'] = 0
            perpendicular_analysis['max_slope_change'] = 0
        
        return perpendicular_analysis
    
    def _analyze_filament_structure(self, x, y):
        """
        ØªØ·Ø¨ÙŠÙ‚ Ù†Ø¸Ø±ÙŠØ© Ø§Ù„ÙØªØ§Ø¦Ù„ - ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø© ÙˆØ§Ù„ØªØ±Ø§Ø¨Ø·
        """
        filament_analysis = {}
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯
        # 1. ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ø´ÙƒÙ„ (Ø¹Ø¯Ø¯ Ø§Ù„Ø§Ù†Ø­Ù†Ø§Ø¡Ø§Øª)
        if len(y) > 4:
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø´ØªÙ‚Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© (Ø§Ù„Ø§Ù†Ø­Ù†Ø§Ø¡)
            spline = UnivariateSpline(x, y, s=0)
            second_derivative = spline.derivative(2)(x)
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†Ù‚Ø§Ø· Ø§Ù„Ø§Ù†Ø­Ù†Ø§Ø¡
            curvature_peaks = find_peaks(np.abs(second_derivative), height=np.std(second_derivative))[0]
            filament_analysis['curvature_points'] = len(curvature_peaks)
            filament_analysis['max_curvature'] = np.max(np.abs(second_derivative))
            filament_analysis['mean_curvature'] = np.mean(np.abs(second_derivative))
        else:
            filament_analysis['curvature_points'] = 0
            filament_analysis['max_curvature'] = 0
            filament_analysis['mean_curvature'] = 0
        
        # 2. ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ±Ø§Ø¨Ø· ÙˆØ§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ©
        # ÙØ­Øµ Ø§Ù„ÙØ¬ÙˆØ§Øª ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        x_diffs = np.diff(x)
        gap_threshold = 3 * np.median(x_diffs)
        gaps = np.sum(x_diffs > gap_threshold)
        
        filament_analysis['data_gaps'] = gaps
        filament_analysis['continuity_score'] = 1 - gaps / len(x_diffs) if len(x_diffs) > 0 else 1
        
        # 3. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¯ÙˆØ±ÙŠØ© ÙˆØ§Ù„ØªÙƒØ±Ø§Ø±
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… FFT Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¯ÙˆØ±ÙŠØ©
        if len(y) > 8:
            fft = np.fft.fft(y - np.mean(y))
            frequencies = np.fft.fftfreq(len(y))
            power_spectrum = np.abs(fft) ** 2
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªØ±Ø¯Ø¯Ø§Øª Ø§Ù„Ù…Ù‡ÙŠÙ…Ù†Ø©
            dominant_freq_idx = np.argmax(power_spectrum[1:len(power_spectrum)//2]) + 1
            dominant_frequency = frequencies[dominant_freq_idx]
            
            filament_analysis['dominant_frequency'] = abs(dominant_frequency)
            filament_analysis['periodicity_strength'] = power_spectrum[dominant_freq_idx] / np.sum(power_spectrum)
        else:
            filament_analysis['dominant_frequency'] = 0
            filament_analysis['periodicity_strength'] = 0
        
        # 4. Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ
        complexity_factors = [
            filament_analysis['curvature_points'] / 10,  # Ø¹Ø¯Ø¯ Ù†Ù‚Ø§Ø· Ø§Ù„Ø§Ù†Ø­Ù†Ø§Ø¡
            filament_analysis['periodicity_strength'],    # Ù‚ÙˆØ© Ø§Ù„Ø¯ÙˆØ±ÙŠØ©
            1 - filament_analysis['continuity_score'],    # Ø¹Ø¯Ù… Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ©
            filament_analysis['dominant_frequency'] * 10  # Ø§Ù„ØªØ±Ø¯Ø¯ Ø§Ù„Ù…Ù‡ÙŠÙ…Ù†
        ]
        
        filament_analysis['complexity_level'] = min(5, sum(complexity_factors))
        
        return filament_analysis
    
    def _analyze_mathematical_properties(self, x, y):
        """
        ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
        """
        properties = {}
        
        # Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        properties['x_range'] = (np.min(x), np.max(x))
        properties['y_range'] = (np.min(y), np.max(y))
        properties['data_points'] = len(x)
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù…
        if len(x) > 1:
            correlation = np.corrcoef(x, y)[0, 1]
            properties['correlation'] = correlation if not np.isnan(correlation) else 0
            
            # Ø§Ù„Ù…ÙŠÙ„ Ø§Ù„Ø¹Ø§Ù…
            slope, intercept = np.polyfit(x, y, 1)
            properties['general_slope'] = slope
            properties['general_intercept'] = intercept
        else:
            properties['correlation'] = 0
            properties['general_slope'] = 0
            properties['general_intercept'] = np.mean(y) if len(y) > 0 else 0
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙˆØ²ÙŠØ¹
        properties['y_mean'] = np.mean(y)
        properties['y_std'] = np.std(y)
        properties['y_skewness'] = self._calculate_skewness(y)
        properties['y_kurtosis'] = self._calculate_kurtosis(y)
        
        return properties
    
    def _calculate_skewness(self, data):
        """Ø­Ø³Ø§Ø¨ Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ù„ØªÙˆØ§Ø¡"""
        if len(data) < 3:
            return 0
        mean = np.mean(data)
        std = np.std(data)
        if std == 0:
            return 0
        return np.mean(((data - mean) / std) ** 3)
    
    def _calculate_kurtosis(self, data):
        """Ø­Ø³Ø§Ø¨ Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„ØªÙÙ„Ø·Ø­"""
        if len(data) < 4:
            return 0
        mean = np.mean(data)
        std = np.std(data)
        if std == 0:
            return 0
        return np.mean(((data - mean) / std) ** 4) - 3
    
    def _determine_function_type(self, x, y, analysis):
        """
        ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„
        """
        function_type = {}
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®ØµØ§Ø¦Øµ
        zero_count = analysis['zero_duality']['zero_count']
        balance_factor = analysis['zero_duality']['balance_factor']
        complexity = analysis['filament_structure']['complexity_level']
        periodicity = analysis['filament_structure']['periodicity_strength']
        symmetry = analysis['perpendicular_opposites']['vertical_symmetry']
        
        # ØªØµÙ†ÙŠÙ Ù†ÙˆØ¹ Ø§Ù„Ø¯Ø§Ù„Ø©
        if periodicity > 0.3:
            if symmetry > 0.7:
                function_type['primary_type'] = 'trigonometric_symmetric'
            else:
                function_type['primary_type'] = 'trigonometric_asymmetric'
        elif complexity < 1.5:
            if zero_count <= 1:
                function_type['primary_type'] = 'monotonic'
            else:
                function_type['primary_type'] = 'simple_polynomial'
        elif complexity < 3.0:
            function_type['primary_type'] = 'complex_polynomial'
        else:
            function_type['primary_type'] = 'highly_complex'
        
        # ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        if complexity < 1.0:
            function_type['sigmoid_components'] = 1
            function_type['linear_components'] = 1
        elif complexity < 2.0:
            function_type['sigmoid_components'] = 2
            function_type['linear_components'] = 1
        elif complexity < 3.0:
            function_type['sigmoid_components'] = 3
            function_type['linear_components'] = 2
        else:
            function_type['sigmoid_components'] = min(5, int(complexity) + 1)
            function_type['linear_components'] = min(3, int(complexity // 2) + 1)
        
        function_type['confidence'] = min(1.0, balance_factor * (1 - abs(complexity - 2) / 3))
        
        return function_type
    
    def _get_default_analysis(self):
        """Ø¥Ø±Ø¬Ø§Ø¹ ØªØ­Ù„ÙŠÙ„ Ø§ÙØªØ±Ø§Ø¶ÙŠ ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£"""
        return {
            'zero_duality': {
                'zero_crossings': [],
                'zero_count': 0,
                'positive_ratio': 0.5,
                'negative_ratio': 0.5,
                'balance_factor': 1.0,
                'mean_value': 0.0,
                'std_value': 1.0,
                'zero_proximity': 0.0
            },
            'perpendicular_opposites': {
                'vertical_symmetry': 0.5,
                'horizontal_symmetry': 0.5,
                'perpendicular_points': 0,
                'slope_variation': 0.0,
                'max_slope_change': 0.0
            },
            'filament_structure': {
                'curvature_points': 0,
                'max_curvature': 0.0,
                'mean_curvature': 0.0,
                'data_gaps': 0,
                'continuity_score': 1.0,
                'dominant_frequency': 0.0,
                'periodicity_strength': 0.0,
                'complexity_level': 1.0
            },
            'mathematical_properties': {
                'x_range': (0, 1),
                'y_range': (0, 1),
                'data_points': 0,
                'correlation': 0.0,
                'general_slope': 0.0,
                'general_intercept': 0.0,
                'y_mean': 0.0,
                'y_std': 1.0,
                'y_skewness': 0.0,
                'y_kurtosis': 0.0
            },
            'function_type': {
                'primary_type': 'simple_polynomial',
                'sigmoid_components': 1,
                'linear_components': 1,
                'confidence': 0.5
            }
        }
