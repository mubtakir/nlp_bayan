#!/usr/bin/env python3
"""
Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø«ÙˆØ±ÙŠ Ø§Ù„Ù…Ø­Ø³Ù† Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ù…Ù† Ø§Ù„ØµÙˆØ±
ğŸ§¬ Ø§Ù„Ù…Ø·ÙˆØ±: Ø¨Ø§Ø³Ù„ ÙŠØ­ÙŠÙ‰ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡
ğŸŒŸ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù†Ø©: Ø§Ù„Ø·Ø±Ù‚ Ø§Ù„Ù…Ø¹ØªØ§Ø¯Ø© Ø£ÙˆÙ„Ø§Ù‹ØŒ Ø«Ù… Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©
ğŸ¯ Ø§Ù„Ù‡Ø¯Ù: Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© Ù…Ø¶Ù…ÙˆÙ†Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø­Ù„ Ø§Ù„Ø£Ø®ÙŠØ±
"""

import numpy as np
import os
from typing import Dict, List, Tuple, Any, Optional
import tempfile
import time
try:
    from .revolutionary_image_inference_system import RevolutionaryImageInferenceSystem
    from core.revolutionary_equation_library import RevolutionaryEquationLibrary
    from .revolutionary_image_processing import RevolutionaryImageProcessor
    from artistic.revolutionary_visualization import RevolutionaryVisualizer, PlotConfig, ColorScheme
    from artistic.enhanced_artistic_unit_fixed import BaserahArtisticRenderer
except ImportError:
    # Fallback for different execution contexts
    try:
        from revolutionary_image_inference_system import RevolutionaryImageInferenceSystem
        from revolutionary_equation_library import RevolutionaryEquationLibrary
        from revolutionary_image_processing import RevolutionaryImageProcessor
        from revolutionary_visualization import RevolutionaryVisualizer, PlotConfig, ColorScheme
        from enhanced_artistic_unit_fixed import BaserahArtisticRenderer
    except ImportError:
        # Last resort: try adding parent directory to path
        import sys
        import os
        sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        from core.revolutionary_equation_library import RevolutionaryEquationLibrary
        from artistic.revolutionary_visualization import RevolutionaryVisualizer, PlotConfig, ColorScheme
        from artistic.enhanced_artistic_unit_fixed import BaserahArtisticRenderer
        from advanced.revolutionary_image_inference_system import RevolutionaryImageInferenceSystem
        from advanced.revolutionary_image_processing import RevolutionaryImageProcessor

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ sklearn Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
try:
    from sklearn.cluster import KMeans
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    print("âš ï¸ sklearn ØºÙŠØ± Ù…ØªÙˆÙØ± - Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ù„ÙˆØ§Ù† Ù…Ø¨Ø³Ø·")

class EnhancedRevolutionaryInferenceSystem:
    """
    Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø«ÙˆØ±ÙŠ Ø§Ù„Ù…Ø­Ø³Ù† Ù…Ø¹ Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©
    ÙŠØ·Ø¨Ù‚ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù†Ø©: Ø§Ù„Ø·Ø±Ù‚ Ø§Ù„Ù…Ø¹ØªØ§Ø¯Ø© Ø£ÙˆÙ„Ø§Ù‹ØŒ Ø«Ù… Ø§Ù„Ø­Ù„ Ø§Ù„Ø£Ø®ÙŠØ±
    """
    
    def __init__(self):
        self.creator = "Ø¨Ø§Ø³Ù„ ÙŠØ­ÙŠÙ‰ Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡"
        self.methodology = "Enhanced Revolutionary Strategy with Reference Library"
        
        # Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        self.basic_system = RevolutionaryImageInferenceSystem()
        
        # Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©
        self.equation_library = RevolutionaryEquationLibrary()
        
        # Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©
        self.artistic_renderer = BaserahArtisticRenderer()
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù†Ø©
        self.enhanced_config = {
            'basic_method_threshold': 0.6,  # Ø­Ø¯ Ø§Ù„Ø¯Ù‚Ø© Ù„Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
            'library_search_threshold': 0.5,  # Ø­Ø¯ Ø§Ù„Ø¯Ù‚Ø© Ù„Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø© (Ù…Ø®ÙØ¶ Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø­Ù„Ù‚Ø§Øª Ø§Ù„Ù„Ø§Ù†Ù‡Ø§Ø¦ÙŠØ©)
            'max_library_search_time': 60,  # Ø¯Ù‚ÙŠÙ‚Ø© ÙˆØ§Ø­Ø¯Ø© ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰ (Ù…Ø®ÙØ¶)
            'max_segments_per_search': 10,  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
            'segment_overlap': 0.1,  # ØªØ¯Ø§Ø®Ù„ Ø¨ÙŠÙ† Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„ØµÙˆØ±Ø©
            'min_segment_size': 20,  # Ø­Ø¯ Ø£Ø¯Ù†Ù‰ Ù„Ø­Ø¬Ù… Ø§Ù„Ø¬Ø²Ø¡
            'expert_guidance_weight': 0.3,  # ÙˆØ²Ù† ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ø®Ø¨ÙŠØ±
            'background_removal_threshold': 0.1,  # Ø­Ø¯ ØªØ­Ø³Ù† Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©
            'max_background_attempts': 8,  # Ø¹Ø¯Ø¯ Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø®Ù„ÙÙŠØ© Ø§Ù„Ù…Ø®ØªØ¨Ø±Ø©
            'background_tolerance': 15  # ØªØ³Ø§Ù…Ø­ Ù„ÙˆÙ† Ø§Ù„Ø®Ù„ÙÙŠØ©
        }

        # Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø®Ù„ÙÙŠØ© Ø§Ù„Ù…Ø®ØªØ¨Ø±Ø© (Ø¨ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©)
        self.background_colors = [
            (255, 255, 255),  # Ø£Ø¨ÙŠØ¶
            (0, 0, 0),        # Ø£Ø³ÙˆØ¯
            (240, 240, 240),  # Ø±Ù…Ø§Ø¯ÙŠ ÙØ§ØªØ­
            (128, 128, 128),  # Ø±Ù…Ø§Ø¯ÙŠ Ù…ØªÙˆØ³Ø·
            (64, 64, 64),     # Ø±Ù…Ø§Ø¯ÙŠ Ø¯Ø§ÙƒÙ†
            (255, 255, 240),  # Ø£Ø¨ÙŠØ¶ Ù…ØµÙØ±
            (248, 248, 255),  # Ø£Ø¨ÙŠØ¶ Ù…Ø²Ø±Ù‚
            (245, 245, 220)   # Ø¨ÙŠØ¬ ÙØ§ØªØ­
        ]
        
        print(f"ğŸ§¬ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø«ÙˆØ±ÙŠ Ø§Ù„Ù…Ø­Ø³Ù†")
        print(f"ğŸ“š Ø§Ù„Ù…ÙƒØªØ¨Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ {self.equation_library.get_library_stats()['total_equations']} Ù…Ø¹Ø§Ø¯Ù„Ø©")
    
    def infer_equation_from_image_enhanced(self, image_path: str, max_iterations: int = 10):
        """
        Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù†Ø©: Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø¹Ø§Ù… Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©
        ØªØ·Ø¨Ù‚ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù†Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©
        """
        print(f"ğŸ§¬ Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ø«ÙˆØ±ÙŠ Ø§Ù„Ù…Ø­Ø³Ù† Ù„Ù„ØµÙˆØ±Ø©: {image_path}")
        print("=" * 70)
        
        start_time = time.time()
        
        try:
            # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø£ÙˆÙ„Ø§Ù‹
            print("ğŸ¯ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©")
            print("-" * 50)

            basic_result = self.basic_system.infer_equation_from_image(image_path, max_iterations)
            basic_accuracy = basic_result.get('overall_accuracy', 0.0)

            print(f"ğŸ“Š Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©: {basic_accuracy:.3f}")

            # ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙƒØ§ÙÙŠØ©
            if basic_accuracy >= self.enhanced_config['basic_method_threshold']:
                print(f"âœ… Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù†Ø¬Ø­Øª! Ø¯Ù‚Ø©: {basic_accuracy:.3f}")
                basic_result['method_used'] = 'basic_revolutionary'
                basic_result['processing_time'] = time.time() - start_time
                return basic_result

            # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1.5: ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù†
            print(f"\nğŸ¯ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1.5: ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù†")
            print("-" * 50)

            color_removal_result = self._apply_advanced_color_removal_strategy(image_path, max_iterations)
            color_removal_accuracy = color_removal_result.get('best_accuracy', 0.0)

            print(f"ğŸ“Š Ù†ØªÙŠØ¬Ø© Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù†: {color_removal_accuracy:.3f}")

            # Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù†ØªÙŠØ¬Ø© Ù…Ù† Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
            if color_removal_accuracy > basic_accuracy:
                print(f"ğŸ¯ ØªØ­Ø³Ù† Ù…Ø¹ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù†! {color_removal_accuracy:.3f} > {basic_accuracy:.3f}")
                print(f"ğŸŒˆ ØªÙ… Ø§Ø®ØªØ¨Ø§Ø± {len(color_removal_result.get('color_tests', []))} Ù„ÙˆÙ†")
                print(f"ğŸ” ØªÙ… Ø§ÙƒØªØ´Ø§Ù {len(color_removal_result.get('combined_shapes', []))} Ø´ÙƒÙ„ Ø¥Ø¬Ù…Ø§Ù„ÙŠ")

                if color_removal_result.get('best_result'):
                    basic_result = color_removal_result['best_result']
                    basic_result['color_tests'] = color_removal_result.get('color_tests', [])
                    basic_result['combined_analysis'] = color_removal_result.get('combined_analysis', {})

                    if 'best_removed_color' in basic_result:
                        print(f"ğŸ¯ Ø£ÙØ¶Ù„ Ù„ÙˆÙ† ØªÙ… Ø¥Ø²Ø§Ù„ØªÙ‡: RGB{basic_result['best_removed_color']}")

                basic_accuracy = color_removal_accuracy

            # ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø© ÙƒØ§ÙÙŠØ©
            if basic_accuracy >= self.enhanced_config['basic_method_threshold']:
                print(f"âœ… Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù†Ø© Ù†Ø¬Ø­Øª! Ø¯Ù‚Ø©: {basic_accuracy:.3f}")
                basic_result['method_used'] = 'enhanced_basic_with_color_removal'
                basic_result['processing_time'] = time.time() - start_time
                return basic_result
            
            # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ù„ Ø§Ù„Ø£Ø®ÙŠØ± - Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©
            print(f"\nğŸ¯ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ù„ Ø§Ù„Ø£Ø®ÙŠØ± - Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©")
            print(f"âš ï¸ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù… ØªØ­Ù‚Ù‚ Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ({basic_accuracy:.3f} < {self.enhanced_config['basic_method_threshold']})")
            print("-" * 50)

            library_result = self._apply_library_search_strategy(image_path, basic_result)

            # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2.5: ØªØ¬Ø±Ø¨Ø© Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ© Ù…Ø¹ Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©
            print(f"\nğŸ¯ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2.5: ØªØ¬Ø±Ø¨Ø© Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ© Ù…Ø¹ Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©")
            print("-" * 50)

            library_bg_result = self._apply_library_with_background_removal(image_path)

            # Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù†ØªÙŠØ¬Ø© Ù…Ù† Ø§Ù„Ù…ÙƒØªØ¨Ø©
            if library_bg_result.get('overall_accuracy', 0) > library_result.get('overall_accuracy', 0):
                print(f"ğŸ¯ ØªØ­Ø³Ù† Ù…Ø¹ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ© ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø©!")
                library_result = library_bg_result
            
            # Ø¯Ù…Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            final_result = self._merge_results(basic_result, library_result)
            final_result['processing_time'] = time.time() - start_time
            
            print(f"\nğŸ† Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:")
            print(f"ğŸ“Š Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: {final_result['overall_accuracy']:.3f}")
            print(f"ğŸ”§ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©: {final_result['method_used']}")
            print(f"â±ï¸ ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {final_result['processing_time']:.2f} Ø«Ø§Ù†ÙŠØ©")
            
            return final_result
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø· Ø§Ù„Ù…Ø­Ø³Ù†: {str(e)}")
            return self._get_error_result(str(e))
    
    def _apply_library_search_strategy(self, image_path: str, basic_result: Dict) -> Dict[str, Any]:
        """
        ØªØ·Ø¨ÙŠÙ‚ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©
        """
        print("ğŸ” Ø¨Ø¯Ø¡ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©...")
        
        library_start_time = time.time()
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„ØµÙˆØ±Ø©
        image_segments = self._extract_image_segments(image_path)

        # ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø­Ù„Ù‚Ø§Øª Ø§Ù„Ù„Ø§Ù†Ù‡Ø§Ø¦ÙŠØ©
        max_segments = min(len(image_segments), self.enhanced_config['max_segments_per_search'])
        image_segments = image_segments[:max_segments]

        print(f"ğŸ“‚ ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(image_segments)} Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© (Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ù€ {max_segments})")

        # Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ù„ÙƒÙ„ Ø¬Ø²Ø¡
        segment_results = []
        total_equations_tested = 0

        for i, segment in enumerate(image_segments):
            print(f"\nğŸ” Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¬Ø²Ø¡ {i+1}/{len(image_segments)}")

            # ÙØ­Øµ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ
            elapsed_time = time.time() - library_start_time
            if elapsed_time > self.enhanced_config['max_library_search_time']:
                print(f"â° ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„ÙˆÙ‚Øª ({elapsed_time:.1f}s)")
                break
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙØ¶Ù„ Ù…Ø¹Ø§Ø¯Ù„Ø© Ù„Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø²Ø¡
            segment_result = self._search_segment_in_library(segment, i)
            segment_results.append(segment_result)
            
            total_equations_tested += segment_result.get('equations_tested', 0)
            
            print(f"  ğŸ“Š Ø£ÙØ¶Ù„ Ø¯Ù‚Ø© Ù„Ù„Ø¬Ø²Ø¡: {segment_result.get('accuracy', 0):.3f}")
        
        # Ø¯Ù…Ø¬ Ù†ØªØ§Ø¦Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡
        library_result = self._combine_segment_results(segment_results)
        library_result['total_equations_tested'] = total_equations_tested
        library_result['search_time'] = time.time() - library_start_time
        library_result['segments_processed'] = len(segment_results)
        
        print(f"\nğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø©:")
        print(f"ğŸ” Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ù…Ø®ØªØ¨Ø±Ø©: {total_equations_tested}")
        print(f"ğŸ“‚ Ø£Ø¬Ø²Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø©: {len(segment_results)}")
        print(f"â±ï¸ ÙˆÙ‚Øª Ø§Ù„Ø¨Ø­Ø«: {library_result['search_time']:.2f} Ø«Ø§Ù†ÙŠØ©")
        print(f"ğŸ¯ Ø£ÙØ¶Ù„ Ø¯Ù‚Ø©: {library_result.get('overall_accuracy', 0):.3f}")
        
        return library_result
    
    def _extract_image_segments(self, image_path: str) -> List[Dict[str, Any]]:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„ØµÙˆØ±Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù†ÙØµÙ„Ø©
        """
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©
        image = cv2.imread(image_path)
        if image is None:
            return []
        
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        height, width = gray.shape
        
        segments = []
        
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ø´Ø¨ÙƒØ©
        grid_size = 3  # Ø´Ø¨ÙƒØ© 3x3
        segment_height = height // grid_size
        segment_width = width // grid_size
        
        for row in range(grid_size):
            for col in range(grid_size):
                # Ø­Ø³Ø§Ø¨ Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø¬Ø²Ø¡
                y_start = row * segment_height
                y_end = min((row + 1) * segment_height, height)
                x_start = col * segment_width
                x_end = min((col + 1) * segment_width, width)
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¬Ø²Ø¡
                segment_image = gray[y_start:y_end, x_start:x_end]
                
                # ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¬Ø²Ø¡ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰
                if self._segment_has_content(segment_image):
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙˆÙ†ØªÙˆØ±Ø§Øª Ù…Ù† Ø§Ù„Ø¬Ø²Ø¡
                    contours = self._extract_contours_from_segment(segment_image)
                    
                    if contours:
                        segment = {
                            'id': f'segment_{row}_{col}',
                            'position': (row, col),
                            'bounds': (y_start, y_end, x_start, x_end),
                            'image': segment_image,
                            'contours': contours,
                            'size': segment_image.shape
                        }
                        segments.append(segment)
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© ÙƒØ¬Ø²Ø¡ ÙˆØ§Ø­Ø¯
        full_contours = self._extract_contours_from_segment(gray)
        if full_contours:
            segments.append({
                'id': 'full_image',
                'position': (0, 0),
                'bounds': (0, height, 0, width),
                'image': gray,
                'contours': full_contours,
                'size': gray.shape
            })
        
        return segments
    
    def _segment_has_content(self, segment_image: np.ndarray) -> bool:
        """
        ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¬Ø²Ø¡ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ù…ÙÙŠØ¯
        """
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¨Ø§ÙŠÙ†
        variance = np.var(segment_image)
        
        # Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„Ø¨ÙƒØ³Ù„ ØºÙŠØ± Ø§Ù„ØµÙØ±ÙŠØ©
        non_zero_pixels = np.count_nonzero(segment_image)
        total_pixels = segment_image.size
        
        # Ù…Ø¹Ø§ÙŠÙŠØ± ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
        has_variance = variance > 100  # ØªØ¨Ø§ÙŠÙ† ÙƒØ§ÙÙŠ
        has_content = (non_zero_pixels / total_pixels) > 0.1  # 10% Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ Ù…Ø­ØªÙˆÙ‰
        
        return has_variance and has_content
    
    def _extract_contours_from_segment(self, segment_image: np.ndarray) -> List[np.ndarray]:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙˆÙ†ØªÙˆØ±Ø§Øª Ù…Ù† Ø¬Ø²Ø¡ Ø§Ù„ØµÙˆØ±Ø©
        """
        try:
            # ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø©
            blurred = cv2.GaussianBlur(segment_image, (3, 3), 0)
            
            # ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù
            edges = cv2.Canny(blurred, 30, 90)
            
            # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙˆÙ†ØªÙˆØ±Ø§Øª
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # ØªØµÙÙŠØ© Ø§Ù„ÙƒÙˆÙ†ØªÙˆØ±Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø©
            filtered_contours = []
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > self.enhanced_config['min_segment_size']:
                    filtered_contours.append(contour)
            
            return filtered_contours
            
        except Exception as e:
            return []
    
    def _search_segment_in_library(self, segment: Dict, segment_index: int) -> Dict[str, Any]:
        """
        Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙØ¶Ù„ Ù…Ø¹Ø§Ø¯Ù„Ø© Ù„Ø¬Ø²Ø¡ Ù…Ø­Ø¯Ø¯ ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø©
        """
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒÙˆÙ†ØªÙˆØ±Ø§Øª Ø¥Ù„Ù‰ Ù†Ù‚Ø§Ø· x, y
        best_result = {
            'segment_id': segment['id'],
            'accuracy': 0.0,
            'equation': None,
            'equations_tested': 0
        }
        
        for contour in segment['contours']:
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒÙˆÙ†ØªÙˆØ± Ø¥Ù„Ù‰ Ù†Ù‚Ø§Ø·
            points = contour.reshape(-1, 2)
            if len(points) < 3:
                continue
            
            x_coords = points[:, 0].astype(float)
            y_coords = points[:, 1].astype(float)
            
            # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª
            x_range = np.ptp(x_coords)
            y_range = np.ptp(y_coords)
            
            if x_range > 0 and y_range > 0:
                x_normalized = (x_coords - np.min(x_coords)) / x_range
                y_normalized = (y_coords - np.min(y_coords)) / y_range
            else:
                continue
            
            # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø©
            library_match = self.equation_library.search_best_match(x_normalized, y_normalized)
            
            best_result['equations_tested'] += library_match['search_stats']['equations_tested']
            
            # ØªØ­Ø¯ÙŠØ« Ø£ÙØ¶Ù„ Ù†ØªÙŠØ¬Ø©
            if library_match['accuracy'] > best_result['accuracy']:
                best_result['accuracy'] = library_match['accuracy']
                best_result['equation'] = library_match['equation']
                best_result['shape_type'] = library_match['shape_type']
                best_result['parameters'] = library_match['parameters']
            
            # Ø¥Ø°Ø§ ÙˆØµÙ„Ù†Ø§ Ù„Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©ØŒ ØªÙˆÙ‚Ù
            if library_match['accuracy'] >= self.enhanced_config['library_search_threshold']:
                break
        
        return best_result

    def _apply_background_removal_strategy(self, image_path: str, max_iterations: int) -> Dict[str, Any]:
        """
        ØªØ·Ø¨ÙŠÙ‚ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ© Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªÙ†Ø¨Ø§Ø·
        """
        print("ğŸ¨ Ø¨Ø¯Ø¡ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©...")

        best_result = {
            'overall_accuracy': 0.0,
            'method_used': 'background_removal_failed',
            'background_tests': []
        }

        original_image = cv2.imread(image_path)
        if original_image is None:
            return best_result

        # Ø§Ø®ØªØ¨Ø§Ø± ÙƒÙ„ Ù„ÙˆÙ† Ø®Ù„ÙÙŠØ©
        for i, bg_color in enumerate(self.background_colors[:self.enhanced_config['max_background_attempts']]):
            print(f"\nğŸ¨ Ø§Ø®ØªØ¨Ø§Ø± Ù„ÙˆÙ† Ø§Ù„Ø®Ù„ÙÙŠØ© {i+1}/{self.enhanced_config['max_background_attempts']}: RGB{bg_color}")

            try:
                # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©
                processed_image_path = self._remove_background_color(image_path, bg_color, i)

                if processed_image_path:
                    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
                    result = self.basic_system.infer_equation_from_image(processed_image_path, max_iterations)
                    accuracy = result.get('overall_accuracy', 0.0)

                    print(f"  ğŸ“Š Ø¯Ù‚Ø© Ù…Ø¹ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©: {accuracy:.3f}")

                    # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø©
                    test_result = {
                        'background_color': bg_color,
                        'accuracy': accuracy,
                        'processed_image': processed_image_path
                    }
                    best_result['background_tests'].append(test_result)

                    # ØªØ­Ø¯ÙŠØ« Ø£ÙØ¶Ù„ Ù†ØªÙŠØ¬Ø©
                    if accuracy > best_result['overall_accuracy']:
                        best_result.update(result)
                        best_result['overall_accuracy'] = accuracy
                        best_result['method_used'] = 'background_removal_enhanced'
                        best_result['best_background_color'] = bg_color
                        best_result['best_processed_image'] = processed_image_path

                        print(f"  ğŸ¯ ØªØ­Ø³Ù†! Ø£ÙØ¶Ù„ Ø¯Ù‚Ø©: {accuracy:.3f}")

                    # Ø¥Ø°Ø§ ÙˆØµÙ„Ù†Ø§ Ù„Ø¯Ù‚Ø© Ø¬ÙŠØ¯Ø©ØŒ ØªÙˆÙ‚Ù
                    if accuracy >= self.enhanced_config['basic_method_threshold']:
                        print(f"  âœ… ÙˆØµÙ„Ù†Ø§ Ù„Ù„Ø¯Ù‚Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù…Ø¹ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©!")
                        break

                    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
                    try:
                        os.remove(processed_image_path)
                    except:
                        pass

            except Exception as e:
                print(f"  âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù„ÙˆÙ† Ø§Ù„Ø®Ù„ÙÙŠØ© {bg_color}: {str(e)}")
                continue

        print(f"\nğŸ“Š Ù…Ù„Ø®Øµ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©:")
        print(f"ğŸ¨ Ø£Ù„ÙˆØ§Ù† Ù…Ø®ØªØ¨Ø±Ø©: {len(best_result['background_tests'])}")
        print(f"ğŸ¯ Ø£ÙØ¶Ù„ Ø¯Ù‚Ø©: {best_result['overall_accuracy']:.3f}")
        if 'best_background_color' in best_result:
            print(f"ğŸŒˆ Ø£ÙØ¶Ù„ Ù„ÙˆÙ† Ø®Ù„ÙÙŠØ©: RGB{best_result['best_background_color']}")

        return best_result

    def _remove_background_color(self, image_path: str, bg_color: tuple, index: int) -> str:
        """
        Ø¥Ø²Ø§Ù„Ø© Ù„ÙˆÙ† Ø®Ù„ÙÙŠØ© Ù…Ø­Ø¯Ø¯ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©
        """
        try:
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©
            image = cv2.imread(image_path)
            if image is None:
                return None

            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ RGB
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

            # Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ù†Ø§Ø¹ Ù„Ù„Ø®Ù„ÙÙŠØ©
            tolerance = self.enhanced_config['background_tolerance']

            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ© Ù…Ù† Ù„ÙˆÙ† Ø§Ù„Ø®Ù„ÙÙŠØ©
            diff = np.abs(image_rgb.astype(np.float32) - np.array(bg_color).astype(np.float32))
            distance = np.sqrt(np.sum(diff**2, axis=2))

            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù‚Ù†Ø§Ø¹
            background_mask = distance <= tolerance

            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ© (Ø¬Ø¹Ù„Ù‡Ø§ Ø´ÙØ§ÙØ© Ø£Ùˆ Ø¨ÙŠØ¶Ø§Ø¡)
            processed_image = image_rgb.copy()
            processed_image[background_mask] = [255, 255, 255]  # Ø®Ù„ÙÙŠØ© Ø¨ÙŠØ¶Ø§Ø¡

            # Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
            temp_path = f"/tmp/bg_removed_{index}_{int(time.time())}.png"
            processed_image_bgr = cv2.cvtColor(processed_image, cv2.COLOR_RGB2BGR)
            cv2.imwrite(temp_path, processed_image_bgr)

            return temp_path

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©: {str(e)}")
            return None

    def _extract_dominant_colors(self, image, num_colors=8):
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©
        """
        try:
            # ØªØµØºÙŠØ± Ø§Ù„ØµÙˆØ±Ø© Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
            small_image = cv2.resize(image, (150, 150))

            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ RGB
            image_rgb = cv2.cvtColor(small_image, cv2.COLOR_BGR2RGB)

            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯
            pixels = image_rgb.reshape(-1, 3)

            # Ø§Ø³ØªØ®Ø¯Ø§Ù… K-means Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
            if SKLEARN_AVAILABLE:
                kmeans = KMeans(n_clusters=num_colors, random_state=42, n_init=10)
                kmeans.fit(pixels)
                colors = kmeans.cluster_centers_.astype(int)
            else:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ù„ÙˆØ§Ù† Ù…Ø¨Ø³Ø· Ø¨Ø¯ÙˆÙ† sklearn
                colors = self._simple_color_extraction(pixels, num_colors)

            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† tuples
            dominant_colors = [tuple(color) for color in colors]

            return dominant_colors

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ù„ÙˆØ§Ù†: {str(e)}")
            # Ø¥Ø±Ø¬Ø§Ø¹ Ø£Ù„ÙˆØ§Ù† Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
            return [(255, 255, 255), (0, 0, 0), (128, 128, 128)]

    def _simple_color_extraction(self, pixels, num_colors):
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ù„ÙˆØ§Ù† Ù…Ø¨Ø³Ø· Ø¨Ø¯ÙˆÙ† sklearn
        """
        try:
            # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø¥Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨Ø³ÙŠØ·Ø©
            unique_colors = []

            # Ø£Ø®Ø° Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙƒØ³Ù„ Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
            sample_size = min(1000, len(pixels))
            sample_indices = np.random.choice(len(pixels), sample_size, replace=False)
            sample_pixels = pixels[sample_indices]

            # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡Ø©
            for pixel in sample_pixels:
                is_similar = False
                for existing_color in unique_colors:
                    if self._color_distance(pixel, existing_color) < 50:
                        is_similar = True
                        break

                if not is_similar:
                    unique_colors.append(tuple(pixel))

                # ØªÙˆÙ‚Ù Ø¹Ù†Ø¯ Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
                if len(unique_colors) >= num_colors:
                    break

            # Ø¥Ø¶Ø§ÙØ© Ø£Ù„ÙˆØ§Ù† Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ù…Ø§ ÙŠÙƒÙÙŠ
            default_colors = [(255, 255, 255), (0, 0, 0), (128, 128, 128),
                            (192, 192, 192), (64, 64, 64)]

            for color in default_colors:
                if len(unique_colors) >= num_colors:
                    break
                if color not in unique_colors:
                    unique_colors.append(color)

            return unique_colors[:num_colors]

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…Ø¨Ø³Ø·: {str(e)}")
            return [(255, 255, 255), (0, 0, 0), (128, 128, 128)]

    def _color_distance(self, color1, color2):
        """
        Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø¨ÙŠÙ† Ù„ÙˆÙ†ÙŠÙ†
        """
        return np.sqrt(sum((a - b) ** 2 for a, b in zip(color1, color2)))

    def _remove_specific_color(self, image_path: str, color: tuple, index: int) -> str:
        """
        Ø¥Ø²Ø§Ù„Ø© Ù„ÙˆÙ† Ù…Ø­Ø¯Ø¯ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©
        """
        try:
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©
            image = cv2.imread(image_path)
            if image is None:
                return None

            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ RGB
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

            # Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ù†Ø§Ø¹ Ù„Ù„ÙˆÙ† Ø§Ù„Ù…Ø­Ø¯Ø¯
            tolerance = self.enhanced_config['background_tolerance']

            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ© Ù…Ù† Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ù…Ø­Ø¯Ø¯
            diff = np.abs(image_rgb.astype(np.float32) - np.array(color).astype(np.float32))
            distance = np.sqrt(np.sum(diff**2, axis=2))

            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù‚Ù†Ø§Ø¹
            color_mask = distance <= tolerance

            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù„ÙˆÙ† (Ø¬Ø¹Ù„Ù‡ Ø´ÙØ§Ù Ø£Ùˆ Ø£Ø¨ÙŠØ¶)
            processed_image = image_rgb.copy()
            processed_image[color_mask] = [255, 255, 255]  # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø¨Ø§Ù„Ø£Ø¨ÙŠØ¶

            # Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
            temp_path = f"/tmp/color_removed_{index}_{int(time.time())}.png"
            processed_image_bgr = cv2.cvtColor(processed_image, cv2.COLOR_RGB2BGR)
            cv2.imwrite(temp_path, processed_image_bgr)

            return temp_path

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù„ÙˆÙ†: {str(e)}")
            return None

    def _analyze_combined_shape_data(self, all_shapes, shape_frequency):
        """
        ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¬Ù…Ø¹Ø© Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø¹Ù…Ù„ÙŠØ§Øª Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù†
        """
        try:
            analysis = {
                'total_detections': len(all_shapes),
                'unique_shapes': len(shape_frequency),
                'most_common_shape': None,
                'confidence_scores': {},
                'layer_analysis': {},
                'recommended_shapes': []
            }

            if not all_shapes:
                return analysis

            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø±Ø§Ù‹
            if shape_frequency:
                most_common = max(shape_frequency.items(), key=lambda x: x[1])
                analysis['most_common_shape'] = {
                    'type': most_common[0],
                    'frequency': most_common[1],
                    'confidence': most_common[1] / len(all_shapes)
                }

            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø«Ù‚Ø© Ù„ÙƒÙ„ Ø´ÙƒÙ„
            for shape_type, frequency in shape_frequency.items():
                confidence = frequency / len(all_shapes)
                analysis['confidence_scores'][shape_type] = confidence

            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª (Ø£ÙŠ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„ØªÙŠ ÙƒØ´ÙØª Ø¹Ù† Ø£Ø´ÙƒØ§Ù„ Ø£ÙƒØ«Ø±)
            color_performance = {}
            for shape_info in all_shapes:
                color = tuple(shape_info['removed_color'])
                if color not in color_performance:
                    color_performance[color] = {
                        'shapes_found': 0,
                        'total_accuracy': 0.0,
                        'detections': []
                    }

                color_performance[color]['shapes_found'] += 1
                color_performance[color]['total_accuracy'] += shape_info['accuracy']
                color_performance[color]['detections'].append(shape_info)

            # Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù„ÙƒÙ„ Ù„ÙˆÙ†
            for color, performance in color_performance.items():
                performance['average_accuracy'] = performance['total_accuracy'] / performance['shapes_found']
                analysis['layer_analysis'][str(color)] = performance

            # Ø§Ù„ØªÙˆØµÙŠØ© Ø¨Ø§Ù„Ø£Ø´ÙƒØ§Ù„ Ø§Ù„Ø£ÙƒØ«Ø± Ù…ÙˆØ«ÙˆÙ‚ÙŠØ©
            for shape_type, confidence in analysis['confidence_scores'].items():
                if confidence >= 0.3:  # Ø¸Ù‡Ø± ÙÙŠ 30% Ø£Ùˆ Ø£ÙƒØ«Ø± Ù…Ù† Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
                    analysis['recommended_shapes'].append({
                        'type': shape_type,
                        'confidence': confidence,
                        'recommendation': 'high' if confidence >= 0.6 else 'medium'
                    })

            return analysis

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©: {str(e)}")
            return {'total_detections': 0, 'error': str(e)}

    def _apply_advanced_color_removal_strategy(self, image_path, max_iterations=3):
        """
        ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©: Ø¥Ø²Ø§Ù„Ø© ÙƒÙ„ Ù„ÙˆÙ† Ø¹Ù„Ù‰ Ø­Ø¯Ø© Ù„ÙƒØ´Ù Ø·Ø¨Ù‚Ø§Øª Ù…Ø®ØªÙ„ÙØ© Ù…Ù† Ø§Ù„Ø£Ø´ÙƒØ§Ù„
        """
        print("ğŸ¨ Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©: Ø¥Ø²Ø§Ù„Ø© ÙƒÙ„ Ù„ÙˆÙ† Ø¹Ù„Ù‰ Ø­Ø¯Ø©...")

        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
        image = cv2.imread(image_path)
        if image is None:
            return {'best_accuracy': 0.0, 'color_tests': [], 'combined_shapes': []}

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©
        detected_colors = self._extract_dominant_colors(image)

        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©
        all_colors_to_test = list(detected_colors) + [
            (255, 255, 255),  # Ø£Ø¨ÙŠØ¶
            (0, 0, 0),        # Ø£Ø³ÙˆØ¯
            (240, 240, 240),  # Ø±Ù…Ø§Ø¯ÙŠ ÙØ§ØªØ­
            (128, 128, 128),  # Ø±Ù…Ø§Ø¯ÙŠ Ù…ØªÙˆØ³Ø·
            (64, 64, 64),     # Ø±Ù…Ø§Ø¯ÙŠ Ø¯Ø§ÙƒÙ†
            (255, 255, 240),  # Ø£ØµÙØ± ÙØ§ØªØ­
            (248, 248, 255),  # Ø£Ø²Ø±Ù‚ ÙØ§ØªØ­
            (245, 245, 220),  # Ø¨ÙŠØ¬
        ]

        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…ÙƒØ±Ø±Ø©
        unique_colors = []
        for color in all_colors_to_test:
            is_duplicate = False
            for existing_color in unique_colors:
                if self._color_distance(color, existing_color) < 30:  # ØªØ³Ø§Ù…Ø­ 30
                    is_duplicate = True
                    break
            if not is_duplicate:
                unique_colors.append(color)

        print(f"ğŸŒˆ ØªÙ… Ø§ÙƒØªØ´Ø§Ù {len(detected_colors)} Ù„ÙˆÙ† Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©")
        print(f"ğŸ¯ Ø³ÙŠØªÙ… Ø§Ø®ØªØ¨Ø§Ø± {len(unique_colors)} Ù„ÙˆÙ† Ø¥Ø¬Ù…Ø§Ù„ÙŠ")

        best_accuracy = 0.0
        best_result = None
        color_tests = []
        all_detected_shapes = []
        shape_frequency = {}

        for i, color in enumerate(unique_colors):
            print(f"\nğŸ¨ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù„ÙˆÙ† {i+1}/{len(unique_colors)}: RGB{color}")

            try:
                # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ù…Ø­Ø¯Ø¯
                processed_image_path = self._remove_specific_color(image_path, color, i)

                if processed_image_path is None:
                    continue

                # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
                result = self.basic_system.infer_equation_from_image(
                    processed_image_path, max_iterations=max_iterations
                )

                accuracy = result.get('overall_accuracy', 0.0)
                shapes_found = result.get('equations', [])

                print(f"  ğŸ“Š Ø¯Ù‚Ø© Ù…Ø¹ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù„ÙˆÙ†: {accuracy:.3f}")
                print(f"  ğŸ” Ø£Ø´ÙƒØ§Ù„ Ù…ÙƒØªØ´ÙØ©: {len(shapes_found)}")

                # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø£Ø´ÙƒØ§Ù„ Ø§Ù„Ù…ÙƒØªØ´ÙØ©
                for shape in shapes_found:
                    shape_info = {
                        'equation': shape,
                        'removed_color': color,
                        'accuracy': accuracy,
                        'detection_method': f'color_removal_{i}'
                    }
                    all_detected_shapes.append(shape_info)

                    # Ø¥Ø­ØµØ§Ø¡ ØªÙƒØ±Ø§Ø± Ø§Ù„Ø£Ø´ÙƒØ§Ù„
                    shape_key = str(shape.get('type', 'unknown'))
                    shape_frequency[shape_key] = shape_frequency.get(shape_key, 0) + 1

                color_tests.append({
                    'color': color,
                    'accuracy': accuracy,
                    'shapes_found': len(shapes_found),
                    'shapes': shapes_found,
                    'result': result
                })

                if accuracy > best_accuracy:
                    best_accuracy = accuracy
                    best_result = result
                    best_result['best_removed_color'] = color

                # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
                if os.path.exists(processed_image_path):
                    os.remove(processed_image_path)

            except Exception as e:
                print(f"  âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù„ÙˆÙ† RGB{color}: {str(e)}")
                color_tests.append({
                    'color': color,
                    'accuracy': 0.0,
                    'shapes_found': 0,
                    'error': str(e)
                })

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©
        combined_analysis = self._analyze_combined_shape_data(all_detected_shapes, shape_frequency)

        print(f"\nğŸ“Š Ù…Ù„Ø®Øµ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù†:")
        print(f"ğŸŒˆ Ø£Ù„ÙˆØ§Ù† Ù…Ø®ØªØ¨Ø±Ø©: {len(color_tests)}")
        print(f"ğŸ¯ Ø£ÙØ¶Ù„ Ø¯Ù‚Ø©: {best_accuracy:.3f}")
        print(f"ğŸ” Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø´ÙƒØ§Ù„ Ø§Ù„Ù…ÙƒØªØ´ÙØ©: {len(all_detected_shapes)}")
        print(f"ğŸ“ˆ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø´ÙƒØ§Ù„: {len(shape_frequency)}")

        if combined_analysis.get('most_common_shape'):
            most_common = combined_analysis['most_common_shape']
            print(f"ğŸ† Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø±Ø§Ù‹: {most_common['type']} (Ø«Ù‚Ø©: {most_common['confidence']:.2f})")

        return {
            'best_accuracy': best_accuracy,
            'best_result': best_result,
            'color_tests': color_tests,
            'combined_shapes': all_detected_shapes,
            'shape_frequency': shape_frequency,
            'combined_analysis': combined_analysis,
            'improvement_achieved': best_accuracy > 0.0
        }

    def _enhance_image_contrast(self, image_path: str, index: int) -> str:
        """
        ØªØ­Ø³ÙŠÙ† ØªØ¨Ø§ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø© Ù„ÙƒØ´Ù Ø£ÙØ¶Ù„ Ù„Ù„Ø£Ø´ÙƒØ§Ù„
        """
        try:
            image = cv2.imread(image_path)
            if image is None:
                return None

            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ LAB
            lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)

            # ØªØ·Ø¨ÙŠÙ‚ CLAHE Ø¹Ù„Ù‰ Ù‚Ù†Ø§Ø© L
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
            l = clahe.apply(l)

            # Ø¯Ù…Ø¬ Ø§Ù„Ù‚Ù†ÙˆØ§Øª
            enhanced_lab = cv2.merge([l, a, b])
            enhanced_image = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)

            # Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø©
            temp_path = f"/tmp/enhanced_{index}_{int(time.time())}.png"
            cv2.imwrite(temp_path, enhanced_image)

            return temp_path

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ¨Ø§ÙŠÙ†: {str(e)}")
            return None

    def _combine_segment_results(self, segment_results: List[Dict]) -> Dict[str, Any]:
        """
        Ø¯Ù…Ø¬ Ù†ØªØ§Ø¦Ø¬ Ø¬Ù…ÙŠØ¹ Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„ØµÙˆØ±Ø©
        """
        if not segment_results:
            return {
                'overall_accuracy': 0.0,
                'equations': [],
                'method_used': 'library_search_failed'
            }

        # Ø¬Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø©
        successful_equations = []
        total_accuracy = 0.0

        for result in segment_results:
            if result.get('equation') and result.get('accuracy', 0) > 0.3:
                successful_equations.append({
                    'equation': result['equation'],
                    'accuracy': result['accuracy'],
                    'segment_id': result['segment_id'],
                    'shape_type': result.get('shape_type', 'unknown')
                })
                total_accuracy += result['accuracy']

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
        if successful_equations:
            overall_accuracy = total_accuracy / len(segment_results)
        else:
            overall_accuracy = 0.0

        return {
            'overall_accuracy': overall_accuracy,
            'equations': successful_equations,
            'method_used': 'library_search',
            'segments_with_equations': len(successful_equations),
            'total_segments': len(segment_results)
        }

    def _merge_results(self, basic_result: Dict, library_result: Dict) -> Dict[str, Any]:
        """
        Ø¯Ù…Ø¬ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ø¹ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…ÙƒØªØ¨Ø©
        """
        basic_accuracy = basic_result.get('overall_accuracy', 0.0)
        library_accuracy = library_result.get('overall_accuracy', 0.0)

        # Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù†ØªÙŠØ¬Ø©
        if library_accuracy > basic_accuracy:
            primary_result = library_result
            secondary_result = basic_result
            method_used = 'enhanced_library_search'
            final_accuracy = library_accuracy
        else:
            primary_result = basic_result
            secondary_result = library_result
            method_used = 'enhanced_basic_method'
            final_accuracy = basic_accuracy

        # Ø¯Ù…Ø¬ Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª
        merged_equations = []

        # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ù…Ù† Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        if 'equations' in primary_result:
            for eq in primary_result['equations']:
                merged_equations.append(eq)

        # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù…Ù† Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ÙÙŠØ¯Ø©
        if 'equations' in secondary_result:
            for eq in secondary_result['equations']:
                if isinstance(eq, dict) and eq.get('accuracy', 0) > 0.5:
                    merged_equations.append(eq)

        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©
        merged_result = {
            'success': final_accuracy > 0.3,
            'overall_accuracy': final_accuracy,
            'equations': merged_equations,
            'method_used': method_used,
            'basic_method_accuracy': basic_accuracy,
            'library_method_accuracy': library_accuracy,
            'improvement_achieved': library_accuracy > basic_accuracy,
            'improvement_factor': library_accuracy / basic_accuracy if basic_accuracy > 0 else float('inf'),
            'processing_summary': {
                'total_equations_found': len(merged_equations),
                'successful_equations': sum(1 for eq in merged_equations if isinstance(eq, dict) and eq.get('accuracy', 0) > 0.5),
                'method_comparison': {
                    'basic_method': basic_accuracy,
                    'library_method': library_accuracy,
                    'winner': 'library' if library_accuracy > basic_accuracy else 'basic'
                }
            }
        }

        # Ø¥Ø¶Ø§ÙØ© ØªÙØ§ØµÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠØ©
        if 'search_time' in library_result:
            merged_result['library_search_time'] = library_result['search_time']

        if 'total_equations_tested' in library_result:
            merged_result['library_equations_tested'] = library_result['total_equations_tested']

        return merged_result

    def _get_error_result(self, error_message: str) -> Dict[str, Any]:
        """
        Ø¥Ø±Ø¬Ø§Ø¹ Ù†ØªÙŠØ¬Ø© Ø®Ø·Ø£
        """
        return {
            'success': False,
            'error': error_message,
            'overall_accuracy': 0.0,
            'equations': [],
            'method_used': 'error',
            'methodology': self.methodology,
            'creator': self.creator
        }

    def get_system_stats(self) -> Dict[str, Any]:
        """
        Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù†
        """
        library_stats = self.equation_library.get_library_stats()

        return {
            'system_type': 'Enhanced Revolutionary Inference System',
            'creator': self.creator,
            'methodology': self.methodology,
            'library_stats': library_stats,
            'configuration': self.enhanced_config,
            'capabilities': {
                'basic_revolutionary_method': True,
                'library_reference_search': True,
                'image_segmentation': True,
                'expert_guidance': True,
                'iterative_improvement': True
            }
        }

    def test_system_performance(self, test_images: List[str]) -> Dict[str, Any]:
        """
        Ø§Ø®ØªØ¨Ø§Ø± Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù†
        """
        print("ğŸ§ª Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø± Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù†")
        print("=" * 50)

        test_results = []
        total_start_time = time.time()

        for i, image_path in enumerate(test_images):
            print(f"\nğŸ–¼ï¸ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØµÙˆØ±Ø© {i+1}/{len(test_images)}: {os.path.basename(image_path)}")

            try:
                result = self.infer_equation_from_image_enhanced(image_path)
                test_results.append({
                    'image_path': image_path,
                    'success': result['success'],
                    'accuracy': result['overall_accuracy'],
                    'method_used': result['method_used'],
                    'processing_time': result.get('processing_time', 0),
                    'equations_found': len(result.get('equations', []))
                })

                print(f"  âœ… Ù†Ø¬Ø­: {result['success']}")
                print(f"  ğŸ“Š Ø¯Ù‚Ø©: {result['overall_accuracy']:.3f}")
                print(f"  ğŸ”§ Ø·Ø±ÙŠÙ‚Ø©: {result['method_used']}")

            except Exception as e:
                test_results.append({
                    'image_path': image_path,
                    'success': False,
                    'accuracy': 0.0,
                    'method_used': 'error',
                    'processing_time': 0,
                    'equations_found': 0,
                    'error': str(e)
                })
                print(f"  âŒ ÙØ´Ù„: {str(e)}")

        total_time = time.time() - total_start_time

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        successful_tests = sum(1 for r in test_results if r['success'])
        total_tests = len(test_results)
        success_rate = (successful_tests / total_tests) * 100 if total_tests > 0 else 0

        accuracies = [r['accuracy'] for r in test_results if r['success']]
        avg_accuracy = np.mean(accuracies) if accuracies else 0

        processing_times = [r['processing_time'] for r in test_results]
        avg_processing_time = np.mean(processing_times) if processing_times else 0

        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø·Ø±Ù‚ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©
        method_stats = {}
        for result in test_results:
            method = result['method_used']
            if method not in method_stats:
                method_stats[method] = 0
            method_stats[method] += 1

        performance_report = {
            'test_summary': {
                'total_tests': total_tests,
                'successful_tests': successful_tests,
                'success_rate': success_rate,
                'average_accuracy': avg_accuracy,
                'average_processing_time': avg_processing_time,
                'total_test_time': total_time
            },
            'method_distribution': method_stats,
            'detailed_results': test_results,
            'performance_grade': self._calculate_performance_grade(success_rate, avg_accuracy)
        }

        print(f"\nğŸ† ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:")
        print(f"ğŸ“Š Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­: {success_rate:.1f}%")
        print(f"ğŸ¯ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¯Ù‚Ø©: {avg_accuracy:.3f}")
        print(f"â±ï¸ Ù…ØªÙˆØ³Ø· ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {avg_processing_time:.2f} Ø«Ø§Ù†ÙŠØ©")
        print(f"ğŸ… ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡: {performance_report['performance_grade']}")

        return performance_report

    def _calculate_performance_grade(self, success_rate: float, avg_accuracy: float) -> str:
        """
        Ø­Ø³Ø§Ø¨ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡
        """
        combined_score = (success_rate / 100) * 0.6 + avg_accuracy * 0.4

        if combined_score >= 0.9:
            return "Ù…Ù…ØªØ§Ø²"
        elif combined_score >= 0.8:
            return "Ø¬ÙŠØ¯ Ø¬Ø¯Ø§Ù‹"
        elif combined_score >= 0.7:
            return "Ø¬ÙŠØ¯"
        elif combined_score >= 0.6:
            return "Ù…Ù‚Ø¨ÙˆÙ„"
        else:
            return "ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†"

    def _apply_library_with_background_removal(self, image_path: str) -> Dict[str, Any]:
        """
        ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ© Ù…Ø¹ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©
        """
        print("ğŸ¨ğŸ“š Ø¨Ø¯Ø¡ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø© Ù…Ø¹ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©...")

        best_result = {
            'overall_accuracy': 0.0,
            'method_used': 'library_with_background_removal',
            'background_library_tests': []
        }

        # Ø§Ø®ØªØ¨Ø§Ø± Ø£Ù‡Ù… 4 Ø£Ù„ÙˆØ§Ù† Ø®Ù„ÙÙŠØ© ÙÙ‚Ø· Ù„ØªÙˆÙÙŠØ± Ø§Ù„ÙˆÙ‚Øª
        priority_colors = self.background_colors[:4]

        for i, bg_color in enumerate(priority_colors):
            print(f"\nğŸ¨ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…ÙƒØªØ¨Ø© Ù…Ø¹ Ù„ÙˆÙ† Ø®Ù„ÙÙŠØ© {i+1}/4: RGB{bg_color}")

            try:
                # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©
                processed_image_path = self._remove_background_color(image_path, bg_color, f"lib_{i}")

                if processed_image_path:
                    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
                    library_result = self._apply_library_search_strategy(processed_image_path, {})
                    accuracy = library_result.get('overall_accuracy', 0.0)

                    print(f"  ğŸ“Š Ø¯Ù‚Ø© Ø§Ù„Ù…ÙƒØªØ¨Ø© Ù…Ø¹ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©: {accuracy:.3f}")

                    # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø©
                    test_result = {
                        'background_color': bg_color,
                        'accuracy': accuracy,
                        'processed_image': processed_image_path
                    }
                    best_result['background_library_tests'].append(test_result)

                    # ØªØ­Ø¯ÙŠØ« Ø£ÙØ¶Ù„ Ù†ØªÙŠØ¬Ø©
                    if accuracy > best_result['overall_accuracy']:
                        best_result.update(library_result)
                        best_result['overall_accuracy'] = accuracy
                        best_result['method_used'] = 'library_with_background_removal'
                        best_result['best_background_color'] = bg_color

                        print(f"  ğŸ¯ ØªØ­Ø³Ù† ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø©! Ø£ÙØ¶Ù„ Ø¯Ù‚Ø©: {accuracy:.3f}")

                    # Ø¥Ø°Ø§ ÙˆØµÙ„Ù†Ø§ Ù„Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©ØŒ ØªÙˆÙ‚Ù
                    if accuracy >= self.enhanced_config['library_search_threshold']:
                        print(f"  âœ… ÙˆØµÙ„Ù†Ø§ Ù„Ù„Ø¯Ù‚Ø© Ø§Ù„Ø¹Ø§Ù„ÙŠØ© Ù…Ø¹ Ø§Ù„Ù…ÙƒØªØ¨Ø© ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©!")
                        break

                    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
                    try:
                        os.remove(processed_image_path)
                    except:
                        pass

            except Exception as e:
                print(f"  âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø© Ù…Ø¹ Ù„ÙˆÙ† Ø§Ù„Ø®Ù„ÙÙŠØ© {bg_color}: {str(e)}")
                continue

        print(f"\nğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„Ù…ÙƒØªØ¨Ø© Ù…Ø¹ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©:")
        print(f"ğŸ¨ Ø£Ù„ÙˆØ§Ù† Ù…Ø®ØªØ¨Ø±Ø©: {len(best_result['background_library_tests'])}")
        print(f"ğŸ¯ Ø£ÙØ¶Ù„ Ø¯Ù‚Ø©: {best_result['overall_accuracy']:.3f}")
        if 'best_background_color' in best_result:
            print(f"ğŸŒˆ Ø£ÙØ¶Ù„ Ù„ÙˆÙ† Ø®Ù„ÙÙŠØ©: RGB{best_result['best_background_color']}")

        return best_result
