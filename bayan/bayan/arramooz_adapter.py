# -*- coding: utf-8 -*-
"""
Ù…Ø­ÙˆÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Arramooz Ø¥Ù„Ù‰ Python
Arramooz Dictionary Adapter for Python

ÙŠØ­ÙˆÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Arramooz (40,850 ÙƒÙ„Ù…Ø©) Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ Ø¨ÙŠØ§Ù†
Converts Arramooz database data (40,850 words) for use in Bayan

Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ø£ØµÙ„ÙŠ: TypeScript ÙÙŠ /vocabulary/arramoozDictionaryAdapter.ts
Original source: TypeScript in /vocabulary/arramoozDictionaryAdapter.ts
"""

import sqlite3
import os
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum


class FoundationWordType(Enum):
    """Ù†ÙˆØ¹ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©"""
    ENTITY = 'ÙƒÙŠØ§Ù†'
    PROPERTY = 'Ø®Ø§ØµÙŠØ©'
    ACTION = 'ÙØ¹Ù„'
    STATE = 'Ø­Ø§Ù„Ø©'
    RELATION = 'Ø¹Ù„Ø§Ù‚Ø©'
    DIRECTION = 'Ø§ØªØ¬Ø§Ù‡'
    QUANTITY = 'ÙƒÙ…ÙŠØ©'
    TIME = 'Ø²Ù…Ù†'


class FoundationCategory(Enum):
    """ÙØ¦Ø© Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©"""
    INITIAL_ENVIRONMENT = 'Ø§Ù„Ø¨ÙŠØ¦Ø©_Ø§Ù„Ø£ÙˆÙ„ÙŠØ©'
    ENTITY_EXISTENCE = 'Ø§Ù„ÙƒÙŠØ§Ù†_ÙˆØ§Ù„ÙˆØ¬ÙˆØ¯'
    PHYSICAL = 'ÙÙŠØ²ÙŠØ§Ø¦ÙŠØ©'
    SENSORY = 'Ø­Ø³ÙŠØ©'
    PSYCHOLOGICAL = 'Ù†ÙØ³ÙŠØ©'
    SOCIAL = 'Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©'
    BASIC_ACTIONS = 'Ø£ÙØ¹Ø§Ù„_Ø£Ø³Ø§Ø³ÙŠØ©'
    TRANSFORMATIONS = 'ØªØ­ÙˆÙ„Ø§Øª'
    NATURAL_ENVIRONMENT = 'Ø¨ÙŠØ¦Ø©_Ø·Ø¨ÙŠØ¹ÙŠØ©'


@dataclass
class FoundationWord:
    """ÙƒÙ„Ù…Ø© Ø£Ø³Ø§Ø³ÙŠØ©"""
    arabic: str
    english: Optional[str] = None
    word_type: FoundationWordType = FoundationWordType.ENTITY
    category: FoundationCategory = FoundationCategory.ENTITY_EXISTENCE
    core_meaning: str = ""
    related_words: List[str] = None
    root_word: Optional[str] = None
    meaning_angle: Optional[str] = None
    examples: List[str] = None
    weight: float = 0.5
    
    def __post_init__(self):
        if self.related_words is None:
            self.related_words = []
        if self.examples is None:
            self.examples = []


class ArramoozAdapter:
    """
    Ù…Ø­ÙˆÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Arramooz
    Arramooz Dictionary Adapter
    
    ÙŠÙˆÙØ± Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ 40,850 ÙƒÙ„Ù…Ø© Ø¹Ø±Ø¨ÙŠØ© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Arramooz
    Provides access to 40,850 Arabic words from Arramooz database
    """
    
    def __init__(self, db_path: str = None):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø­ÙˆÙ„
        
        Args:
            db_path: Ù…Ø³Ø§Ø± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        """
        self.db_path = db_path
        self.conn: Optional[sqlite3.Connection] = None
        self.cache: Dict[str, FoundationWord] = {}
        self.root_cache: Dict[str, List[FoundationWord]] = {}
        self.is_loaded = False
    
    def _find_database(self) -> Optional[str]:
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„Ù Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ù…Ø³Ø§Ø±Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©"""
        if self.db_path and os.path.exists(self.db_path):
            return self.db_path
            
        # Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
        possible_paths = [
            # Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø§Ù„Ù…Ø­Ø¯Ø¯ ÙÙŠ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø£ØµÙ„ÙŠ
            'src/baserah/lexicon/databases/arramooz_dictionary.db',
            # ÙÙŠ Ù†ÙØ³ Ø§Ù„Ù…Ø¬Ù„Ø¯
            os.path.join(os.path.dirname(__file__), 'arramooz_dictionary.db'),
            # ÙÙŠ Ù…Ø¬Ù„Ø¯ databases Ø§Ù„Ù…Ø¬Ø§ÙˆØ±
            os.path.join(os.path.dirname(__file__), 'databases', 'arramooz_dictionary.db'),
            # ÙÙŠ Ù…Ø¬Ù„Ø¯ databases ÙÙŠ Ø§Ù„Ø¬Ø°Ø±
            'databases/arramooz_dictionary.db',
            # ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ
            'arramooz_dictionary.db'
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                return path
                
        return None

    def load_database(self) -> bool:
        """
        ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        Load the database
        
        Returns:
            True Ø¥Ø°Ø§ Ù†Ø¬Ø­ Ø§Ù„ØªØ­Ù…ÙŠÙ„ØŒ False Ø¥Ø°Ø§ ÙØ´Ù„
        """
        if self.is_loaded:
            return True
            
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        found_path = self._find_database()
        if not found_path:
            print(f'âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª arramooz_dictionary.db')
            print(f'   ÙŠØ±Ø¬Ù‰ ÙˆØ¶Ø¹Ù‡ ÙÙŠ Ø£Ø­Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:')
            print(f'   - src/baserah/lexicon/databases/')
            print(f'   - {os.path.dirname(__file__)}/')
            return False
        
        self.db_path = found_path
        
        try:
            self.conn = sqlite3.connect(self.db_path)
            self.conn.row_factory = sqlite3.Row
            self.is_loaded = True
            print('âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Arramooz Ø¨Ù†Ø¬Ø§Ø­ (40,850 ÙƒÙ„Ù…Ø©)')
            return True
        except Exception as e:
            print(f'âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Arramooz: {e}')
            print(f'   Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹: {self.db_path}')
            return False
    
    def search_word(self, word: str) -> Optional[FoundationWord]:
        """
        Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø©
        Search for a word
        
        Args:
            word: Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±Ø§Ø¯ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†Ù‡Ø§
        
        Returns:
            FoundationWord Ø£Ùˆ None Ø¥Ø°Ø§ Ù„Ù… ØªÙˆØ¬Ø¯
        """
        if not self.is_loaded or not self.conn:
            raise RuntimeError('Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…Ø­Ù…Ù„Ø©. Ø§Ø³ØªØ®Ø¯Ù… load_database() Ø£ÙˆÙ„Ø§Ù‹.')
        
        # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„ÙƒÙ„Ù…Ø© (Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ Ø§Ù„ØªØ¹Ø±ÙŠÙ)
        normalized = self._normalize_word(word)
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
        if normalized in self.cache:
            return self.cache[normalized]
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡
        result = self._search_in_nouns(normalized)
        if result:
            self.cache[normalized] = result
            return result
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£ÙØ¹Ø§Ù„
        result = self._search_in_verbs(normalized)
        if result:
            self.cache[normalized] = result
            return result
        
        return None
    
    def search_by_root(self, root: str, limit: int = 20) -> List[FoundationWord]:
        """
        Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ø¬Ø°Ø±
        Search by root
        
        Args:
            root: Ø§Ù„Ø¬Ø°Ø±
            limit: Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ù†ØªØ§Ø¦Ø¬
        
        Returns:
            Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø´ØªÙ‚Ø© Ù…Ù† Ø§Ù„Ø¬Ø°Ø±
        """
        if not self.is_loaded or not self.conn:
            raise RuntimeError('Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…Ø­Ù…Ù„Ø©. Ø§Ø³ØªØ®Ø¯Ù… load_database() Ø£ÙˆÙ„Ø§Ù‹.')
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
        if root in self.root_cache:
            return self.root_cache[root]
        
        results = []
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡
        try:
            cursor = self.conn.cursor()
            cursor.execute('SELECT * FROM nouns WHERE root = ? LIMIT ?', (root, limit))
            for row in cursor.fetchall():
                word = self._convert_noun_to_foundation_word(dict(row))
                if word:
                    results.append(word)
        except Exception as e:
            print(f'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ø¬Ø°Ø± ÙÙŠ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡: {e}')
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø£ÙØ¹Ø§Ù„
        try:
            cursor = self.conn.cursor()
            cursor.execute('SELECT * FROM verbs WHERE root = ? LIMIT ?', (root, limit))
            for row in cursor.fetchall():
                word = self._convert_verb_to_foundation_word(dict(row))
                if word:
                    results.append(word)
        except Exception as e:
            print(f'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ø¬Ø°Ø± ÙÙŠ Ø§Ù„Ø£ÙØ¹Ø§Ù„: {e}')
        
        # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
        self.root_cache[root] = results
        
        return results
    
    def get_statistics(self) -> Dict[str, int]:
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        Get database statistics
        
        Returns:
            Ù‚Ø§Ù…ÙˆØ³ Ø¨Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        """
        if not self.is_loaded or not self.conn:
            return {'nouns': 0, 'verbs': 0, 'total': 0}
        
        try:
            cursor = self.conn.cursor()
            
            cursor.execute('SELECT COUNT(*) FROM nouns')
            noun_count = cursor.fetchone()[0]
            
            cursor.execute('SELECT COUNT(*) FROM verbs')
            verb_count = cursor.fetchone()[0]
            
            return {
                'nouns': noun_count,
                'verbs': verb_count,
                'total': noun_count + verb_count
            }
        except Exception as e:
            print(f'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª: {e}')
            return {'nouns': 0, 'verbs': 0, 'total': 0}
    
    def close(self):
        """Ø¥ØºÙ„Ø§Ù‚ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        if self.conn:
            self.conn.close()
            self.conn = None
            self.is_loaded = False
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ø®Ø§ØµØ©
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _normalize_word(self, word: str) -> str:
        """ØªØ·Ø¨ÙŠØ¹ Ø§Ù„ÙƒÙ„Ù…Ø© (Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ Ø§Ù„ØªØ¹Ø±ÙŠÙ)"""
        if word.startswith('Ø§Ù„'):
            return word[2:]
        return word
    
    def _search_in_nouns(self, word: str) -> Optional[FoundationWord]:
        """Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡"""
        try:
            cursor = self.conn.cursor()
            cursor.execute('''
                SELECT * FROM nouns 
                WHERE unvocalized = ? OR normalized = ? OR stamped = ?
                LIMIT 1
            ''', (word, word, word))
            
            row = cursor.fetchone()
            if row:
                return self._convert_noun_to_foundation_word(dict(row))
        except Exception as e:
            print(f'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡: {e}')
        
        return None
    
    def _search_in_verbs(self, word: str) -> Optional[FoundationWord]:
        """Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£ÙØ¹Ø§Ù„"""
        try:
            cursor = self.conn.cursor()
            cursor.execute('''
                SELECT * FROM verbs 
                WHERE unvocalized = ? OR normalized = ? OR stamped = ?
                LIMIT 1
            ''', (word, word, word))
            
            row = cursor.fetchone()
            if row:
                return self._convert_verb_to_foundation_word(dict(row))
        except Exception as e:
            print(f'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£ÙØ¹Ø§Ù„: {e}')
        
        return None
    
    def _convert_noun_to_foundation_word(self, noun: Dict) -> Optional[FoundationWord]:
        """ØªØ­ÙˆÙŠÙ„ Ø§Ø³Ù… Arramooz Ø¥Ù„Ù‰ FoundationWord"""
        if not noun.get('unvocalized'):
            return None
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†ÙˆØ¹
        word_type = self._determine_noun_type(
            noun.get('wordtype', ''),
            noun.get('category', '')
        )
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø©
        related = []
        for field in ['feminin', 'masculin', 'single', 'broken_plural']:
            value = noun.get(field)
            if value and value.strip():
                related.append(value)
        
        return FoundationWord(
            arabic=noun['unvocalized'],
            english=None,
            word_type=word_type,
            category=FoundationCategory.ENTITY_EXISTENCE,
            core_meaning=noun.get('definition', f"{noun.get('wordtype', '')} Ù…Ù† {noun.get('root', '')}"),
            related_words=related,
            root_word=noun.get('root'),
            meaning_angle=noun.get('wazn'),
            examples=[],
            weight=0.5
        )
    
    def _convert_verb_to_foundation_word(self, verb: Dict) -> Optional[FoundationWord]:
        """ØªØ­ÙˆÙŠÙ„ ÙØ¹Ù„ Arramooz Ø¥Ù„Ù‰ FoundationWord"""
        if not verb.get('unvocalized'):
            return None
        
        return FoundationWord(
            arabic=verb['unvocalized'],
            english=None,
            word_type=FoundationWordType.ACTION,
            category=FoundationCategory.BASIC_ACTIONS,
            core_meaning=f"ÙØ¹Ù„ Ù…Ù† Ø§Ù„Ø¬Ø°Ø± {verb.get('root', '')}",
            related_words=[],
            root_word=verb.get('root'),
            meaning_angle=verb.get('future_type'),
            examples=[],
            weight=0.5
        )
    
    def _determine_noun_type(self, wordtype: str, category: str) -> FoundationWordType:
        """ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø§Ø³Ù…"""
        if 'ÙØ§Ø¹Ù„' in wordtype or 'Ù…ÙØ¹ÙˆÙ„' in wordtype:
            return FoundationWordType.ENTITY
        if 'ØµÙØ©' in wordtype:
            return FoundationWordType.PROPERTY
        if category == 'Ø­Ø§Ù„Ø©':
            return FoundationWordType.STATE
        return FoundationWordType.ENTITY
    
    def __enter__(self):
        """Ø¯Ø¹Ù… context manager"""
        self.load_database()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Ø¥ØºÙ„Ø§Ù‚ ØªÙ„Ù‚Ø§Ø¦ÙŠ"""
        self.close()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ù…Ø«Ø§Ù„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                  â•‘
â•‘              ğŸ” Ù…Ø­ÙˆÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Arramooz                      â•‘
â•‘              Arramooz Dictionary Adapter                        â•‘
â•‘                                                                  â•‘
â•‘              40,850 ÙƒÙ„Ù…Ø© Ø¹Ø±Ø¨ÙŠØ©                                  â•‘
â•‘                                                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")
    
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… context manager
    try:
        with ArramoozAdapter() as adapter:
            # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            stats = adapter.get_statistics()
            print(f"\nğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
            print(f"   â”œâ”€ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡: {stats['nouns']:,}")
            print(f"   â”œâ”€ Ø§Ù„Ø£ÙØ¹Ø§Ù„: {stats['verbs']:,}")
            print(f"   â””â”€ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹: {stats['total']:,}")
            
            # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨Ø­Ø«
            print(f"\nğŸ” Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨Ø­Ø«:")
            test_words = ["Ù…Ø¯Ø±Ø³Ø©", "ÙƒØªØ§Ø¨", "ÙŠØ¯Ø±Ø³", "ÙƒØªØ¨"]
            
            for word in test_words:
                result = adapter.search_word(word)
                if result:
                    print(f"\n   Ø§Ù„ÙƒÙ„Ù…Ø©: {word}")
                    print(f"   â”œâ”€ Ø§Ù„Ù†ÙˆØ¹: {result.word_type.value}")
                    print(f"   â”œâ”€ Ø§Ù„Ø¬Ø°Ø±: {result.root_word}")
                    print(f"   â””â”€ Ø§Ù„Ù…Ø¹Ù†Ù‰: {result.core_meaning[:50]}...")
            
            # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ø¬Ø°Ø±
            print(f"\nğŸ“š Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ø¬Ø°Ø± 'Ø¯Ø±Ø³':")
            root_results = adapter.search_by_root('Ø¯Ø±Ø³', limit=5)
            for i, word in enumerate(root_results, 1):
                print(f"   {i}. {word.arabic} ({word.word_type.value})")
            
    except Exception as e:
        print(f"\nâŒ Ø®Ø·Ø£: {e}")
        print("\nğŸ’¡ ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ:")
        print("   src/baserah/lexicon/databases/arramooz_dictionary.db")
