# Conceptual surface realizer layer for Bayan

hybrid {
    import ai.lexicon as lex
    import ai.morphology as morph
}

# Helper: shallow clone of a sequence list
def _clone_sequence(seq):
{
    cloned = []
    for i in range(len(seq)):
    {
        cloned.append(seq[i])
    }
    return cloned
}

# Realize directly from a SurfacePlan
def realize_from_surface_plan(plan, register):
{
    if register == None:
    {
        register = "neutral"
    }

    # 1. Get the abstract sequence
    abstract_seq = plan["sequence"]
    lang = plan["lang"]
    
    # 2. Transform into surface tokens using Lexicon & Morphology
    surface_tokens = []
    
    for i in range(len(abstract_seq)):
    {
        node = abstract_seq[i]
        
        # Default to the node itself if not a dict or no concept
        token_str = str(node)
        
        if isinstance(node, dict):
        {
            # Check if it has a concept to realize
            if "concept_key" in node:
            {
                concept_id = node["concept_key"]
                # Lookup lemma
                entry = lex.lookup_lemma(concept_id, lang)
                
                if entry != None:
                {
                    lemma = entry["lemma"]
                    pos = entry["pos"]
                    
                    # Apply Morphology based on POS and features
                    features = {}
                    if "features" in node:
                    {
                        features = node["features"]
                    }
                    
                    if pos == "verb":
                    {
                        # Verb Conjugation
                        tense = "past" # default
                        if "tense" in features: { tense = features["tense"] }
                        
                        person = "3ms" # default
                        if "person" in features: { person = features["person"] }
                        
                        if lang == "arabic" or lang == "ar":
                        {
                            token_str = morph.conjugate_arabic_verb(lemma, tense, person)
                        }
                        else:
                        {
                            # English needs person mapping (3ms -> 3s)
                            en_person = "3s"
                            if person == "1s": { en_person = "1s" }
                            token_str = morph.conjugate_english_verb(lemma, tense, en_person)
                        }
                    }
                    elif pos == "noun":
                    {
                        # Noun Declension / Pluralization
                        if lang == "arabic" or lang == "ar":
                        {
                            definiteness = "indef"
                            if "definiteness" in features: { definiteness = features["definiteness"] }
                            token_str = morph.decline_arabic_noun(lemma, definiteness)
                        }
                        else:
                        {
                            number = "singular"
                            if "number" in features: { number = features["number"] }
                            if number == "plural":
                            {
                                token_str = morph.pluralize_english_noun(lemma)
                            }
                            else:
                            {
                                token_str = lemma
                            }
                            
                            # English definite article is separate usually, but for simplicity:
                            if "definiteness" in features and features["definiteness"] == "def":
                            {
                                token_str = "the " + token_str
                            }
                        }
                    }
                    else:
                    {
                        token_str = lemma
                    }
                }
                else:
                {
                    # Concept not found, fallback to concept name
                    token_str = "[" + concept_id + "]"
                }
            }
            elif "symbol" in node:
            {
                token_str = node["symbol"]
            }
        }
        
        surface_tokens.append(token_str)
    }

    return {
        "realization_type": "SurfaceRealization",
        "sentence_type": plan["sentence_type"],
        "lang": plan["lang"],
        "register": register,
        "tokens": surface_tokens,
        "modifiers": plan["modifiers"],
        "source": "SurfacePlan"
    }
}


# Realize from a SentenceTree
def realize_from_sentence_tree(tree, register):
{
    if register == None:
    {
        register = "neutral"
    }

    plan = {
        "plan_type": "SurfacePlan",
        "sentence_type": tree["sentence_type"],
        "lang": tree["lang_hint"],
        "sequence": tree["linearization"],
        "modifiers": tree["modifiers"]
    }
    return realize_from_surface_plan(plan, register)
}


# Generic entry point
def realize_any(struct, register):
{
    if register == None:
    {
        register = "neutral"
    }
    if "tree_type" in struct:
    {
        return realize_from_sentence_tree(struct, register)
    }
    elif "plan_type" in struct:
    {
        return realize_from_surface_plan(struct, register)
    }
    else:
    {
        return {
            "realization_type": "SurfaceRealization",
            "sentence_type": struct.get("sentence_type", "Unknown"),
            "lang": "abstract",
            "register": register,
            "tokens": [],
            "modifiers": {},
            "raw": struct
        }
    }
}


# Convert to token strings
def realization_to_token_strings(realization):
{
    toks = []
    seq = realization["tokens"]
    for i in range(len(seq)):
    {
        tok = seq[i]
        if isinstance(tok, dict) and "symbol" in tok:
        {
            toks.append(tok["symbol"])
        }
        elif isinstance(tok, str):
        {
            toks.append(tok)
        }
        else:
        {
            toks.append(str(tok))
        }
    }
    return toks
}


# Convert to text
def realization_to_text(realization):
{
    toks = realization_to_token_strings(realization)
    sep = " "
    return sep.join(toks)
}


# Build LM example
def build_conceptual_lm_example(conceptual_trace, blueprint_roles, stree, register):
{
    if register == None:
    {
        register = "neutral"
    }

    surface = realize_from_sentence_tree(stree, register)
    text = realization_to_text(surface)
    return {
        "conceptual_trace": conceptual_trace,
        "blueprint_roles": blueprint_roles,
        "sentence_tree": stree,
        "surface": surface,
        "text": text
    }
}


# Build training data from program output
def build_lm_training_data(program_output, language):
{
    if language == None:
    {
        language = "arabic"
    }

    examples = []
    full_text_parts = []

    # Extract circuits from program output
    if "circuits" in program_output:
    {
        circuits = program_output["circuits"]
        for i in range(len(circuits)):
        {
            circuit = circuits[i]

            # Generate text for this circuit
            text = _circuit_to_text(circuit, language)
            full_text_parts.append(text)

            # Create a training example from circuit
            example = {
                "circuit_type": circuit.get("circuit_type", "unknown"),
                "language": language,
                "text": text,
                "index": i
            }
            examples.append(example)
        }
    }

    # Join all texts
    sep = " "
    if language == "arabic":
    {
        sep = "، "
    }
    else:
    {
        sep = ", "
    }
    full_text = sep.join(full_text_parts)

    return {
        "training_examples": examples,
        "full_text": full_text,
        "count": len(examples),
        "language": language
    }
}


# Helper: Convert circuit to text
def _circuit_to_text(circuit, language):
{
    # Simple text generation from circuit
    circuit_type = circuit.get("circuit_type", "unknown")

    if language == "arabic":
    {
        if circuit_type == "action_state_eval":
        {
            return "دائرة الفعل والحالة والتقييم"
        }
        elif circuit_type == "causal_link":
        {
            return "دائرة الربط السببي"
        }
        elif circuit_type == "temporal_sequence":
        {
            return "دائرة التسلسل الزمني"
        }
        elif circuit_type == "contextualized_event":
        {
            return "دائرة الحدث السياقي"
        }
        elif circuit_type == "uncertain_cause_effect":
        {
            return "دائرة السبب والنتيجة غير المؤكدة"
        }
        elif circuit_type == "enhanced_comparison":
        {
            return "دائرة المقارنة المحسنة"
        }
        else:
        {
            return "دائرة مفاهيمية"
        }
    }
    else:
    {
        if circuit_type == "action_state_eval":
        {
            return "action state evaluation circuit"
        }
        elif circuit_type == "causal_link":
        {
            return "causal link circuit"
        }
        elif circuit_type == "temporal_sequence":
        {
            return "temporal sequence circuit"
        }
        elif circuit_type == "contextualized_event":
        {
            return "contextualized event circuit"
        }
        elif circuit_type == "uncertain_cause_effect":
        {
            return "uncertain cause effect circuit"
        }
        elif circuit_type == "enhanced_comparison":
        {
            return "enhanced comparison circuit"
        }
        else:
        {
            return "conceptual circuit"
        }
    }
}


# Convert conceptual trace to natural text
def trace_to_natural_text(trace, language):
{
    if language == None:
    {
        language = "arabic"
    }

    # Extract key information from trace
    entities = trace.get("entities", [])
    events = trace.get("events", [])
    transforms = trace.get("transforms", [])

    # Generate natural text based on trace content
    parts = []

    if language == "arabic":
    {
        # Arabic text generation
        if len(entities) > 0:
        {
            parts.append("الكيانات: " + str(len(entities)))
        }
        if len(events) > 0:
        {
            parts.append("الأحداث: " + str(len(events)))
        }
        if len(transforms) > 0:
        {
            parts.append("التحولات: " + str(len(transforms)))
        }

        if len(parts) == 0:
        {
            return "أثر مفاهيمي"
        }

        sep = "، "
        return sep.join(parts)
    }
    else:
    {
        # English text generation
        if len(entities) > 0:
        {
            parts.append("entities: " + str(len(entities)))
        }
        if len(events) > 0:
        {
            parts.append("events: " + str(len(events)))
        }
        if len(transforms) > 0:
        {
            parts.append("transforms: " + str(len(transforms)))
        }

        if len(parts) == 0:
        {
            return "conceptual trace"
        }

        sep = ", "
        return sep.join(parts)
    }
}
